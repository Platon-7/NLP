{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOWFyxujaA/G7TfuQKdnR4/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d1479ad728d412c91c7c46a138af181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47425f0afa264c19b79d1bab2b0fe0c2",
              "IPY_MODEL_a380a8539f2f4d829ccd325a4bdcd3e3",
              "IPY_MODEL_ca56d87c20094d4b8738a82c9afae3e1"
            ],
            "layout": "IPY_MODEL_b7a201a0875d40cebf99377d014a1b8f"
          }
        },
        "47425f0afa264c19b79d1bab2b0fe0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ad32321bbf248538fe92af7147fdf1f",
            "placeholder": "​",
            "style": "IPY_MODEL_0e15ad63118a4e9cb56fe49b83732136",
            "value": "100%"
          }
        },
        "a380a8539f2f4d829ccd325a4bdcd3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd6dd474368e46dfb92c601d0596e68b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8aa4278054f04cb5a7d2d98a1e2f3a8e",
            "value": 3
          }
        },
        "ca56d87c20094d4b8738a82c9afae3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65443b18fdbf41f993e7e75159b63e30",
            "placeholder": "​",
            "style": "IPY_MODEL_5a494117354d40db9cdabd49554b4c6f",
            "value": " 3/3 [00:00&lt;00:00, 45.04it/s]"
          }
        },
        "b7a201a0875d40cebf99377d014a1b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ad32321bbf248538fe92af7147fdf1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e15ad63118a4e9cb56fe49b83732136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd6dd474368e46dfb92c601d0596e68b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aa4278054f04cb5a7d2d98a1e2f3a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65443b18fdbf41f993e7e75159b63e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a494117354d40db9cdabd49554b4c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgKEO_5BiVpy"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czbBmNL5PIvl"
      },
      "source": [
        "# PART 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M25zKOyeOAFU"
      },
      "source": [
        "## Installs, Imports and Paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set \n",
        "PYTORCH_CUDA_ALLOC_CONF=\"garbage_collection_threshold:0.6,max_split_size_mb:128\""
      ],
      "metadata": {
        "id": "u2lgEvdZQvhh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NpnfcH4ZQwWt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit_learn\n",
        "!pip install -U nltk\n",
        "!pip install -U datasets\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install scipy\n",
        "!pip install --upgrade scikeras\n",
        "!pip install -U tensorflow-gpu\n",
        "!pip install keras-self-attention\n",
        "!pip install transformers\n",
        "!pip install optuna\n",
        "!pip install wandb\n",
        "!pip install ray[tune]"
      ],
      "metadata": {
        "id": "zRkWpL1PQxOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "import random\n",
        "import nltk\n",
        "import urllib.request, zipfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import scipy\n",
        "import keras\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch\n",
        "from ray.tune.schedulers import PopulationBasedTraining\n",
        "from tensorflow.keras import backend as K\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "from tabulate import tabulate\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from google.colab import files\n",
        "from ray import tune\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "stemmer = WordNetLemmatizer()\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTofpGWXQyqr",
        "outputId": "36549e72-ab88-4c14-ece1-c4f3867117a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE_SY-eF-llQ",
        "outputId": "431dca7f-6867-48b0-cbd1-82a14b31c42a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: wandb: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_LOG_MODEL = true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek16RK_e-o09",
        "outputId": "8137ab8b-e457-45cb-fa68-db12cffbc9ad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_LOG_MODEL=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_PROJECT = sentiment-analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lde6GMT1-pID",
        "outputId": "5020ff17-bd66-4c02-8580-54c3f2008f00"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_PROJECT=sentiment-analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_NOTEBOOK_NAME = \"/content/Sentiment-Analysis-Part-5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvxmDnun-tEo",
        "outputId": "f4a6ed3a-55e0-4820-c177-716c4c744dfc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_NOTEBOOK_NAME=\"/content/Sentiment-Analysis-Part-5\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./Sentiment-Analysis'):\n",
        "  os.makedirs('./Sentiment-Analysis')\n",
        "os.chdir('./Sentiment-Analysis')"
      ],
      "metadata": {
        "id": "U6LfW8q3Q0J2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiFwBq-9Qw68"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhmaXbVTLMUp"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove(text, polarity, n):\n",
        "    for _ in range(int(len(text)*n)):\n",
        "        number = random.randrange(0,len(text))\n",
        "        text.pop(number)\n",
        "        polarity.pop(number)\n",
        "    return\n",
        "\n",
        "#importing the dataset\n",
        "tweets = load_dataset(\"tweet_eval\",'sentiment')\n",
        "\n",
        "#create train/dev/test sets \n",
        "train = tweets['train']\n",
        "dev = tweets['validation']\n",
        "test = tweets['test']\n",
        "\n",
        "x_train = train['text']\n",
        "x_val = dev['text'] \n",
        "x_test = test['text']\n",
        "\n",
        "y_train = train['label'] \n",
        "y_val = dev['label']\n",
        "y_test = test['label']\n",
        "\n",
        "#removing big parts because of too many data\n",
        "#remove(x_train, y_train, 0.5)\n",
        "#remove(x_val, y_val, 0.2)\n",
        "#remove(x_test, y_test, 0.5)\n",
        "\n",
        "print(\"Training Data Size: \", len(x_train))\n",
        "print(\"Evaluation Data Size: \", len(x_val))\n",
        "print(\"Test Data Size: \", len(x_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "3d1479ad728d412c91c7c46a138af181",
            "47425f0afa264c19b79d1bab2b0fe0c2",
            "a380a8539f2f4d829ccd325a4bdcd3e3",
            "ca56d87c20094d4b8738a82c9afae3e1",
            "b7a201a0875d40cebf99377d014a1b8f",
            "2ad32321bbf248538fe92af7147fdf1f",
            "0e15ad63118a4e9cb56fe49b83732136",
            "bd6dd474368e46dfb92c601d0596e68b",
            "8aa4278054f04cb5a7d2d98a1e2f3a8e",
            "65443b18fdbf41f993e7e75159b63e30",
            "5a494117354d40db9cdabd49554b4c6f"
          ]
        },
        "id": "8eSPTr4kQ4E5",
        "outputId": "032498ff-82b3-4d82-cf56-d3593fbe0f71"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d1479ad728d412c91c7c46a138af181"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Size:  45615\n",
            "Evaluation Data Size:  2000\n",
            "Test Data Size:  12284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V-IfupbgX9R"
      },
      "source": [
        "### Heuristic for text-classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_size = []\n",
        "for sent in x_train:\n",
        "  internal_c = 0\n",
        "  for word in sent:\n",
        "    internal_c += 1\n",
        "  total_size.append(internal_c)\n",
        "\n",
        "sum = 0\n",
        "for i in range(len(total_size)):\n",
        "  sum += total_size[i]\n",
        "\n",
        "mean = sum/len(total_size)\n",
        "\n",
        "print(len(x_train))\n",
        "print(mean)\n",
        "print(len(x_train)/mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h6G8IFbQ8Ho",
        "outputId": "cd7ce3ef-ce84-4c5c-f6b8-1c34b52fff72"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45615\n",
            "106.93285103584347\n",
            "426.57611349677785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the ground for BERT"
      ],
      "metadata": {
        "id": "kG8WDTcb8uga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preview Data"
      ],
      "metadata": {
        "id": "sje6FGHa6_r-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = [len(i.split()) for i in x_train]\n",
        "pd.Series(seq_len).hist(bins=30)\n",
        "# max sequence length for each document/sentence sample\n",
        "max_length = 25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "WNYOU8FERB9p",
        "outputId": "b1dc71c7-f028-44d1-bf0c-0cd68bc8ef7c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model and adjust Data"
      ],
      "metadata": {
        "id": "wiHH--dj7FPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT's (WordPiece) tokenizer\n",
        "# Uncased model -> lowercase characters\n",
        "model_name = \"bert-base-uncased\"\n",
        "#target_list = ['0', '1', '2']\n",
        "tokenizer_1 = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
      ],
      "metadata": {
        "id": "Gn7BueBHRETQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89823f55-9c22-4f13-c264-347e292a06e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the dataset at max_length, using truncation and padding\n",
        "train_encodings = tokenizer_1(x_train, truncation=True, padding=True, max_length=max_length)\n",
        "valid_encodings = tokenizer_1(x_val, truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings = tokenizer_1(x_test, truncation=True, padding=True, max_length=max_length)"
      ],
      "metadata": {
        "id": "51Vg4AU7RFOJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader consists of encodings (Xs) and labels (Ys)\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #every key has a list as value (list of samples)\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Convert our tokenized data into a torch Dataset\n",
        "train_dataset = SentimentDataset(train_encodings, y_train)\n",
        "valid_dataset = SentimentDataset(valid_encodings, y_val)\n",
        "test_dataset = SentimentDataset(test_encodings, y_val)"
      ],
      "metadata": {
        "id": "B4OGr9t0RGYL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_list = [0, 1, 2]\n",
        "# Load a BERT model for *text classification* \n",
        "\n",
        "\"\"\"\n",
        "    This is a classic Bert Model transformer \n",
        "    with a sequence classification/regression head on top \n",
        "    (a linear layer on top of the pooled output) \n",
        "\"\"\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxKJEEHGRHlQ",
        "outputId": "ac1a2872-ede3-4866-ed72-2498dd9a92dd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "9gICkNi-6vYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size= 16,  # batch size per device during training\n",
        "    per_device_eval_batch_size= 20,   # batch size for evaluation\n",
        "    warmup_steps=300,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay. The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in AdamW optimizer.\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
        "    logging_steps=10,               # log & save weights each logging_steps\n",
        "    evaluation_strategy=\"steps\",     # The evaluation strategy to adopt during training. Evaluation is done (and logged) every `logging_steps`\n",
        ")"
      ],
      "metadata": {
        "id": "hnti8GGERK7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2eb86fc-ae46-44b6-e466-b2f2b0906961"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 10\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom metric method\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  f1 = f1_score(labels, preds, average = 'macro')\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "      'f1': f1\n",
        "  }"
      ],
      "metadata": {
        "id": "JHMQu5V5RMKI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  trainer = Trainer(\n",
        "      model=model,                         # the instantiated Transformers model to be trained\n",
        "      args=training_args,                  # training arguments, defined above\n",
        "      train_dataset=train_dataset,         # training dataset\n",
        "      eval_dataset=valid_dataset,          # evaluation dataset\n",
        "      compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "  )\n",
        "\n",
        "  trainer.train()"
      ],
      "metadata": {
        "id": "NIFQ_MSDRNWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate and Save Model"
      ],
      "metadata": {
        "id": "UEAklLtV6qKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the current model after training\n",
        "trainer.evaluate()\n",
        "\n",
        "# Save the fine-tuned model and the tokenizer\n",
        "model_path = \"sent-anal-bert-base-uncased\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer_1.save_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "vuoeETn-RSnd",
        "outputId": "d70be1d2-0ec0-435e-db74-2b34b18a8cad"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in sent-anal-bert-base-uncased/config.json\n",
            "Model weights saved in sent-anal-bert-base-uncased/pytorch_model.bin\n",
            "tokenizer config file saved in sent-anal-bert-base-uncased/tokenizer_config.json\n",
            "Special tokens file saved in sent-anal-bert-base-uncased/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sent-anal-bert-base-uncased/tokenizer_config.json',\n",
              " 'sent-anal-bert-base-uncased/special_tokens_map.json',\n",
              " 'sent-anal-bert-base-uncased/vocab.txt',\n",
              " 'sent-anal-bert-base-uncased/added_tokens.json',\n",
              " 'sent-anal-bert-base-uncased/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "5Sj4JdBFs8D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(\"sent-anal-bert-base-uncased\", num_labels=len(target_list)).to(\"cuda\")\n",
        "tokenizer_2 = BertTokenizerFast.from_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buLHOETTs4gP",
        "outputId": "b57101fa-ef2c-4637-fc14-01cb2ff6c8ef"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file sent-anal-bert-base-uncased/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file sent-anal-bert-base-uncased/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at sent-anal-bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Assessment"
      ],
      "metadata": {
        "id": "G0kP_CR16c4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(text):\n",
        "    # prepare our text into tokenized sequence\n",
        "    inputs = tokenizer_2(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # perform inference to our model\n",
        "    outputs = model(**inputs)\n",
        "    # get output probabilities by doing softmax\n",
        "    probs = outputs[0].softmax(1)\n",
        "    # executing argmax function to get the candidate label\n",
        "    return target_list[probs.argmax()]\n",
        "\n",
        "def get_probabilities(x):\n",
        "  y_proba = []\n",
        "  for sent in x:\n",
        "    inputs = tokenizer_2(sent, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # perform inference to our model\n",
        "    outputs = model(**inputs)\n",
        "    # get output probabilities by doing softmax\n",
        "    probs = outputs[0].softmax(1)\n",
        "    y_proba.append(probs)\n",
        "  return y_proba"
      ],
      "metadata": {
        "id": "6ASxT70MRUlQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  def predictions(x_test):\n",
        "    y_pred = []\n",
        "    for sentence in x_test:\n",
        "      y_pred.append(int(get_prediction(sentence)))\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "  y_pred_train = predictions(x_train)\n",
        "  y_pred_val = predictions(x_val)\n",
        "  y_pred_test = predictions(x_test)\n",
        "  \n",
        "  K.clear_session()"
      ],
      "metadata": {
        "id": "TYpyhJYNRVm3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  m_train_f1_score = f1_score(y_train, y_pred_train, average = 'macro')\n",
        "  print(\"Train f1-score: {:.2f}% \\n\".format(m_train_f1_score*100))\n",
        "\n",
        "  m_val_f1_score = f1_score(y_val, y_pred_val, average = 'macro')\n",
        "  print(\"Evaluation f1-score: {:.2f}% \\n\".format(m_val_f1_score*100))\n",
        "\n",
        "  m_test_f1_score = f1_score(y_test, y_pred_test, average = 'macro')\n",
        "  print(\"Test f1-score: {:.2f}% \\n\".format(m_test_f1_score*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv11D3zzRWro",
        "outputId": "a2d7889b-a9b5-40af-97df-eaac23a4a0ce"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train f1-score: 90.43% \n",
            "\n",
            "Evaluation f1-score: 68.88% \n",
            "\n",
            "Test f1-score: 66.21% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precision, Recall, AUC, ROC-AUC"
      ],
      "metadata": {
        "id": "2a0fHGVR6aFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "-YrwUbexRbMh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def alter_labels(data, status):\n",
        "  temp = []\n",
        "  for i in range(len(data)):\n",
        "    if status == 'add':\n",
        "      temp.append(data[i]+ 1)\n",
        "    if status == 'subtract':\n",
        "      temp.append(data[i] - 1)\n",
        "  return temp"
      ],
      "metadata": {
        "id": "TovqmS2LU0X8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_Bert_Results(x, y_true, y_pred):\n",
        "\n",
        "  y_pred_enc = alter_labels(y_pred, 'subtract') # 0,1,2\n",
        "  y_true_enc = alter_labels(y_true, 'subtract') # 0,1,2\n",
        "\n",
        "  train_precision_score = precision_score(y_true_enc, y_pred_enc, average = None)\n",
        "  train_recall_score = recall_score(y_true_enc, y_pred_enc, average = None)\n",
        "  train_f1_score = f1_score(y_true_enc, y_pred_enc, average = None)\n",
        "\n",
        "\n",
        "  m_train_precision_score = precision_score(y_true_enc, y_pred_enc, average = 'macro')\n",
        "  m_train_recall_score = recall_score(y_true_enc, y_pred_enc, average = 'macro')\n",
        "  m_train_f1_score = f1_score(y_true_enc, y_pred_enc, average = 'macro')\n",
        "\n",
        "  y_pred_onehot = np.eye(len(np.unique(y_pred_enc)))[y_pred_enc]\n",
        "\n",
        "  # One-hot encode the true class labels\n",
        "  y_true_onehot = np.eye(len(np.unique(y_true_enc)))[y_true_enc]\n",
        "\n",
        "\n",
        "  m_train_roc_auc_score = roc_auc_score(y_true_onehot, y_pred_onehot, multi_class= 'ovr', average = 'macro')\n",
        "\n",
        "\n",
        "  table = [['    ', 'Precision', 'Recall', 'F1', 'AUC', 'Macro-Precision', 'Macro-Recall', 'Macro-F1', 'Macro-AUC'], \n",
        "        ['Positive', round(train_precision_score[0], 3), round(train_recall_score[0], 3), round(train_f1_score[0], 3),'-', '-', '-', '-'],\n",
        "        ['Neutral', round(train_precision_score[1], 3), round(train_recall_score[1], 3), round(train_f1_score[1], 3), '-', '-', '-', '-'],\n",
        "        ['Negative', round(train_precision_score[2], 3), round(train_recall_score[2], 3), round(train_f1_score[2], 3), '-', '-', '-', '-'],\n",
        "        ['Total', '-', '-','-','-', round(m_train_precision_score, 3), round(m_train_recall_score, 3), round(m_train_f1_score, 3), round(m_train_roc_auc_score, 3)]]\n",
        "\n",
        "  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
      ],
      "metadata": {
        "id": "v3QwTmqGRcZ3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bert ---------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "print(\"The training results: \\n\")\n",
        "calculate_Bert_Results(x_train, y_train, y_pred_train)\n",
        "\n",
        "print(\"The evaluation results: \\n\")\n",
        "calculate_Bert_Results(x_val, y_val, y_pred_val)\n",
        "\n",
        "print(\"The test results: \\n\")\n",
        "calculate_Bert_Results(x_test, y_test, y_pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QQqmcVQRduT",
        "outputId": "affb52b6-ac82-4b5a-f64b-25467ce9fef7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bert ---------------------------------------------------------------------------------------------------------\n",
            "\n",
            "The training results: \n",
            "\n",
            "╒══════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│          │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │   Macro-AUC │\n",
            "╞══════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ Positive │ 0.907       │ 0.884    │ 0.896 │ -     │ -                 │ -              │ -          │             │\n",
            "├──────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Neutral  │ 0.917       │ 0.884    │ 0.9   │ -     │ -                 │ -              │ -          │             │\n",
            "├──────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Negative │ 0.895       │ 0.941    │ 0.917 │ -     │ -                 │ -              │ -          │             │\n",
            "├──────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total    │ -           │ -        │ -     │ -     │ 0.906             │ 0.903          │ 0.904      │       0.926 │\n",
            "╘══════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n",
            "The evaluation results: \n",
            "\n",
            "╒══════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│          │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │   Macro-AUC │\n",
            "╞══════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ Positive │ 0.638       │ 0.593    │ 0.615 │ -     │ -                 │ -              │ -          │             │\n",
            "├──────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Neutral  │ 0.692       │ 0.692    │ 0.692 │ -     │ -                 │ -              │ -          │             │\n",
            "├──────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Negative │ 0.75        │ 0.77     │ 0.76  │ -     │ -                 │ -              │ -          │             │\n",
            "├──────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total    │ -           │ -        │ -     │ -     │ 0.693             │ 0.685          │ 0.689      │       0.763 │\n",
            "╘══════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n",
            "The test results: \n",
            "\n",
            "╒══════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│          │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │   Macro-AUC │\n",
            "╞══════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ Positive │ 0.686       │ 0.684    │ 0.685 │ -     │ -                 │ -              │ -          │             │\n",
            "├──────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Neutral  │ 0.693       │ 0.614    │ 0.651 │ -     │ -                 │ -              │ -          │             │\n",
            "├──────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Negative │ 0.577       │ 0.745    │ 0.65  │ -     │ -                 │ -              │ -          │             │\n",
            "├──────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total    │ -           │ -        │ -     │ -     │ 0.652             │ 0.681          │ 0.662      │       0.751 │\n",
            "╘══════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper Parameter Tuning"
      ],
      "metadata": {
        "id": "5Jfbm6uu4TtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics2(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [classes[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [classes[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    # Compute precision, recall, f1, and accuracy\n",
        "    num_correct = 0\n",
        "    num_predicted = 0\n",
        "    num_gold = 0\n",
        "    for i in range(len(true_predictions)):\n",
        "        for j in range(len(true_predictions[i])):\n",
        "            if true_predictions[i][j] == true_labels[i][j]:\n",
        "                num_correct += 1\n",
        "            num_predicted += 1\n",
        "            num_gold += 1\n",
        "    precision = num_correct / num_predicted if num_predicted > 0 else 0\n",
        "    recall = num_correct / num_gold if num_gold > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    accuracy = num_correct / num_gold if num_gold > 0 else 0\n",
        "\n",
        "    eval_metrics = {\n",
        "        \"eval_loss\": 0,  # add any necessary loss calculation\n",
        "        \"eval_precision\": precision,\n",
        "        \"eval_recall\": recall,\n",
        "        \"eval_f1\": f1,\n",
        "        \"eval_accuracy\": accuracy,\n",
        "        \"eval_runtime\": 0,  # add any necessary runtime calculation\n",
        "        \"eval_samples_per_second\": 0,  # add any necessary samples per second calculation\n",
        "        \"eval_steps_per_second\": 0,  # add any necessary steps per second calculation\n",
        "    }\n",
        "\n",
        "    return eval_metrics\n"
      ],
      "metadata": {
        "id": "b0lOtUavCVG9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "\n",
        "def model_init():\n",
        "    return BertForSequenceClassification.from_pretrained(\"/content/Sentiment-Analysis/Sentiment-Analysis/sent-anal-bert-base-uncased\", num_labels=len(target_list), return_dict=True).to(\"cuda\")\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"test\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    report_to=\"wandb\",\n",
        "    eval_steps=100,\n",
        "    disable_tqdm=True\n",
        ")\n",
        "\n",
        "def tune_model(config):\n",
        "    trainer = Trainer(\n",
        "        args=training_args,\n",
        "        tokenizer=tokenizer_2,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=valid_dataset,\n",
        "        model_init=model_init,\n",
        "        compute_metrics=compute_metrics2,\n",
        "    )\n",
        "    trainer.train()\n",
        "    results = trainer.evaluate()\n",
        "\n",
        "    tune.report(eval_accuracy=results[\"eval_accuracy\"], eval_f1=results[\"eval_f1\"])\n",
        "\n",
        "search_space = {\n",
        "    \"learning_rate\": tune.loguniform(0.0001, 0.001, 0.01),\n",
        "    \"num_train_epochs\": tune.choice([1, 2, 3]),\n",
        "    \"per_device_train_batch_size\": tune.choice([4, 8, 16]),\n",
        "    \"weight_decay\": tune.loguniform(1e-6, 1e-1)\n",
        "}\n",
        "\n",
        "scheduler = ASHAScheduler(\n",
        "    max_t=5,\n",
        "    grace_period=1,\n",
        "    reduction_factor=2)\n",
        "\n",
        "reporter = CLIReporter(metric_columns=[\"eval_accuracy\", \"eval_f1\"])\n",
        "\n",
        "analysis = tune.run(\n",
        "    tune_model,\n",
        "    metric = \"eval_f1\",\n",
        "    mode = \"max\",\n",
        "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},\n",
        "    config=search_space,\n",
        "    num_samples=5,\n",
        "    scheduler=scheduler,\n",
        "    progress_reporter=reporter\n",
        ")"
      ],
      "metadata": {
        "id": "W6zgY3xPCPCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}