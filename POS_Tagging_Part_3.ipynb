{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQ5ejRdCrXguwg4Iek3L40"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRXODnxy0Thc"
      },
      "source": [
        "# **POS Tagging**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K8IUY23KfIf"
      },
      "source": [
        "# PART 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqHnUDfH1eh5"
      },
      "source": [
        "## Installs, Imports and Paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rRUG4jKepS4M"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit_learn\n",
        "!pip install nltk\n",
        "!pip install --upgrade wandb\n",
        "!pip install datasets\n",
        "!pip install tensorflow\n",
        "!pip install scipy\n",
        "!pip install scikeras\n",
        "!pip install numpy\n",
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzoNzSMrpTzE",
        "outputId": "7b3128f2-487e-4a9e-f5de-e4f896c689fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.5.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.15.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=805b2b142cb6883caad99f9b43cd8835d13570013498cdc3860c111b0f0b2ade\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, urllib3, smmap, setproctitle, docker-pycreds, sentry-sdk, gitdb, GitPython, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.15.0 setproctitle-1.3.2 smmap-5.0.0 urllib3-1.26.14 wandb-0.13.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, multiprocess, responses, huggingface-hub, datasets\n",
            "Successfully installed datasets-2.9.0 huggingface-hub-0.12.1 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (23.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pickle\n",
        "import random\n",
        "import nltk\n",
        "import wandb\n",
        "import os\n",
        "import string\n",
        "import spacy\n",
        "import keras\n",
        "import urllib.request, zipfile\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv1D, concatenate\n",
        "from keras.layers import add\n",
        "from collections import Counter\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from sklearn import preprocessing\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.models import FastText\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "from pandas.core.missing import find_valid_index\n",
        "from sklearn.model_selection import learning_curve, GridSearchCV\n",
        "from tabulate import tabulate\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "stemmer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StR_3Q5OpVA-",
        "outputId": "36dd17cb-9bcb-4334-9013-437a456fe630"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yazcDMIzpWJH",
        "outputId": "2f2b26e1-0734-4232-afe0-2dab1cc97b62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_LOG_MODEL=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkn_N6oHpXZP",
        "outputId": "22d081dd-7494-4bf8-bc2a-0e5772c2c1dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_LOG_MODEL=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "if not os.path.exists('./POS-Tagging'):\n",
        "  os.makedirs('./POS-Tagging')\n",
        "os.chdir('./POS-Tagging')\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "sWgYPyZrpZCn",
        "outputId": "19e35019-6120-462d-a1e1-b724d8ed9062"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed0982f4-80a0-423a-a938-15b05bcdaab5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ed0982f4-80a0-423a-a938-15b05bcdaab5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving en_lines-ud-dev.txt to en_lines-ud-dev.txt\n",
            "Saving en_lines-ud-test.txt to en_lines-ud-test.txt\n",
            "Saving en_lines-ud-train.txt to en_lines-ud-train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL_exeMt2Gxn"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def myData(name, percentage):\n",
        "  with open(name, \"r\", encoding=\"utf-8\") as myfile:\n",
        "    my_data = myfile.read()\n",
        "    cropped_data = my_data[:int(len(my_data)*percentage)]\n",
        "\n",
        "  return cropped_data\n",
        "\n",
        "\n",
        "train_data = myData(\"en_lines-ud-train.txt\", 1) # as a second parameter pass the percentage of the data you want\n",
        "dev_data = myData(\"en_lines-ud-dev.txt\", 1)\n",
        "test_data = myData(\"en_lines-ud-test.txt\", 1)"
      ],
      "metadata": {
        "id": "4rakS5Sgpbes"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.add_pipe('sentencizer')\n",
        "\n",
        "# tokenize and lemmatize the data and finally create x-y list\n",
        "def processing(my_data):\n",
        "  \n",
        "  tuples=[]\n",
        "  x = []\n",
        "  y = []\n",
        "  for sent in my_data.sents:\n",
        "    partial_tuple=[]\n",
        "    temp_x = []\n",
        "    temp_y = []\n",
        "    for token in sent:\n",
        "      if token.pos_:\n",
        "        temp_x.append(token.lemma_)\n",
        "        temp_y.append(token.pos_)\n",
        "        partial_tuple.append((token.lemma_, token.pos_))\n",
        "    tuples.append(partial_tuple)\n",
        "    x.append(temp_x)\n",
        "    y.append(temp_y)\n",
        "  return tuples, x, y\n",
        "\n",
        "train_tuples, x_train, y_train = processing(nlp(train_data))\n",
        "dev_tuples, x_dev, y_dev = processing(nlp(dev_data))\n",
        "test_tuples, x_test, y_test = processing(nlp(test_data))"
      ],
      "metadata": {
        "id": "RVYe8x1JpcoY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SToZwv8H2XKw"
      },
      "source": [
        "## Loading Pre-trained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./embeddings'):\n",
        "  os.makedirs('./embeddings')\n",
        "\n",
        "urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip', './embeddings/wiki-news-300d-1M.vec.zip')\n",
        "zip_ref = zipfile.ZipFile('./embeddings/wiki-news-300d-1M.vec.zip', 'r')\n",
        "zip_ref.extractall('./embeddings')\n",
        "zip_ref.close()\n",
        "\n",
        "embs_path = './embeddings/wiki-news-300d-1M.vec'\n",
        "embeddings = KeyedVectors.load_word2vec_format(embs_path, binary=False)"
      ],
      "metadata": {
        "id": "rO9G_7pApdyR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTaWRJJf2gs5"
      },
      "source": [
        "## Data Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPSghOH8V0J2"
      },
      "source": [
        "### Word count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the word_index dictionary with an index for the pad token and an index for the oov words\n",
        "word_index = {'pad': 0, 'oov': 1}\n",
        "\n",
        "# Flatten the list of tuples into a list of words\n",
        "all_words = [word for sentence in train_tuples for word, tag in sentence]\n",
        "\n",
        "# Count the number of occurrences of each word\n",
        "word_counts = Counter(all_words)\n",
        "\n",
        "# Create an entry in the word_index dictionary for each unique word, with the index being the current length of the dictionary\n",
        "for word, count in word_counts.items():\n",
        "    word_index[word] = len(word_index)\n",
        "\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaImCuIPprRR",
        "outputId": "d4da1bb2-2983-4d38-86df-98488853eb26"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pad': 0, 'oov': 1, 'show': 2, 'all': 3, 'about': 4, 'ANSI': 5, 'SQL': 6, 'query': 7, 'mode': 8, 'some': 9, 'of': 10, 'the': 11, 'content': 12, 'in': 13, 'this': 14, 'topic': 15, 'may': 16, 'not': 17, 'be': 18, '\\n': 19, 'applicable': 20, 'to': 21, 'language': 22, '.': 23, 'you': 24, 'can': 25, 'create': 26, 'one': 27, 'two': 28, ':': 29, 'ANSI-89': 30, 'describe': 31, 'traditional': 32, 'Jet': 33, 'syntax': 34, 'conform': 35, 'closely': 36, 'ansi-89': 37, 'Level': 38, '1': 39, 'specification': 40, ',': 41, 'but': 42, 'level': 43, 'compliant': 44, 'certain': 45, 'feature': 46, 'implement': 47, 'and': 48, 'wildcard': 49, 'character': 50, 'visual': 51, 'Basic': 52, 'for': 53, 'Applications': 54, '(': 55, 'VBA': 56, ')': 57, 'ansi-92': 58, 'provide': 59, 'new': 60, 'reserved': 61, 'word': 62, 'rule': 63, 'that': 64, 'enhance': 65, 'your': 66, 'ability': 67, 'filter': 68, 'statement': 69, 'have': 70, 'more': 71, 'Microsoft': 72, 'Access': 73, '2000': 74, 'use': 75, 'adox': 76, 'could': 77, 'programmatically': 78, 'however': 79, 'any': 80, 'visible': 81, 'Database': 82, 'window': 83, 'because': 84, 'there': 85, 'no': 86, 'option': 87, 'set': 88, 'user': 89, 'interface': 90, 'now': 91, '2002': 92, 'through': 93, 'current': 94, 'database': 95, 'as': 96, 'default': 97, 'why': 98, '?': 99, 'want': 100, 'follow': 101, 'reason': 102, 'anticipate': 103, 'upsize': 104, 'application': 105, 'future': 106, 'an': 107, 'project': 108, 'will': 109, 'run': 110, 'with': 111, 'minimal': 112, 'change': 113, 'a': 114, 'Server': 115, 'take': 116, 'advantage': 117, 'find': 118, 'such': 119, 'security': 120, 'setting': 121, 'by': 122, 'GRANT': 123, 'revoke': 124, 'sql': 125, 'distinct': 126, 'aggregate': 127, 'function': 128, 'reference': 129, 'example': 130, 'sum': 131, '-': 132, 'DISTINCT': 133, 'price': 134, 'LIMIT': 135, 'nn': 136, 'ROWS': 137, 'clause': 138, 'limit': 139, 'number': 140, 'row': 141, 'return': 142, 'should': 143, 'avoid': 144, 'mix': 145, 'under': 146, 'different': 147, 'file': 148, 'format': 149, 'disable': 150, ';': 151, 'only': 152, 'available': 153, 'connection': 154, 'store': 155, 'information': 156, 'data': 157, 'source': 158, 'OLE': 159, 'DB': 160, 'datum': 161, 'associate': 162, 'bind': 163, 'or': 164, 'access': 165, 'page': 166, 'when': 167, 'open': 168, 'read': 169, 'link': 170, 'base': 171, 'on': 172, 'connect': 173, 'appropriate': 174, 'Office': 175, 'Data': 176, 'Connection': 177, '.odc': 178, 'HTML': 179, 'xml': 180, 'view': 181, 'edit': 182, 'text': 183, 'editor': 184, 'Universal': 185, 'Link': 186, '.udl': 187, 'standard': 188, 'Links': 189, 'persistent': 190, 'object': 191, 'definition': 192, 'benefit': 193, 'simplify': 194, 'task': 195, 'deploy': 196, 'relate': 197, 'common': 198, 'share': 199, 'single': 200, 'if': 201, 'move': 202, 'copy': 203, 'instead': 204, 'update': 205, 'ConnectionString': 206, 'property': 207, 'each': 208, 'dependent': 209, 'need': 210, 'make': 211, 'point': 212, 'right': 213, 'location': 214, 'choose': 215, 'whether': 216, 'simply': 217, 'without': 218, 'also': 219, 'exist': 220, 'establish': 221, 'between': 222, \"'s\": 223, 'ConnectionFile': 224, 'name': 225, 'time': 226, 'extract': 227, 'either': 228, 'remember': 229, 'other': 230, 'affect': 231, 'break': 232, 'null': 233, 'automatically': 234, 'convert': 235, 'previous': 236, 'version': 237, 'must': 238, 'before': 239, 'it': 240, 'design': 241, 'backup': 242, 'pagefilename.bak.htm': 243, 'at': 244, 'same': 245, 'original': 246, 'revert': 247, 'delete': 248, 'converted': 249, 'rename': 250, 'then': 251, 'include': 252, 'web': 253, 'component': 254, 'PivotTable': 255, 'list': 256, 'chart': 257, 'spreadsheet': 258, 'valid': 259, 'license': 260, 'able': 261, 'those': 262, 'analyze': 263, 'several': 264, 'technique': 265, 'help': 266, 'crosstab': 267, 'calculate': 268, 'restructure': 269, 'easy': 270, 'analysis': 271, 'Crosstab': 272, 'average': 273, 'count': 274, 'type': 275, 'total': 276, 'group': 277, '–': 278, 'down': 279, 'left': 280, 'side': 281, 'datasheet': 282, 'another': 283, 'across': 284, 'top': 285, 'comparison': 286, 'select': 287, '2': 288, 'add': 289, 'interactive': 290, 'table': 291, 'dynamically': 292, 'from': 293, 'within': 294, 'browser': 295, 'layout': 296, 'they': 297, 'field': 298, 'display': 299, 'column': 300, 'area': 301, 'remove': 302, 'sort': 303, 'illustration': 304, 'order': 305, 'View': 306, 'form': 307, 'build': 308, 'report': 309, 'underlie': 310, 'Component': 311, 'so': 312, 'do': 313, 'thing': 314, 'Employees': 315, 'customize': 316, 'PivotChart': 317, 'control': 318, 'how': 319, 'present': 320, 'let': 321, 'compare': 322, 'summarize': 323, 'value': 324, 'element': 325, 'summary': 326, 'subset': 327, 'drop': 328, 'predefine': 329, 'workspace': 330, 'Detail': 331, 'after': 332, 'caption': 333, 'cover': 334, 'up': 335, 'still': 336, 'drag': 337, 'additional': 338, 'unique': 339, 'item': 340, 'detail': 341, 'record': 342, 'Filter': 343, 'allow': 344, 'confine': 345, 'particular': 346, 'part': 347, 'Product': 348, 'product': 349, 'high': 350, 'low': 351, 'multiple': 352, 'close': 353, 'refer': 354, 'inner': 355, 'outer': 356, 'switch': 357, 'Outer': 358, '3': 359, '4': 360, 'repeat': 361, 'long': 362, 'see': 363, 'differently': 364, 'depend': 365, 'series': 366, 'pie': 367, 'consist': 368, 'additionally': 369, 'write': 370, 'style': 371, 'similar': 372, 'document': 373, 'combination': 374, 'like': 375, 'tag': 376, 'html': 377, 'template': 378, 'specific': 379, 'output': 380, 'note': 381, 'require': 382, 'css': 383, 'xsl': 384, 'sheet': 385, 'Internet': 386, 'Explorer': 387, '5': 388, 'later': 389, 'internet': 390, 'collapsible|expandable': 391, 'tree': 392, 'insure': 393, 'XML': 394, 'intranet': 395, 'Website': 396, 'consistent': 397, 'uniform': 398, 'appearance': 399, 'extensible': 400, 'Stylesheet': 401, 'Language': 402, 'Transformation': 403, 'XSLT': 404, 'currently': 405, 'development': 406, 'World': 407, 'Wide': 408, 'Web': 409, 'Consortium': 410, 'W3C': 411, 'support': 412, 'map': 413, 'transform': 414, 'into': 415, 'way': 416, 'presentation': 417, 'target': 418, 'back': 419, 'again': 420, 'typically': 421, 'developer': 422, 'transformation': 423, 'apply': 424, 'during': 425, 'export': 426, 'interpret': 427, 'recognize': 428, 'Service': 429, 'Advertising': 430, 'Protocol': 431, 'SAP': 432, 'custom': 433, 'purchase': 434, 'many': 435, 'construct': 436, 'structure': 437, 'command': 438, 'programming': 439, 'which': 440, 'variable': 441, 'loop': 442, 'iteration': 443, 'conditional': 444, 'give': 445, 'considerable': 446, 'over': 447, 'convenient': 448, 'readily': 449, 'schema': 450, 'both': 451, 'optionally': 452, 'Schema': 453, 'XSD': 454, 'behind': 455, 'Extensible': 456, 'Style': 457, 'XSL': 458, 'process': 459, '.mdb': 460, 'well': 461, 'produce': 462, '.adp': 463, 'just': 464, 'save': 465, '.xml': 466, 'formal': 467, 'what': 468, '.xsd': 469, 'Customers': 470, 'Orders': 471, 'Details': 472, 'customer': 473, 'call': 474, 'ReportML': 475, 'model': 476, '_': 477, 'report.xml': 478, 'addition': 479, 'specify': 480, '.xsl': 481, 'unavailable': 482, '\"': 483, 'develop': 484, 'event': 485, 'attribute': 486, 'mean': 487, 'basic': 488, 'root': 489, 'encompass': 490, 'entire': 491, 'start': 492, 'end': 493, 'match': 494, 'case': 495, 'sensitive': 496, 'corresponding': 497, 'empty': 498, 'denote': 499, 'special': 500, 'shorthand': 501, 'out': 502, 'overlap': 503, 'properly': 504, 'nest': 505, 'reserve': 506, 'themselves': 507, 'portion': 508, 'substitute': 509, 'sequence': 510, 'entity': 511, 'Character': 512, 'Entity': 513, 'where': 514, 'declaration': 515, 'state': 516, 'optional': 517, 'recommend': 518, 'together': 519, 'notice': 520, '&': 521, 'amp;apo': 522, 'apostrophe': 523, 'import': 524, 'receiving': 525, 'purpose': 526, 'misinterpret': 527, 'directly': 528, 'Mom': 529, 'Boston': 530, 'Crab': 531, 'Meat': 532, 'white': 533, 'space': 534, 'throughout': 535, 'readability': 536, 'while': 537, 'consider': 538, 'define': 539, 'Excel': 540, 'familiar': 541, 'work': 542, 'accomplish': 543, 'modify': 544, 'prepare': 545, 'toolbar': 546, 'reflect': 547, 'hide': 548, 'cell': 549, 'might': 550, 'difference': 551, 'program': 552, 'noninteractive': 553, 'copying': 554, 'FrontPage': 555, 'than': 556, 'Word': 557, 'unformatted': 558, 'filtering': 559, 'Filtering': 560, 'autofiltering': 561, 'first': 562, 'Sport': 563, 'Golf': 564, 'sale': 565, 'Quarter': 566, 'Qtr3': 567, 'arrow': 568, 'Field': 569, 'blue': 570, 'black': 571, 'AutoFilter': 572, 'button': 573, 'particularly': 574, 'helpful': 575, 'large': 576, 'amount': 577, 'focus': 578, 'category': 579, 'Region': 580, 'South': 581, 'West': 582, 'region': 583, 'Conditional': 584, 'bottom': 585, 'n': 586, 'three': 587, 'city': 588, 'generate': 589, 'most': 590, 'five': 591, 'least': 592, 'profitable': 593, 'percentage': 594, '25': 595, '%': 596, 'salesperson': 597, 'handle': 598, '40': 599, '10': 600, 'people': 601, 'Chart': 602, 'far': 603, 'narrow': 604, 'selection': 605, 'useful': 606, 'contain': 607, 'axis': 608, 'interior': 609, 'horizontal': 610, 'line': 611, 'upward': 612, 'distance': 613, 'near': 614, 'parallel': 615, 'below': 616, 'remain': 617, 'constant': 618, 'perpendicular': 619, 'above': 620, 'contract': 621, 'downward': 622, 'lengthen': 623, 'exterior': 624, 'away': 625, 'center': 626, 'grid': 627, 'grow': 628, 'towards': 629, 'small': 630, 'grouped': 631, 'press': 632, 'CTRL': 633, 'C.': 634, 'Press': 635, 'v': 636, 'paste': 637, 'vertical': 638, 'halfway': 639, 'locate': 640, 'recreate': 641, 'Null': 642, 'calculation': 643, 'blank': 644, 'their': 645, 'Count': 646, 'Nullvalues': 647, 'nz': 648, 'zero': 649, 'expression': 650, 'installing': 651, 'licensing': 652, 'distribute': 653, 'Components': 654, 'interact': 655, 'interactivity': 656, 'is': 657, 'formatting': 658, 'List': 659, 'protect': 660, 'these': 661, 'environment': 662, 'who': 663, 'print': 664, 'manipulate': 665, 'functionality': 666, \"'ve\": 667, 'instal': 668, 'separately': 669, 'installation': 670, 'designer': 671, 'prompt': 672, 'install': 673, 'configure': 674, 'pointer': 675, 'Resource': 676, 'Kit': 677, 'once': 678, 'computer': 679, 'Users': 680, 'full': 681, 'capability': 682, 'office': 683, 'site': 684, 'organization': 685, 'enterprise': 686, 'agreement': 687, 'download': 688, 'package': 689, '.lpk': 690, 'License': 691, 'Package': 692, 'author': 693, 'Tool': 694, 'MSDN': 695, 'Online': 696, 'mixing': 697, 'compatible': 698, 'decide': 699, 'go': 700, 'runtime': 701, 'error': 702, 'unexpected': 703, 'result': 704, 'range': 705, 'criterion': 706, 'asterisk': 707, 'country': 708, 'u': 709, 'country|region': 710, 'countries|region': 711, 'begin': 712, 'letter': 713, 'percent': 714, 'sign': 715, 'duplicate': 716, 'alias': 717, 'ambiguous': 718, 'problem': 719, 'cause': 720, 'general': 721, 'following': 722, 'prevent': 723, '97': 724, 'retest': 725, 'ensure': 726, 'expect': 727, 'rewrite': 728, 'necessary': 729, 'accidental': 730, 'intentional': 731, 'code': 732, 'changing': 733, 'confusion': 734, 'always': 735, 'search': 736, 'librarie': 737, 'library': 738, 'dialog': 739, 'box': 740, 'References': 741, 'Tools': 742, 'menu': 743, 'Editor': 744, 'specified': 745, 'reflibpath': 746, 'key': 747, 'Windows': 748, 'Registry': 749, 'check': 750, 'existence': 751, 'matching': 752, 'load': 753, 'path': 754, 'folder': 755, 'Msaccess.exe': 756, 'system': 757, 'System': 758, 'System32': 759, 'WINNT': 760, 'PATH': 761, 'Help': 762, 'subfolder': 763, 'perform': 764, 'fix': 765, 'manually': 766, 'procedure': 767, 'enable': 768, 'quickly': 769, 'review': 770, 'enter': 771, 'look': 772, 'Save': 773, 'File': 774, 'carry': 775, 'determine': 776, 'outcome': 777, 'Datasheet': 778, 'arrange': 779, 'implication': 780, 'leave': 781, 'unbound': 782, 'subform': 783, 'subreport': 784, 'appear': 785, 'header': 786, 'footer': 787, 'section': 788, 'Controls': 789, 'Form': 790, 'place': 791, 'outermost': 792, 'Report': 793, 'navigation': 794, 'comment': 795, 'block': 796, 'picture': 797, 'bitmap': 798, 'image': 799, 'AllowAdditions': 800, 'AllowDeletions': 801, 'AllowEdits': 802, 'False': 803, 'ignore': 804, '\\n\\n': 805, 'wrong': 806, 'telephone': 807, 'ring': 808, 'dead': 809, 'night': 810, 'voice': 811, 'ask': 812, 'someone': 813, 'he': 814, 'much': 815, 'think': 816, 'happen': 817, 'would': 818, 'conclude': 819, 'nothing': 820, 'real': 821, 'except': 822, 'chance': 823, 'beginning': 824, 'its': 825, 'consequence': 826, 'turn': 827, 'predetermine': 828, 'come': 829, 'stranger': 830, 'mouth': 831, 'question': 832, 'story': 833, 'itself': 834, 'something': 835, 'tell': 836, 'Quinn': 837, 'little': 838, 'detain': 839, 'we': 840, 'great': 841, 'importance': 842, 'know': 843, 'thirty': 844, 'year': 845, 'old': 846, 'marry': 847, 'father': 848, 'his': 849, 'wife': 850, 'son': 851, 'book': 852, 'precise': 853, 'mystery': 854, 'novel': 855, 'William': 856, 'Wilson': 857, 'rate': 858, 'bring': 859, 'enough': 860, 'money': 861, 'live': 862, 'modestly': 863, 'New': 864, 'York': 865, 'apartment': 866, 'spend': 867, 'six': 868, 'month': 869, 'rest': 870, 'free': 871, 'wish': 872, 'painting': 873, 'movie': 874, 'summer': 875, 'watch': 876, 'baseball': 877, 'television': 878, 'winter': 879, 'opera': 880, 'More': 881, 'anything': 882, 'walk': 883, 'nearly': 884, 'every': 885, 'day': 886, 'rain': 887, 'shine': 888, 'hot': 889, 'cold': 890, 'never': 891, 'really': 892, 'anywhere': 893, 'wherever': 894, 'leg': 895, 'inexhaustible': 896, 'labyrinth': 897, 'endless': 898, 'step': 899, 'matter': 900, 'neighborhood': 901, 'street': 902, 'feeling': 903, 'lose': 904, 'himself': 905, 'feel': 906, 'though': 907, 'movement': 908, 'reduce': 909, 'eye': 910, 'escape': 911, 'obligation': 912, 'else': 913, 'measure': 914, 'peace': 915, 'salutatory': 916, 'emptiness': 917, 'world': 918, 'outside': 919, 'around': 920, 'speed': 921, 'keep': 922, 'impossible': 923, 'dwell': 924, 'very': 925, 'Motion': 926, 'essence': 927, 'act': 928, 'put': 929, 'foot': 930, 'front': 931, 'drift': 932, 'own': 933, 'body': 934, 'wander': 935, 'aimlessly': 936, 'become': 937, 'equal': 938, 'good': 939, 'nowhere': 940, 'realize': 941, 'intention': 942, 'ever': 943, 'past': 944, 'ambitious': 945, 'young': 946, 'man': 947, 'publish': 948, 'poetry': 949, 'play': 950, 'critical': 951, 'essay': 952, 'translation': 953, 'quite': 954, 'abruptly': 955, 'die': 956, 'friend': 957, 'haunt': 958, 'although': 959, 'continue': 960, 'anyone': 961, 'next': 962, 'morning': 963, 'wake': 964, 'early': 965, 'week': 966, 'drink': 967, 'coffee': 968, 'butter': 969, 'toast': 970, 'score': 971, 'paper': 972, 'Mets': 973, 'ninth': 974, 'inning': 975, 'occur': 976, 'appointment': 977, 'even': 978, 'locution': 979, \"'\": 980, 'seem': 981, 'odd': 982, 'Paul': 983, 'Auster': 984, 'person': 985, 'idea': 986, 'nevertheless': 987, 'wear': 988, 'imitation': 989, 'clear': 990, 'breakfast': 991, 'dish': 992, 'toss': 993, 'newspaper': 994, 'couch': 995, 'bathroom': 996, 'shower': 997, 'shave': 998, 'bedroom': 999, 'wrap': 1000, 'towel': 1001, 'closet': 1002, 'pick': 1003, 'clothe': 1004, 'tend': 1005, 'toward': 1006, 'jacket': 1007, 'tie': 1008, 'since': 1009, 'funeral': 1010, 'hang': 1011, 'amidst': 1012, 'debris': 1013, 'wardrobe': 1014, 'dismiss': 1015, 'shirt': 1016, 'too': 1017, 'gray': 1018, 'red': 1019, 'affair': 1020, 'kind': 1021, 'trance': 1022, 'until': 1023, 'hand': 1024, 'doorknob': 1025, 'suspect': 1026, 'I': 1027, 'say': 1028, 'exactly': 1029, 'hour': 1030, 'climb': 1031, 'bus': 1032, '70th': 1033, 'Street': 1034, 'Fifth': 1035, 'Avenue': 1036, 'answer': 1037, 'park': 1038, 'green': 1039, 'sun': 1040, 'sharp': 1041, 'fleeting': 1042, 'shadow': 1043, 'Frick': 1044, 'austere': 1045, 'abandon': 1046, 'moment': 1047, 'Vermeer': 1048, 'Soldier': 1049, 'Young': 1050, 'Girl': 1051, 'Smiling': 1052, 'try': 1053, 'girl': 1054, 'face': 1055, 'exact': 1056, 'position': 1057, 'her': 1058, 'cup': 1059, 'faceless': 1060, 'mind': 1061, 'catch': 1062, 'glimpse': 1063, 'wall': 1064, 'sunlight': 1065, 'pour': 1066, 'surround': 1067, 'cross': 1068, 'eastward': 1069, 'Madison': 1070, 'south': 1071, 'arrive': 1072, 'stand': 1073, 'building': 1074, 'pause': 1075, 'suddenly': 1076, 'anymore': 1077, 'remarkably': 1078, 'calm': 1079, 'everything': 1080, 'already': 1081, 'door': 1082, 'lead': 1083, 'lobby': 1084, 'last': 1085, 'advice': 1086, 'my': 1087, 'woman': 1088, 'throw': 1089, 'off': 1090, 'track': 1091, 'fast': 1092, 'absorb': 1093, 'presence': 1094, 'she': 1095, 'impression': 1096, 'talk': 1097, 'force': 1098, 'respond': 1099, 'therefore': 1100, 'ground': 1101, 'fall': 1102, 'manage': 1103, 'piece': 1104, 'encounter': 1105, 'memory': 1106, 'tendency': 1107, 'subvert': 1108, 'sure': 1109, 'perhaps': 1110, 'height': 1111, 'hip': 1112, 'touch': 1113, 'wide': 1114, 'voluptuous': 1115, 'dark': 1116, 'hair': 1117, 'self': 1118, 'vaguely': 1119, 'seductive': 1120, 'dress': 1121, 'lipstick': 1122, 'Mr': 1123, 'tentative': 1124, 'smile': 1125, 'questioning': 1126, 'tilt': 1127, 'head': 1128, 'Virginia': 1129, 'Stillman': 1130, 'Peter': 1131, 'wait': 1132, 'eight': 1133, \"o'clock\": 1134, 'ten': 1135, 'glance': 1136, 'frantic': 1137, 'explain': 1138, 'threshold': 1139, 'brain': 1140, 'shut': 1141, 'somehow': 1142, 'beyond': 1143, 'loom': 1144, 'blur': 1145, 'room': 1146, 'richly': 1147, 'furnish': 1148, 'numerous': 1149, 'art': 1150, 'silver': 1151, 'ashtray': 1152, 'elaborately': 1153, 'frame': 1154, 'sit': 1155, 'sofa': 1156, 'alone': 1157, 'living': 1158, 'Mrs.': 1159, 'husband': 1160, 'surely': 1161, 'minute': 1162, 'light': 1163, 'almost': 1164, 'noon': 1165, 'consult': 1166, 'smell': 1167, 'perfume': 1168, 'hover': 1169, 'imagine': 1170, 'Max': 1171, 'Work': 1172, 'cigarette': 1173, 'blow': 1174, 'smoke': 1175, 'please': 1176, 'gust': 1177, 'disperse': 1178, 'hear': 1179, 'sound': 1180, 'entirely': 1181, 'blond': 1182, 'child': 1183, 'uncannily': 1184, 'thought': 1185, 'vanish': 1186, 'velvet': 1187, 'armchair': 1188, 'opposite': 1189, 'seat': 1190, 'nor': 1191, 'acknowledge': 1192, 'attention': 1193, 'immobility': 1194, 'manner': 1195, 'speak': 1196, 'phone': 1197, 'machine': 1198, 'fitful': 1199, 'alternate': 1200, 'slow': 1201, 'rapid': 1202, 'gesture': 1203, 'rigid': 1204, 'yet': 1205, 'expressive': 1206, 'operation': 1207, 'lie': 1208, 'relearn': 1209, 'motion': 1210, 'conscious': 1211, 'submovement': 1212, 'flow': 1213, 'spontaneity': 1214, 'marionette': 1215, 'string': 1216, 'White': 1217, 'neck': 1218, 'pant': 1219, 'shoe': 1220, 'sock': 1221, 'against': 1222, 'pallor': 1223, 'skin': 1224, 'flaxen': 1225, 'thinness': 1226, 'effect': 1227, 'transparent': 1228, 'vein': 1229, 'milky': 1230, 'dissolve': 1231, 'mixture': 1232, 'sky': 1233, 'cloud': 1234, 'address': 1235, 'silent': 1236, 'settle': 1237, 'slowly': 1238, 'chair': 1239, 'meet': 1240, 'invisible': 1241, 'blind': 1242, 'possible': 1243, 'study': 1244, 'recognition': 1245, 'flicker': 1246, 'hold': 1247, 'stare': 1248, 'dumbly': 1249, 'pass': 1250, 'yes': 1251, 'thank': 1252, 'course': 1253, 'here': 1254, 'corner': 1255, '72nd': 1256, 'wave': 1257, 'cab': 1258, 'car': 1259, 'rattle': 1260, 'Side': 1261, 'wonder': 1262, 'air': 1263, 'house': 1264, 'hungry': 1265, 'eat': 1266, 'strange': 1267, 'correct': 1268, 'fourteen': 1269, 'stay': 1270, 'four': 1271, 'shrug': 1272, 'discrepancy': 1273, 'learn': 1274, 'often': 1275, 'retrace': 1276, 'along': 1277, '107th': 1278, 'Broadway': 1279, 'uptown': 1280, 'suitable': 1281, 'bar': 1282, 'appeal': 1283, 'tonight': 1284, 'boozy': 1285, 'chatter': 1286, 'normally': 1287, 'welcome': 1288, '112th': 1289, 'Heights': 1290, 'Luncheonette': 1291, 'brightly': 1292, 'dreary': 1293, 'rack': 1294, 'girlie': 1295, 'magazine': 1296, 'stationery': 1297, 'supply': 1298, 'patron': 1299, 'Formica': 1300, 'counter': 1301, 'swivel': 1302, 'stool': 1303, 'tall': 1304, 'puerto': 1305, 'rican': 1306, 'cardboard': 1307, 'chef': 1308, 'hat': 1309, 'job': 1310, 'food': 1311, 'mainly': 1312, 'gristle': 1313, 'stud': 1314, 'hamburger': 1315, 'patty': 1316, 'bland': 1317, 'sandwich': 1318, 'pale': 1319, 'tomato': 1320, 'wilt': 1321, 'lettuce': 1322, 'milkshake': 1323, 'egg': 1324, 'cream': 1325, 'bun': 1326, 'ensconce': 1327, 'cash': 1328, 'register': 1329, 'boss': 1330, 'bald': 1331, 'curly': 1332, 'concentration': 1333, 'camp': 1334, 'tattoe': 1335, 'forearm': 1336, 'lord': 1337, 'domain': 1338, 'pipe': 1339, 'cigar': 1340, 'impassively': 1341, 'owl': 1342, 'edition': 1343, 'Daily': 1344, 'News': 1345, 'deserted': 1346, 'seven': 1347, 'buttered': 1348, 'roll': 1349, 'lap': 1350, 'glass': 1351, 'hotel': 1352, 'brown': 1353, 'overcoat': 1354, 'fashioned': 1355, 'carpet': 1356, 'bag': 1357, 'routine': 1358, 'vary': 1359, 'advance': 1360, 'sometimes': 1361, 'mere': 1362, 'increment': 1363, 'pausing': 1364, 'weigh': 1365, 'among': 1366, 'difficult': 1367, 'briskly': 1368, 'stop': 1369, 'shuffle': 1370, 'strain': 1371, 'rhythm': 1372, 'disrupt': 1373, 'hare': 1374, 'pursuit': 1375, 'tortoise': 1376, 'remind': 1377, 'dutifully': 1378, 'notebook': 1379, 'meaning': 1380, 'elude': 1381, 'narrowly': 1382, 'circumscribed': 1383, 'bound': 1384, 'north': 1385, 'Riverside': 1386, 'Park': 1387, 'east': 1388, 'Amsterdam': 1389, 'haphazard': 1390, 'journey': 1391, 'itinerary': 1392, 'border': 1393, 'precision': 1394, 'baffle': 1395, 'respect': 1396, 'aimless': 1397, 'permanently': 1398, 'pavement': 1399, 'indeed': 1400, 'stoop': 1401, 'examine': 1402, 'archeologist': 1403, 'inspect': 1404, 'shard': 1405, 'prehistoric': 1406, 'ruin': 1407, 'occasionally': 1408, 'pore': 1409, 'onto': 1410, 'sidewalk': 1411, 'gently': 1412, 'inside': 1413, 'reach': 1414, 'coat': 1415, 'pocket': 1416, 'having': 1417, 'complete': 1418, 'collect': 1419, 'valueless': 1420, 'broken': 1421, 'discard': 1422, 'stray': 1423, 'bit': 1424, 'junk': 1425, 'collapsible': 1426, 'umbrella': 1427, 'shorn': 1428, 'material': 1429, 'sever': 1430, 'rubber': 1431, 'doll': 1432, 'glove': 1433, 'shatter': 1434, 'bulb': 1435, 'sogged': 1436, 'shred': 1437, 'torn': 1438, 'photograph': 1439, 'anonymous': 1440, 'machinery': 1441, 'sundry': 1442, 'clump': 1443, 'flotsam': 1444, 'identify': 1445, 'fact': 1446, 'scavenging': 1447, 'seriously': 1448, 'intrigue': 1449, 'observe': 1450, 'stupidly': 1451, 'surface': 1452, 'secret': 1453, 'accumulate': 1454, 'plot': 1455, 'various': 1456, 'stratagem': 1457, 'steal': 1458, 'somewhere': 1459, 'meal': 1460, 'bump': 1461, 'mumble': 1462, 'apology': 1463, 'neither': 1464, 'happy': 1465, 'sad': 1466, 'twice': 1467, 'scavenge': 1468, 'haul': 1469, 'unusually': 1470, 'middle': 1471, 'remerge': 1472, 'few': 1473, 'methodically': 1474, 'macadam': 1475, 'footpath': 1476, 'thrash': 1477, 'bush': 1478, 'stick': 1479, 'quest': 1480, 'abate': 1481, 'greenery': 1482, 'stone': 1483, 'twig': 1484, 'dry': 1485, 'dog': 1486, 'turd': 1487, 'sniff': 1488, 'carefully': 1489, 'afternoon': 1490, 'lunch': 1491, 'bench': 1492, 'gaze': 1493, 'Hudson': 1494, 'warm': 1495, 'sprawl': 1496, 'grass': 1497, 'asleep': 1498, 'darkness': 1499, 'dinner': 1500, 'Apollo': 1501, 'Coffee': 1502, 'Shop': 1503, '97th': 1504, 'contact': 1505, 'confirm': 1506, 'whom': 1507, 'home': 1508, 'essential': 1509, 'involved': 1510, 'cut': 1511, 'embark': 1512, 'meaningless': 1513, 'merely': 1514, 'bide': 1515, 'lull': 1516, 'lethargy': 1517, 'strike': 1518, 'assume': 1519, 'aware': 1520, 'unlikely': 1521, 'discreet': 1522, 'blend': 1523, 'traffic': 1524, 'drastic': 1525, 'trouble': 1526, 'discover': 1527, 'watcher': 1528, 'certainty': 1529, 'replace': 1530, 'situation': 1531, 'comfort': 1532, 'believe': 1533, 'belief': 1534, 'waste': 1535, 'actually': 1536, 'interpretation': 1537, 'knowledge': 1538, 'accept': 1539, 'article': 1540, 'faith': 1541, 'occupy': 1542, 'excursion': 1543, 'teach': 1544, 'understand': 1545, 'connectedness': 1546, 'reversal': 1547, 'thus': 1548, 'usurp': 1549, 'sovereignty': 1550, 'inwardness': 1551, 'flood': 1552, 'external': 1553, 'drown': 1554, 'exert': 1555, 'degree': 1556, 'fit': 1557, 'despair': 1558, 'Wandering': 1559, 'mindlessness': 1560, 'stagger': 1561, 'blindman': 1562, 'spot': 1563, 'privilege': 1564, 'deny': 1565, 'oblige': 1566, 'concentrate': 1567, 'soon': 1568, 'thereafter': 1569, 'suit': 1570, 'constantly': 1571, 'danger': 1572, 'quicken': 1573, 'pace': 1574, 'crash': 1575, 'guard': 1576, 'mishap': 1577, 'devise': 1578, 'method': 1579, 'deceleration': 1580, 'Daniel': 1581, 'comfortably': 1582, 'stricture': 1583, 'husk': 1584, 'speck': 1585, 'punctuation': 1586, 'mark': 1587, 'brick': 1588, 'life': 1589, 'nightmare': 1590, 'probability': 1591, 'clue': 1592, 'backtrack': 1593, 'predict': 1594, 'theory': 1595, 'behavior': 1596, 'obscure': 1597, 'hint': 1598, 'extreme': 1599, 'suggest': 1600, 'get': 1601, 'unlisted': 1602, 'eliminate': 1603, 'disturbing': 1604, 'temporarily': 1605, 'fail': 1606, 'altogether': 1607, 'bad': 1608, 'identity': 1609, 'important': 1610, 'circumstance': 1611, 'hiring': 1612, 'grant': 1613, 'fill': 1614, 'leap': 1615, 'detective': 1616, 'Stillmans': 1617, 'clean': 1618, 'breast': 1619, 'forgive': 1620, 'yellow': 1621, 'Detective': 1622, 'Agency': 1623, 'listing': 1624, 'Manhattan': 1625, 'Drive': 1626, 'mention': 1627, 'agency': 1628, 'necessarily': 1629, 'advertise': 1630, 'dial': 1631, 'conversation': 1632, 'risk': 1633, 'brush': 1634, 'west': 1635, 'tiny': 1636, 'shift': 1637, 'seep': 1638, 'half': 1639, 'thread': 1640, 'whatever': 1641, 'accustomed': 1642, 'freedom': 1643, 'shuffling': 1644, 'spell': 1645, '116th': 1646, '119th': 1647, 'Streets': 1648, 'Church': 1649, 'Grant': 1650, 'Tomb': 1651, 'polished': 1652, 'bourgeois': 1653, 'sobriety': 1654, 'eleventh': 1655, 'floor': 1656, 'buzzer': 1657, 'intercom': 1658, 'push': 1659, 'ride': 1660, 'elevator': 1661, 'fellow': 1662, 'mid': 1663, 'rumpled': 1664, 'beard': 1665, 'thumb': 1666, 'finger': 1667, 'uncapped': 1668, 'fountain': 1669, 'pen': 1670, 'poise': 1671, 'writing': 1672, 'surprised': 1673, 'standing': 1674, 'tentatively': 1675, 'polite': 1676, 'tone': 1677, 'muster': 1678, 'sorry': 1679, 'disturb': 1680, 'apologize': 1681, 'hardly': 1682, 'myself': 1683, 'honest': 1684, 'complicated': 1685, 'afraid': 1686, 'abstractedly': 1687, 'mutter': 1688, 'hard': 1689, 'dredge': 1690, 'poet': 1691, 'poem': 1692, 'ago': 1693, 'title': 1694, 'Unfinished': 1695, 'Business': 1696, 'hope': 1697, 'pleasant': 1698, 'oddly': 1699, 'shape': 1700, 'corridor': 1701, 'cluttered': 1702, 'everywhere': 1703, 'artist': 1704, 'toy': 1705, 'scatter': 1706, 'truck': 1707, 'bear': 1708, 'monster': 1709, 'fray': 1710, 'upholstered': 1711, 'kitchen': 1712, 'fetch': 1713, 'beer': 1714, 'bottle': 1715, 'wooden': 1716, 'crate': 1717, 'serve': 1718, 'literary': 1719, 'successful': 1720, 'ploy': 1721, 'mirror': 1722, 'Don': 1723, 'Quixote': 1724, 'madness': 1725, 'absurd': 1726, 'ludicrous': 1727, 'delusion': 1728, 'finally': 1729, 'twist': 1730, 'mad': 1731, 'pretend': 1732, 'orchestrate': 1733, 'whole': 1734, 'preoccupy': 1735, 'posterity': 1736, 'accurately': 1737, 'chronicler': 1738, 'adventure': 1739, 'imply': 1740, 'beforehand': 1741, 'Sancho': 1742, 'Panza': 1743, 'faithful': 1744, 'squire': 1745, 'role': 1746, 'destine': 1747, 'engineer': 1748, 'Benengali': 1749, 'quartet': 1750, 'probably': 1751, 'translate': 1752, 'arabic': 1753, 'manuscript': 1754, 'Spanish': 1755, 'skilled': 1756, 'disguise': 1757, 'darken': 1758, 'don': 1759, 'Moor': 1760, 'scene': 1761, 'marketplace': 1762, 'Toledo': 1763, 'cervante': 1764, 'hire': 1765, 'decipher': 1766, 'beauty': 1767, 'tranquil': 1768, 'engage': 1769, 'elaborate': 1770, 'hoax': 1771, 'interesting': 1772, 'opinion': 1773, 'conduct': 1774, 'experiment': 1775, 'test': 1776, 'gullibility': 1777, 'utmost': 1778, 'conviction': 1779, 'spew': 1780, 'nonsense': 1781, 'windmill': 1782, 'knight': 1783, 'barber': 1784, 'basin': 1785, 'helmet': 1786, 'puppet': 1787, 'persuade': 1788, 'agree': 1789, 'extent': 1790, 'tolerate': 1791, 'blasphemy': 1792, 'amusement': 1793, 'obvious': 1794, 'proof': 1795, 'highly': 1796, 'amusing': 1797, 'amuse': 1798, 'lean': 1799, 'ironic': 1800, 'pleaure': 1801, 'obviously': 1802, 'enjoy': 1803, 'nature': 1804, 'pleasure': 1805, 'soundless': 1806, 'laughter': 1807, 'joke': 1808, 'short': 1809, 'punchline': 1810, 'generalize': 1811, 'mirth': 1812, 'response': 1813, 'interrupt': 1814, 'clattering': 1815, 'slamming': 1816, 'burst': 1817, 'perk': 1818, 'rise': 1819, 'excuse': 1820, 'hallway': 1821, 'staccato': 1822, 'shrapnel': 1823, 'basso': 1824, 'rumble': 1825, 'guffaw': 1826, 'daddy': 1827, '!': 1828, 'perfectly': 1829, 'okay': 1830, 'hall': 1831, 'shoot': 1832, 'sight': 1833, 'haired': 1834, 'boy': 1835, 'rapidly': 1836, 'withdraw': 1837, 'shyness': 1838, 'faint': 1839, 'hello': 1840, 'yoyo': 1841, 'exaggerated': 1842, 'pantomine': 1843, 'dunno': 1844, 'Siri': 1845, 'breathing': 1846, 'beside': 1847, 'plastic': 1848, 'artifact': 1849, 'age': 1850, 'fasten': 1851, 'flute': 1852, 'whistling': 1853, 'descend': 1854, 'spark': 1855, 'gasp': 1856, 'dangle': 1857, 'philosopher': 1858, 'rewinde': 1859, 'spool': 1860, 'attempt': 1861, 'brief': 1862, 'thin': 1863, 'blonde': 1864, 'radiantly': 1865, 'beautiful': 1866, 'energy': 1867, 'happiness': 1868, 'taunt': 1869, 'envy': 1870, 'rage': 1871, 'lacerate': 1872, 'pity': 1873, 'spout': 1874, 'drivel': 1875, 'yoyos': 1876, 'ham': 1877, 'omelette': 1878, 'pray': 1879, 'deliverance': 1880, 'laugh': 1881, 'Everybody': 1882, 'shout': 1883, 'spread': 1884, 'arm': 1885, 'spin': 1886, 'gyroscope': 1887, 'glad': 1888, 'extend': 1889, 'shake': 1890, 'uncanny': 1891, 'slenderness': 1892, 'bone': 1893, 'norwegian': 1894, 'Norway': 1895, 'indirectly': 1896, 'Northfield': 1897, 'Minnesota': 1898, 'collapse': 1899, 'send': 1900, 'stride': 1901, 'June': 1902, 'second': 1903, 'tomorrow': 1904, 'third': 1905, 'fourth': 1906, 'debate': 1907, 'forget': 1908, 'trip': 1909, 'Paris': 1910, 'curious': 1911, 'shade': 1912, 'dinginess': 1913, 'laspe': 1914, 'fruit': 1915, 'paint': 1916, 'exhaust': 1917, 'encroach': 1918, 'soot': 1919, 'plaster': 1920, 'crumble': 1921, 'dirty': 1922, 'wash': 1923, 'water': 1924, 'sink': 1925, 'lather': 1926, 'blade': 1927, 'scrape': 1928, 'unpleasant': 1929, 'fart': 1930, 'bowl': 1931, 'cornflake': 1932, 'argument': 1933, 'etiquette': 1934, 'fair': 1935, 'disappear': 1936, 'acceptable': 1937, 'busy': 1938, 'dialing': 1939, 'waiting': 1940, 'operator': 1941, 'charge': 1942, 'cent': 1943, 'crackling': 1944, 'wire': 1945, 'further': 1946, 'possibility': 1947, 'hook': 1948, 'innings': 1949, 'game': 1950, 'St.': 1951, 'Louis': 1952, 'infield': 1953, 'sacrifice': 1954, 'fly': 1955, 'double': 1956, 'Youngblood': 1957, 'care': 1958, 'commercial': 1959, 'twentieth': 1960, 'desk': 1961, 'steadily': 1962, 'bother': 1963, 'signal': 1964, 'slam': 1965, 'receiver': 1966, 'crack': 1967, 'bed': 1968, 'dream': 1969, 'strict': 1970, 'flight': 1971, 'Israel': 1972, 'frisk': 1973, 'electronic': 1974, 'hoop': 1975, 'fore': 1976, 'aft': 1977, 'luggage': 1978, 'patient': 1979, 'visibility': 1980, 'queue': 1981, 'poor': 1982, 'Hasidim': 1983, 'broad': 1984, 'sidelock': 1985, 'fringe': 1986, 'Heathrow': 1987, 'restless': 1988, 'rush': 1989, 'gesticulate': 1990, 'exclaim': 1991, 'jump': 1992, 'hundred': 1993, 'attend': 1994, 'circumcision': 1995, 'firstborn': 1996, 'spiritual': 1997, 'leader': 1998, 'Belzer': 1999, 'Rabbi': 2000, '747': 2001, 'Alexandra': 2002, 'enfilade': 2003, 'hairy': 2004, 'ambush': 2005, 'foreign': 2006, 'lock': 2007, 'childhood': 2008, 'revisit': 2009, 'tallith': 2010, 'katan': 2011, 'scapular': 2012, 'mine': 2013, 'scrap': 2014, 'calico': 2015, 'whereas': 2016, 'theirs': 2017, 'linen': 2018, 'God': 2019, 'instruct': 2020, 'Moses': 2021, 'bid': 2022, 'garment': 2023, 'thousand': 2024, 'our': 2025, 'rear': 2026, 'aircraft': 2027, 'yiddish': 2028, 'certainly': 2029, 'dislike': 2030, 'rather': 2031, 'Hasid': 2032, 'late': 2033, 'twenty': 2034, 'pimply': 2035, 'goggle': 2036, 'underlip': 2037, 'extrude': 2038, 'civilized': 2039, 'impulse': 2040, 'inferior': 2041, 'permit': 2042, 'unrelated': 2043, 'communicate': 2044, 'deal': 2045, 'hearted': 2046, 'visibly': 2047, 'vividly': 2048, 'dodge': 2049, 'aisle': 2050, 'visit': 2051, 'impatiently': 2052, 'lavatory': 2053, 'amiable': 2054, 'geese': 2055, 'pay': 2056, 'English': 2057, 'stewardess': 2058, 'furious': 2059, 'hostess': 2060, 'receive': 2061, 'cry': 2062, 'irritation': 2063, 'retreat': 2064, 'merry': 2065, 'minded': 2066, 'exulting': 2067, 'gentile': 2068, 'uniformed': 2069, 'female': 2070, 'attendant': 2071, 'exotic': 2072, 'bediener': 2073, 'bodyless': 2074, 'difficulty': 2075, 'kosher': 2076, 'big': 2077, 'british': 2078, 'affront': 2079, 'bosom': 2080, 'indignation': 2081, 'Rome': 2082, 'Amused': 2083, 'chicken': 2084, 'kid': 2085, 'British': 2086, 'Airways': 2087, 'chill': 2088, 'death': 2089, 'upon': 2090, 'exercise': 2091, 'recoil': 2092, 'tray': 2093, 'Yiddish': 2094, 'offend': 2095, 'slap': 2096, 'Jew': 2097, 'awful': 2098, 'womenfolk': 2099, 'pack': 2100, 'beef': 2101, 'Jewish': 2102, 'Rumanian': 2103, 'shock': 2104, 'jewish': 2105, 'upbringing': 2106, 'favor': 2107, 'condition': 2108, 'trephena': 2109, 'promise': 2110, 'duty': 2111, 'listen': 2112, 'proposition': 2113, 'prepared': 2114, 'fifteen': 2115, 'dollar': 2116, 'generous': 2117, 'earn': 2118, 'hasidic': 2119, 'sweater': 2120, 'factory': 2121, 'Jersey': 2122, 'rabbi': 2123, 'Jerusalem': 2124, 'expensive': 2125, 'disagreeable': 2126, 'guiltily': 2127, 'appetite': 2128, 'spoil': 2129, 'prayer': 2130, 'fervent': 2131, 'discomfiture': 2132, 'Minchah': 2133, 'service': 2134, 'rock': 2135, 'stretch': 2136, 'Jews': 2137, 'lively': 2138, 'childlike': 2139, 'cheerful': 2140, 'natural': 2141, 'love': 2142, 'costume': 2143, 'sell': 2144, 'outsider': 2145, 'learning': 2146, 'lecture': 2147, 'Hebrew': 2148, 'University': 2149, 'mathematician': 2150, 'puzzled': 2151, 'astonish': 2152, 'innocent': 2153, 'ignorant': 2154, 'Le': 2155, 'Monde': 2156, 'gloat': 2157, 'July': 2158, '12': 2159, 'raid': 2160, 'accuse': 2161, 'reactionary': 2162, 'Rhodesia': 2163, 'Africa': 2164, 'demonstration': 2165, 'military': 2166, 'superiority': 2167, 'western': 2168, 'upset': 2169, 'balance': 2170, 'rich': 2171, 'climate': 2172, 'treat': 2173, 'Third': 2174, 'partner': 2175, 'rhodesian': 2176, 'Africans': 2177, 'Israelis': 2178, 'champagne': 2179, 'european': 2180, 'approval': 2181, 'endanger': 2182, 'plan': 2183, 'France': 2184, 'international': 2185, 'rescue': 2186, 'wisecrack': 2187, 'Amin': 2188, 'speech': 2189, 'Port': 2190, 'OAS': 2191, 'provoke': 2192, 'applause': 2193, 'delegate': 2194, 'hostage': 2195, 'comfortable': 2196, 'explosive': 2197, 'weep': 2198, 'beg': 2199, 'everybody': 2200, 'David': 2201, 'Shahar': 2202, 'whose': 2203, 'chest': 2204, 'deep': 2205, 'breath': 2206, 'advise': 2207, 'nourishing': 2208, 'sage': 2209, 'delicacy': 2210, 'Dead': 2211, 'Sea': 2212, 'bulbous': 2213, 'roof': 2214, 'color': 2215, 'deadness': 2216, 'melting': 2217, 'human': 2218, 'weight': 2219, 'intelligible': 2220, 'metaphysical': 2221, 'universe': 2222, 'openness': 2223, 'rockjumbled': 2224, 'valley': 2225, 'elsewhere': 2226, 'disintegrate': 2227, 'mingle': 2228, 'Mishkenot': 2229, \"Sha'ananim\": 2230, 'slope': 2231, 'Mount': 2232, 'Zion': 2233, 'Old': 2234, 'City': 2235, 'Gai': 2236, 'Hinnom': 2237, 'Gehenna': 2238, 'tradition': 2239, 'worshiper': 2240, 'Moloch': 2241, 'ancient': 2242, 'Karaite': 2243, 'burial': 2244, 'mingling': 2245, 'yourself': 2246, 'queerly': 2247, 'nerve': 2248, 'dust': 2249, 'grind': 2250, 'geologically': 2251, 'dolomite': 2252, 'clay': 2253, 'hoarier': 2254, 'Gray': 2255, 'Bloom': 2256, 'Joyce': 2257, 'Ulysses': 2258, 'brilliant': 2259, 'massive': 2260, 'crumpled': 2261, 'mountain': 2262, 'exhaustion': 2263, 'atmosphere': 2264, 'american': 2265, 'commonplace': 2266, 'true': 2267, 'soul': 2268, 'municipality': 2269, 'Wolfson': 2270, 'Foundation': 2271, 'London': 2272, 'planting': 2273, 'garden': 2274, 'arab': 2275, 'kick': 2276, 'soccer': 2277, 'ball': 2278, 'East': 2279, 'toughie': 2280, 'stiffen': 2281, 'shoulder': 2282, 'practice': 2283, 'dangerous': 2284, 'loiterer': 2285, 'muscular': 2286, 'ornament': 2287, 'nag': 2288, 'horseshoe': 2289, 'bridle': 2290, 'writer': 2291, 'thoughtful': 2292, 'tout': 2293, 'tombe': 2294, 'cavern': 2295, 'niche': 2296, 'corpse': 2297, 'lay': 2298, 'fender': 2299, 'rust': 2300, 'century': 2301, 'metal': 2302, 'absolutely': 2303, 'Prophet': 2304, 'Jeremiah': 2305, 'Elie': 2306, 'Kedourie': 2307, 'Political': 2308, 'Memoirs': 2309, 'unknown': 2310, 'diplomacy': 2311, 'forty': 2312, 'Middle': 2313, 'United': 2314, 'States': 2315, 'rely': 2316, 'heavily': 2317, 'management': 2318, 'consultant': 2319, 'public': 2320, 'relation': 2321, 'expert': 2322, 'firm': 2323, 'Booz': 2324, 'Allen': 2325, 'amp': 2326, 'Hamilton': 2327, 'lend': 2328, 'specialist': 2329, 'Miles': 2330, 'Copeland': 2331, 'State': 2332, 'Department': 2333, '1955': 2334, 'member': 2335, 'Policy': 2336, 'Planning': 2337, 'Committee': 2338, 'main': 2339, 'friendship': 2340, 'ourselves': 2341, 'Nasser': 2342, '1947': 2343, 'Damascus': 2344, 'unofficial': 2345, 'syrian': 2346, 'probe': 2347, 'liberalize': 2348, 'political': 2349, 'democracy': 2350, 'Americans': 2351, 'fight': 2352, 'rig': 2353, 'election': 2354, 'Syria': 2355, 'corruption': 2356, 'despite': 2357, 'power': 2358, 'Frustrated': 2359, 'heavy': 2360, 'American': 2361, 'Minister': 2362, 'encourage': 2363, 'coup': 2364, \"d'etat\": 2365, 'bizarre': 2366, 'ambassador': 2367, 'minister': 2368, 'genuine': 2369, 'revolution': 2370, 'overthrow': 2371, 'landowner': 2372, 'crook': 2373, 'politician': 2374, 'elite': 2375, 'underpin': 2376, 'ruler': 2377, 'buttress': 2378, 'population': 2379, 'presumably': 2380, 'approve': 2381, 'legitimate': 2382, 'aim': 2383, 'whoever': 2384, 'equivalent': 2385, 'philosophical': 2386, 'Egypt': 2387, 'Kermit': 2388, 'Roosevelt': 2389, 'CIA': 2390, 'officer': 2391, 'involve': 2392, 'conspiracy': 2393, '22': 2394, '1952': 2395, 'regime': 2396, 'populace': 2397, 'literate': 2398, 'stable': 2399, 'class': 2400, 'sufficient': 2401, 'identification': 2402, 'local': 2403, 'ideal': 2404, 'truly': 2405, 'indigenous': 2406, 'democratic': 2407, 'institution': 2408, 'glide': 2409, 'realm': 2410, 'loan': 2411, 'egyptian': 2412, 'government': 2413, 'James': 2414, 'Eichelberger': 2415, 'scientist': 2416, 'account': 2417, 'executive': 2418, 'J': 2419, 'Walter': 2420, 'Thompson': 2421, 'advertising': 2422, 'Cairo': 2423, 'confidant': 2424, 'policy': 2425, 'Arabic': 2426, 'staff': 2427, 'Power': 2428, 'Problems': 2429, 'Revolutionary': 2430, 'Government': 2431, 'forth': 2432, 'accord': 2433, 'final': 2434, 'Zakaria': 2435, 'Mohieddin': 2436, 'reasonable': 2437, 'deputy': 2438, 'intelligence': 2439, 'analyst': 2440, 'C.I.A.': 2441, 'former': 2442, 'police': 2443, 'politisize': 2444, 'partisan': 2445, 'paramilitary': 2446, 'revolutionary': 2447, 'Leninism': 2448, 'neat': 2449, 'ice': 2450, 'bitter': 2451, 'safely': 2452, 'Jefferson': 2453, 'liberty': 2454, 'refresh': 2455, 'blood': 2456, 'patriot': 2457, 'tyrant': 2458, 'romantic': 2459, 'alive': 2460, 'prime': 2461, 'client': 2462, 'pure': 2463, 'professional': 2464, 'understanding': 2465, 'mass': 2466, 'cadre': 2467, 'shocking': 2468, 'suspicion': 2469, 'collaborator': 2470, 'seizure': 2471, 'solve': 2472, 'social': 2473, 'befriend': 2474, 'increase': 2475, 'strengthen': 2476, 'America': 2477, 'universal': 2478, 'equality': 2479, 'illusionless': 2480, 'tough': 2481, 'guy': 2482, 'scale': 2483, 'mover': 2484, 'shaker': 2485, 'shaper': 2486, 'destiny': 2487, 'surrender': 2488, 'fantasy': 2489, 'omnipotence': 2490, 'nation': 2491, 'plenipotentiary': 2492, 'confidently': 2493, 'Bolshevik': 2494, 'fire': 2495, 'doubt': 2496, 'resource': 2497, 'science': 2498, 'lesson': 2499, 'tyranny': 2500, 'puzzling': 2501, 'imparting': 2502, 'interest': 2503, 'contribute': 2504, 'welfare': 2505, 'intriguing': 2506, 'whence': 2507, 'passion': 2508, 'functionary': 2509, 'Fury': 2510, 'Compson': 2511, 'belong': 2512, 'e': 2513, 'E': 2514, 'Cummings': 2515, '1910': 2516, 'land': 2517, 'kike': 2518, 'wop': 2519, 'buy': 2520, 'italian': 2521, 'flinch': 2522, 'Chicago': 2523, 'Faulkner': 2524, 'guilty': 2525, 'offense': 2526, 'borrow': 2527, 'Ben': 2528, 'Gurion': 2529, 'illusion': 2530, 'goyish': 2531, 'emigrate': 2532, 'liberal': 2533, 'signify': 2534, 'govern': 2535, 'severe': 2536, 'leftist': 2537, 'critic': 2538, 'exception': 2539, 'Left': 2540, 'detractor': 2541, 'abuse': 2542, 'less': 2543, 'immigrant': 2544, 'North': 2545, 'Orient': 2546, 'denounce': 2547, 'corrupt': 2548, 'Levantine': 2549, 'theocratic': 2550, 'Gossip': 2551, 'trace': 2552, 'israeli': 2553, 'financial': 2554, 'swindle': 2555, 'observant': 2556, 'Orthodox': 2557, 'Ashkenazi': 2558, 'unimaginative': 2559, 'Rabin': 2560, 'lack': 2561, 'stature': 2562, 'terrible': 2563, 'generation': 2564, 'hostile': 2565, 'african': 2566, 'asian': 2567, 'oriental': 2568, 'blame': 2569, 'baksheesh': 2570, 'mentality': 2571, 'intellectual': 2572, 'quality': 2573, 'deplorable': 2574, 'phrase': 2575, 'deteriorate': 2576, 'society': 2577, 'immediately': 2578, 'paradox': 2579, 'Jakov': 2580, 'Lind': 2581, 'quote': 2582, 'hell': 2583, 'await': 2584, 'personal': 2585, 'dissatisfaction': 2586, 'mediocre': 2587, 'inordinate': 2588, 'demand': 2589, 'uncomfortable': 2590, 'Christianity': 2591, 'persistency': 2592, 'Jacques': 2593, 'Maritain': 2594, 'characterize': 2595, 'anti': 2596, 'Semitism': 2597, 'rid': 2598, 'moral': 2599, 'burden': 2600, 'disaster': 2601, 'history': 2602, 'zone': 2603, 'horrible': 2604, 'irony': 2605, 'conveniently': 2606, 'Holocaust': 2607, 'accompany': 2608, 'reflection': 2609, 'partly': 2610, 'proud': 2611, 'mostly': 2612, 'genius': 2613, 'heart': 2614, 'crisis': 2615, 'Valley': 2616, 'Jehosaphat': 2617, 'tomb': 2618, 'road': 2619, 'acre': 2620, 'cave': 2621, 'grave': 2622, 'litter': 2623, 'schoolroom': 2624, 'singe': 2625, 'November': 2626, 'uncomfortably': 2627, 'Jordanians': 2628, 'tear': 2629, 'jordanian': 2630, 'herodian': 2631, 'relic': 2632, 'distort': 2633, 'Absalom': 2634, 'funnel': 2635, 'tapering': 2636, 'army': 2637, 'direction': 2638, 'interminable': 2639, 'fine': 2640, 'obsess': 2641, 'lamentation': 2642, 'Messiah': 2643, 'trumpet': 2644, 'hen': 2645, 'scratch': 2646, 'peck': 2647, 'speckle': 2648, 'party': 2649, 'dungaree': 2650, 'sleeve': 2651, 'waist': 2652, 'muslim': 2653, 'cemetery': 2654, 'significant': 2655, 'historical': 2656, 'private': 2657, 'sly': 2658, 'submit': 2659, 'Stendhal': 2660, 'hero': 2661, 'prison': 2662, 'french': 2663, 'aesthetic': 2664, 'paradise': 2665, 'detention': 2666, 'Ferte': 2667, 'Mace': 2668, 'brave': 2669, 'modern': 2670, 'Mandelstams': 2671, 'Sinyavskys': 2672, 'hunger': 2673, 'Siberia': 2674, 'Osip': 2675, 'Mandelstam': 2676, 'recite': 2677, 'convict': 2678, 'request': 2679, 'Andrei': 2680, 'Sinyavsky': 2681, 'journal': 2682, 'politic': 2683, 'experience': 2684, 'recover': 2685, 'proper': 2686, 'foreground': 2687, 'John': 2688, 'Auerbach': 2689, 'Caesarea': 2690, 'kibbutznik': 2691, 'seaman': 2692, 'voyage': 2693, 'dear': 2694, 'warn': 2695, 'contrary': 2696, 'sixty': 2697, 'draw': 2698, 'slight': 2699, 'delicate': 2700, 'chief': 2701, 'ticket': 2702, 'complicate': 2703, 'emergency': 2704, 'repair': 2705, 'ocean': 2706, 'boyish': 2707, 'bearded': 2708, 'copper': 2709, 'nervous': 2710, 'valise': 2711, 'booze': 2712, 'pyjama': 2713, 'delighted': 2714, 'suffer': 2715, 'activate': 2716, 'grieve': 2717, 'Adam': 2718, 'warfare': 2719, 'unit': 2720, 'action': 2721, 'helicopter': 2722, 'embrace': 2723, 'sunny': 2724, 'numb': 2725, 'wasp': 2726, 'autumn': 2727, 'aquavit': 2728, 'passionately': 2729, 'discuss': 2730, 'literature': 2731, 'marvelous': 2732, 'suffering': 2733, 'hill': 2734, 'Moab': 2735, 'sixteen': 2736, 'Warsaw': 2737, 'ghetto': 2738, 'parent': 2739, 'sister': 2740, 'kill': 2741, 'everyone': 2742, 'obtain': 2743, 'polish': 2744, 'engine': 2745, 'german': 2746, 'freighter': 2747, 'war': 2748, 'via': 2749, 'Cyprus': 2750, 'join': 2751, 'Kibbutz': 2752, 'Sdot': 2753, 'Yam': 2754, 'married': 2755, 'cancer': 2756, 'typical': 2757, 'Eastern': 2758, 'Europe': 2759, 'completely': 2760, 'mother': 2761, 'Germans': 2762, 'harvesting': 2763, 'kibbutz': 2764, 'exceptional': 2765, 'sail': 2766, 'infrequently': 2767, 'huge': 2768, 'tanker': 2769, 'supermechanize': 2770, 'ultraefficient': 2771, 'crew': 2772, 'port': 2773, 'cargo': 2774, 'potash': 2775, 'steel': 2776, 'Naples': 2777, 'weather': 2778, 'harbor': 2779, 'anchor': 2780, 'japanese': 2781, 'ship': 2782, 'pilot': 2783, 'tug': 2784, 'official': 2785, 'claim': 2786, 'incapacitate': 2787, 'captain': 2788, 'post': 2789, 'bond': 2790, 'expense': 2791, 'crippled': 2792, 'berth': 2793, 'briefly': 2794, 'dispute': 2795, 'unloaded': 2796, 'demurrage': 2797, 'fee': 2798, 'mount': 2799, 'holdup': 2800, 'racketeer': 2801, 'con': 2802, 'going': 2803, 'slang': 2804, 'Haifa': 2805, 'protection': 2806, 'insurance': 2807, 'company': 2808, 'town': 2809, 'waiter': 2810, 'bartender': 2811, 'wipe': 2812, 'continually': 2813, 'community': 2814, 'jam': 2815, 'worthy': 2816, 'lane': 2817, 'screw': 2818, 'honking': 2819, 'madly': 2820, 'standstill': 2821, 'evening': 2822, 'snarl': 2823, 'nearby': 2824, 'beach': 2825, 'Mississippi': 2826, 'tourist': 2827, 'bathing': 2828, 'cabin': 2829, 'nail': 2830, 'lovely': 2831, 'pang': 2832, 'Sixth': 2833, 'Fleet': 2834, 'carrier': 2835, 'F': 2836, 'Kennedy': 2837, 'shore': 2838, 'civilian': 2839, 'clothing': 2840, 'rowdy': 2841, 'Oklahoma': 2842, 'Tulsa': 2843, 'especially': 2844, 'interested': 2845, 'delight': 2846, 'ignorance': 2847, 'refreshing': 2848, 'sailor': 2849, 'holocaust': 2850, 'tank': 2851, 'desert': 2852, 'terrorist': 2853, 'bomb': 2854, 'sea': 2855, 'shorthande': 2856, 'chat': 2857, 'confidante': 2858, 'silly': 2859, 'quarter': 2860, 'Stromboli': 2861, 'streak': 2862, 'crimson': 2863, 'lava': 2864, 'volcano': 2865, 'phenomenon': 2866, 'island': 2867, 'mast': 2868, 'Balkans': 2869, 'village': 2870, 'church': 2871, 'locker': 2872, 'bird': 2873, 'badly': 2874, 'dumb': 2875, 'bastard': 2876, 'foul': 2877, 'pump': 2878, 'ballast': 2879, 'pollute': 2880, 'Harold': 2881, 'Rosenberg': 2882, 'freely': 2883, 'plane': 2884, 'suck': 2885, 'gale': 2886, 'exposition': 2887, 'harangue': 2888, 'expostulation': 2889, 'threat': 2890, 'prophecy': 2891, 'diplomat': 2892, 'cagey': 2893, 'explanation': 2894, 'responsible': 2895, 'cautious': 2896, 'grudging': 2897, 'rephrasing': 2898, 'amend': 2899, 'deadly': 2900, 'division': 2901, 'passionate': 2902, 'denunciation': 2903, 'Western': 2904, 'Russia': 2905, 'utterly': 2906, 'attentive': 2907, 'shoreless': 2908, 'subject': 2909, 'ultimately': 2910, 'survival': 2911, 'decent': 2912, 'decade': 2913, 'grasp': 2914, 'antiquity': 2915, 'daily': 2916, 'utility': 2917, 'shop': 2918, 'supermarket': 2919, 'symphony': 2920, 'orchestra': 2921, 'radio': 2922, 'music': 2923, 'explosion': 2924, 'Jaffa': 2925, 'Road': 2926, 'wounded': 2927, 'Uneasy': 2928, 'explode': 2929, 'dynamite': 2930, 'End': 2931, 'restaurant': 2932, 'fundamental': 2933, 'England': 2934, 'charming': 2935, 'dining': 2936, '1973': 2937, 'coolly': 2938, 'sweet': 2939, 'flower': 2940, 'lamp': 2941, 'family': 2942, 'adolescent': 2943, 'school': 2944, 'domestic': 2945, 'ceremony': 2946, 'destructive': 2947, 'enemy': 2948, 'unchanged': 2949, 'creation': 2950, 'pleasantly': 2951, 'refuse': 2952, 'admit': 2953, 'historic': 2954, 'uneasiness': 2955, 'immovable': 2956, 'Nellie': 2957, 'cruising': 2958, 'yawl': 2959, 'swing': 2960, 'flutter': 2961, 'wind': 2962, 'river': 2963, 'tide': 2964, 'Thames': 2965, 'waterway': 2966, 'offing': 2967, 'weld': 2968, 'joint': 2969, 'luminous': 2970, 'tan': 2971, 'barge': 2972, 'cluster': 2973, 'canvas': 2974, 'sharply': 2975, 'peak': 2976, 'gleam': 2977, 'varnish': 2978, 'sprit': 2979, 'haze': 2980, 'flatness': 2981, 'Gravesend': 2982, 'condense': 2983, 'mournful': 2984, 'gloom': 2985, 'brood': 2986, 'motionless': 2987, 'earth': 2988, 'Director': 2989, 'Companies': 2990, 'host': 2991, 'affectionately': 2992, 'bow': 2993, 'seaward': 2994, 'nautical': 2995, 'resemble': 2996, 'trustworthiness': 2997, 'personify': 2998, 'estuary': 2999, 'brooding': 3000, 'besides': 3001, 'period': 3002, 'separation': 3003, 'tolerant': 3004, 'yarn': 3005, 'Lawyer': 3006, 'virtue': 3007, 'cushion': 3008, 'deck': 3009, 'rug': 3010, 'Accountant': 3011, 'domino': 3012, 'architecturally': 3013, 'Marlow': 3014, 'legged': 3015, 'mizzen': 3016, 'cheek': 3017, 'complexion': 3018, 'straight': 3019, 'ascetic': 3020, 'aspect': 3021, 'palm': 3022, 'outward': 3023, 'idol': 3024, 'satisfy': 3025, 'amongst': 3026, 'exchange': 3027, 'lazily': 3028, 'afterwards': 3029, 'silence': 3030, 'board': 3031, 'yacht': 3032, 'meditative': 3033, 'placid': 3034, 'staring': 3035, 'serenity': 3036, 'exquisite': 3037, 'brilliance': 3038, 'pacifically': 3039, 'benign': 3040, 'immensity': 3041, 'unstained': 3042, 'mist': 3043, 'Essex': 3044, 'marsh': 3045, 'gauzy': 3046, 'radiant': 3047, 'fabric': 3048, 'woode': 3049, 'inland': 3050, 'drape': 3051, 'diaphanous': 3052, 'fold': 3053, 'upper': 3054, 'somber': 3055, 'anger': 3056, 'approach': 3057, 'curved': 3058, 'imperceptible': 3059, 'glow': 3060, 'dull': 3061, 'ray': 3062, 'heat': 3063, 'stricken': 3064, 'crowd': 3065, 'forthwith': 3066, 'profound': 3067, 'unruffle': 3068, 'decline': 3069, 'race': 3070, 'bank': 3071, 'dignity': 3072, 'uttermost': 3073, 'venerable': 3074, 'stream': 3075, 'vivid': 3076, 'flush': 3077, 'depart': 3078, 'august': 3079, 'abide': 3080, 'reverence': 3081, 'affection': 3082, 'evoke': 3083, 'spirit': 3084, 'tidal': 3085, 'fro': 3086, 'unceasing': 3087, 'battle': 3088, 'Sir': 3089, 'Francis': 3090, 'Drake': 3091, 'Franklin': 3092, 'untitled': 3093, 'errant': 3094, 'jewel': 3095, 'flash': 3096, 'Golden': 3097, 'Hind': 3098, 'round': 3099, 'flank': 3100, 'treasure': 3101, 'Queen': 3102, 'Highness': 3103, 'gigantic': 3104, 'tale': 3105, 'Erebus': 3106, 'Terror': 3107, 'conquest': 3108, 'Deptford': 3109, 'Greenwich': 3110, 'Erith': 3111, 'adventurer': 3112, 'settler': 3113, 'king': 3114, 'Change': 3115, 'admiral': 3116, 'interloper': 3117, 'eastern': 3118, 'trade': 3119, 'commission': 3120, 'India': 3121, 'fleet': 3122, 'hunter': 3123, 'gold': 3124, 'pursuer': 3125, 'fame': 3126, 'sword': 3127, 'torch': 3128, 'messenger': 3129, 'bearer': 3130, 'sacred': 3131, 'greatness': 3132, 'float': 3133, 'ebb': 3134, '...': 3135, 'seed': 3136, 'commonwealth': 3137, 'germ': 3138, 'empire': 3139, 'dusk': 3140, 'Chapman': 3141, 'lighthouse': 3142, 'erect': 3143, 'mud': 3144, 'flat': 3145, 'strongly': 3146, 'fairway': 3147, 'stir': 3148, 'monstrous': 3149, 'ominously': 3150, 'sunshine': 3151, 'lurid': 3152, 'glare': 3153, 'star': 3154, 'represent': 3155, 'wanderer': 3156, 'express': 3157, 'sedentary': 3158, 'immutability': 3159, 'surrounding': 3160, 'veil': 3161, 'sense': 3162, 'slightly': 3163, 'disdainful': 3164, 'mysterious': 3165, 'unless': 3166, 'mistress': 3167, 'inscrutable': 3168, 'Destiny': 3169, 'casual': 3170, 'stroll': 3171, 'spree': 3172, 'suffice': 3173, 'unfold': 3174, 'continent': 3175, 'generally': 3176, 'worth': 3177, 'direct': 3178, 'simplicity': 3179, 'shell': 3180, 'nut': 3181, 'propensity': 3182, 'episode': 3183, 'kernel': 3184, 'envelop': 3185, 'likeness': 3186, 'misty': 3187, 'halo': 3188, 'spectral': 3189, 'illumination': 3190, 'moonshine': 3191, 'remark': 3192, 'surprising': 3193, 'grunt': 3194, 'presently': 3195, 'Romans': 3196, 'nineteen': 3197, '....': 3198, 'Light': 3199, 'Knights': 3200, 'blaze': 3201, 'plain': 3202, 'lightning': 3203, 'yesterday': 3204, 'commander': 3205, 'ye': 3206, 'them': 3207, 'trireme': 3208, 'Mediterranean': 3209, 'overland': 3210, 'Gauls': 3211, 'hurry': 3212, 'craft': 3213, 'legionary': 3214, 'wonderful': 3215, 'lot': 3216, 'handy': 3217, 'apparently': 3218, 'concertina': 3219, 'sandbank': 3220, 'forest': 3221, 'savage': 3222, 'precious': 3223, 'falernian': 3224, 'wine': 3225, 'ashore': 3226, 'wilderness': 3227, 'needle': 3228, 'bundle': 3229, 'hay': 3230, 'fog': 3231, 'tempest': 3232, 'disease': 3233, 'exile': 3234, 'skulking': 3235, 'oh': 3236, 'brag': 3237, 'cheer': 3238, 'promotion': 3239, 'Ravenna': 3240, 'survive': 3241, 'citizen': 3242, 'toga': 3243, 'dice': 3244, 'train': 3245, 'prefect': 3246, 'tax': 3247, 'gatherer': 3248, 'trader': 3249, 'mend': 3250, 'fortune': 3251, 'swamp': 3252, 'march': 3253, 'wood': 3254, 'savagery': 3255, 'utter': 3256, 'jungle': 3257, 'wild': 3258, 'initiation': 3259, 'midst': 3260, 'incomprehensible': 3261, 'detestable': 3262, 'fascination': 3263, 'abomination': 3264, 'regret': 3265, 'longing': 3266, 'powerless': 3267, 'disgust': 3268, 'hate': 3269, 'Mind': 3270, 'lift': 3271, 'elbow': 3272, 'pose': 3273, 'Buddha': 3274, 'preaching': 3275, 'lotus': 3276, 'none': 3277, 'efficiency': 3278, 'devotion': 3279, 'chap': 3280, 'colonist': 3281, 'administration': 3282, 'squeeze': 3283, 'conqueror': 3284, 'brute': 3285, 'boast': 3286, 'strength': 3287, 'accident': 3288, 'arise': 3289, 'weakness': 3290, 'grab': 3291, 'sake': 3292, 'robbery': 3293, 'violence': 3294, 'aggravate': 3295, 'murder': 3296, 'tackle': 3297, 'flatter': 3298, 'nose': 3299, 'pretty': 3300, 'redeem': 3301, 'sentimental': 3302, 'pretense': 3303, 'unselfish': 3304, 'offer': 3305, 'flame': 3306, 'pursue': 3307, 'overtake': 3308, 'separate': 3309, 'hastily': 3310, 'deepening': 3311, 'sleepless': 3312, 'patiently': 3313, 'till': 3314, 'hesitating': 3315, 'suppose': 3316, 'fresh': 3317, 'fate': 3318, 'inconclusive': 3319, 'personally': 3320, 'teller': 3321, 'unaware': 3322, 'audience': 3323, 'ought': 3324, 'farth': 3325, 'culminating': 3326, 'pitiful': 3327, 'extraordinary': 3328, 'Indian': 3329, 'Ocean': 3330, 'Pacific': 3331, 'China': 3332, 'Seas': 3333, 'regular': 3334, 'dose': 3335, 'loaf': 3336, 'hinder': 3337, 'invade': 3338, 'heavenly': 3339, 'mission': 3340, 'civilize': 3341, 'tired': 3342, 'Australia': 3343, 'glory': 3344, 'exploration': 3345, 'invite': 3346, 'Pole': 3347, 'shall': 3348, 'glamour': 3349, 'Equator': 3350, 'latitude': 3351, 'hemisphere': 3352, 'hankering': 3353, 'got': 3354, 'boyhood': 3355, 'lake': 3356, 'cease': 3357, 'delightful': 3358, 'patch': 3359, 'gloriously': 3360, 'mighty': 3361, 'immense': 3362, 'snake': 3363, 'uncoiled': 3364, 'curve': 3365, 'afar': 3366, 'vast': 3367, 'tail': 3368, 'depth': 3369, 'fascinate': 3370, 'concern': 3371, 'dash': 3372, 'steamboat': 3373, 'charm': 3374, 'Continental': 3375, 'trading': 3376, 'cheap': 3377, 'nasty': 3378, 'venture': 3379, 'Company': 3380, 'profit': 3381, 'Charlie': 3382, 'laborer': 3383, 'queer': 3384, 'truth': 3385, 'sunset': 3386, 'confound': 3387, 'contentedly': 3388, 'knock': 3389, 'flannel': 3390, 'impostor': 3391, 'crossing': 3392, 'hesitation': 3393, 'startled': 3394, 'steamer': 3395, 'sole': 3396, 'soldier': 3397, 'coast': 3398, 'slip': 3399, 'enigma': 3400, 'frown': 3401, 'inviting': 3402, 'grand': 3403, 'insipid': 3404, 'mute': 3405, 'whispering': 3406, 'featureless': 3407, 'making': 3408, 'monotonous': 3409, 'grimness': 3410, 'edge': 3411, 'colossal': 3412, 'surf': 3413, 'glitter': 3414, 'creep': 3415, 'fierce': 3416, 'glisten': 3417, 'drip': 3418, 'steam': 3419, 'grayish': 3420, 'whitish': 3421, 'flag': 3422, 'settlement': 3423, 'pin': 3424, 'untouched': 3425, 'expanse': 3426, 'background': 3427, 'pound': 3428, 'clerk': 3429, 'levy': 3430, 'toll': 3431, 'forsake': 3432, 'tin': 3433, 'shed': 3434, 'pole': 3435, 'nobody': 3436, 'fling': 3437, 'Gran': 3438, 'Bassam': 3439, 'Little': 3440, 'Popo': 3441, 'sordid': 3442, 'farce': 3443, 'sinister': 3444, 'backcloth': 3445, 'idleness': 3446, 'passenger': 3447, 'isolation': 3448, 'oily': 3449, 'languid': 3450, 'somberness': 3451, 'toil': 3452, 'senseless': 3453, 'positive': 3454, 'brother': 3455, 'boat': 3456, 'momentary': 3457, 'reality': 3458, 'paddle': 3459, 'eyeball': 3460, 'sing': 3461, 'perspiration': 3462, 'grotesque': 3463, 'mask': 3464, 'muscle': 3465, 'vitality': 3466, 'intense': 3467, 'straightforward': 3468, 'scare': 3469, 'French': 3470, 'thereabout': 3471, 'ensign': 3472, 'limp': 3473, 'rag': 3474, 'muzzle': 3475, 'inch': 3476, 'gun': 3477, 'hull': 3478, 'greasy': 3479, 'slimy': 3480, 'swell': 3481, 'sway': 3482, 'pop': 3483, 'dart': 3484, 'projectile': 3485, 'feeble': 3486, 'screech': 3487, 'insanity': 3488, 'proceeding': 3489, 'lugubrious': 3490, 'drollery': 3491, 'dissipate': 3492, 'somebody': 3493, 'assure': 3494, 'earnestly': 3495, 'native': 3496, 'lonely': 3497, 'fever': 3498, 'farcical': 3499, 'dance': 3500, 'earthy': 3501, 'overheated': 3502, 'catacomb': 3503, 'formless': 3504, 'Nature': 3505, 'herself': 3506, 'ward': 3507, 'intruder': 3508, 'rot': 3509, 'thicken': 3510, 'slime': 3511, 'contorted': 3512, 'mangrove': 3513, 'writhe': 3514, 'extremity': 3515, 'impotent': 3516, 'particularized': 3517, 'vague': 3518, 'oppressive': 3519, 'weary': 3520, 'pilgrimage': 3521, 'mile': 3522, 'higher': 3523, 'passage': 3524, 'swede': 3525, 'bridge': 3526, 'morose': 3527, 'lanky': 3528, 'gait': 3529, 'miserable': 3530, 'wharf': 3531, 'contemptuously': 3532, 'bitterness': 3533, 'funny': 3534, 'franc': 3535, 'o': 3536, 'athwart': 3537, 'ahead': 3538, 'vigilantly': 3539, 'watchfully': 3540, 'rocky': 3541, 'cliff': 3542, 'mound': 3543, 'iron': 3544, 'excavation': 3545, 'declivity': 3546, 'continuous': 3547, 'noise': 3548, 'inhabited': 3549, 'devastation': 3550, 'naked': 3551, 'ant': 3552, 'jetty': 3553, 'sudden': 3554, 'recrudescence': 3555, 'station': 3556, 'barrack': 3557, 'farewell': 3558, 'boiler': 3559, 'wallowing': 3560, 'aside': 3561, 'bowlder': 3562, 'undersized': 3563, 'railway': 3564, 'wheel': 3565, 'carcass': 3566, 'animal': 3567, 'decay': 3568, 'stack': 3569, 'rusty': 3570, 'rail': 3571, 'shady': 3572, 'feebly': 3573, 'blink': 3574, 'steep': 3575, 'horn': 3576, 'toot': 3577, 'detonation': 3578, 'puff': 3579, 'objectless': 3580, 'blasting': 3581, 'clink': 3582, 'basket': 3583, 'footstep': 3584, 'wound': 3585, 'loin': 3586, 'wag': 3587, 'rib': 3588, 'limb': 3589, 'knot': 3590, 'rope': 3591, 'collar': 3592, 'chain': 3593, 'bight': 3594, 'rhythmically': 3595, 'clinking': 3596, 'ominous': 3597, 'imagination': 3598, 'criminal': 3599, 'outraged': 3600, 'law': 3601, 'bursting': 3602, 'insoluble': 3603, 'meager': 3604, 'violently': 3605, 'dilate': 3606, 'nostril': 3607, 'quiver': 3608, 'stonily': 3609, 'uphill': 3610, 'deathlike': 3611, 'indifference': 3612, 'unhappy': 3613, 'raw': 3614, 'reclaimed': 3615, 'despondently': 3616, 'rifle': 3617, 'hoist': 3618, 'weapon': 3619, 'alacrity': 3620, 'simple': 3621, 'prudence': 3622, 'alike': 3623, 'speedily': 3624, 'reassure': 3625, 'rascally': 3626, 'grin': 3627, 'partnership': 3628, 'exalted': 3629, 'trust': 3630, 'gang': 3631, 'tender': 3632, 'fend': 3633, 'resist': 3634, 'attack': 3635, 'cost': 3636, 'blunder': 3637, 'devil': 3638, 'greed': 3639, 'desire': 3640, 'strong': 3641, 'lusty': 3642, 'eyed': 3643, 'drive': 3644, 'hillside': 3645, 'foresaw': 3646, 'blinding': 3647, 'acquaint': 3648, 'flabby': 3649, 'weak': 3650, 'rapacious': 3651, 'pitiless': 3652, 'folly': 3653, 'insidious': 3654, 'appalled': 3655, 'warning': 3656, 'obliquely': 3657, 'artificial': 3658, 'hole': 3659, 'dig': 3660, 'divine': 3661, 'quarry': 3662, 'sandpit': 3663, 'anyhow': 3664, 'philanthropic': 3665, 'ravine': 3666, 'scar': 3667, 'drainage': 3668, 'tumble': 3669, 'wanton': 3670, 'smash': 3671, 'gloomy': 3672, 'circle': 3673, 'Inferno': 3674, 'uninterrupted': 3675, 'headlong': 3676, 'stillness': 3677, 'grove': 3678, 'leaf': 3679, 'launch': 3680, 'audible': 3681, 'crouch': 3682, 'trunk': 3683, 'cling': 3684, 'efface': 3685, 'dim': 3686, 'attitude': 3687, 'pain': 3688, 'abandonment': 3689, 'significance': 3690, 'wreck': 3691, 'fancy': 3692, 'stupid': 3693, 'nuisance': 3694, 'manager': 3695, 'volunteer': 3696, 'skipper': 3697, 'plenty': 3698, 'fish': 3699, 'interview': 3700, 'size': 3701, 'ordinary': 3702, 'usual': 3703, 'trenchant': 3704, 'axe': 3705, 'disclaim': 3706, 'otherwise': 3707, 'indefinable': 3708, 'lip': 3709, 'stealthy': 3710, 'unconscious': 3711, 'intensify': 3712, 'instant': 3713, 'seal': 3714, 'commonest': 3715, 'youth': 3716, 'employ': 3717, 'obey': 3718, 'inspire': 3719, 'fear': 3720, 'Uneasiness': 3721, 'definite': 3722, 'mistrust': 3723, 'effective': 3724, 'faculty': 3725, 'organizing': 3726, 'initiative': 3727, 'evident': 3728, 'ill': 3729, 'term': 3730, 'triumphant': 3731, 'health': 3732, 'rout': 3733, 'constitution': 3734, 'riot': 3735, 'pompously': 3736, 'Jack': 3737, 'gather': 3738, 'originate': 3739, 'tropical': 3740, 'agent': 3741, 'entrail': 3742, 'utterance': 3743, 'keeping': 3744, 'annoy': 3745, 'quarrel': 3746, 'precedence': 3747, 'mess': 3748, 'unalterable': 3749, 'civil': 3750, 'uncivil': 3751, 'quiet': 3752, 'overfe': 3753, 'negro': 3754, 'insolence': 3755, 'relieve': 3756, 'delay': 3757, 'sealing': 3758, 'wax': 3759, 'rumor': 3760, 'jeopardy': 3761, 'Mr.': 3762, 'Kurtz': 3763, 'irritable': 3764, 'Hang': 3765, 'ah': 3766, 'murmur': 3767, 'anxiety': 3768, 'uneasy': 3769, 'fidget': 3770, 'dumbfound': 3771, 'futile': 3772, 'hut': 3773, 'veranda': 3774, 'idiot': 3775, 'startlingly': 3776, 'nicety': 3777, 'estimate': 3778, 'requisite': 3779, 'turning': 3780, 'yard': 3781, 'stave': 3782, 'faithless': 3783, 'pilgrim': 3784, 'bewitch': 3785, 'rotten': 3786, 'fence': 3787, 'ivory': 3788, 'rang': 3789, 'whisper': 3790, 'sigh': 3791, 'taint': 3792, 'imbecile': 3793, 'rapacity': 3794, 'whiff': 3795, 'Jove': 3796, 'unreal': 3797, 'invincible': 3798, 'evil': 3799, 'passing': 3800, 'fantastic': 3801, 'invasion': 3802, 'cotton': 3803, 'bead': 3804, 'avenging': 3805, 'consume': 3806, 'trash': 3807, 'quietly': 3808, 'dismantled': 3809, 'caper': 3810, 'stout': 3811, 'mustache': 3812, 'pail': 3813, 'behave': 3814, 'splendidly': 3815, 'dip': 3816, 'quart': 3817, 'hopeless': 3818, 'heap': 3819, 'ember': 3820, 'fiercely': 3821, 'nigger': 3822, 'beat': 3823, 'horribly': 3824, 'sick': 3825, 'pronounce': 3826, 'unfortunate': 3827, 'eh': 3828, 'incredible': 3829, 'gentlemanly': 3830, 'fork': 3831, 'hooked': 3832, 'offish': 3833, 'spy': 3834, 'hiss': 3835, 'perceive': 3836, 'aristocrat': 3837, 'dressing': 3838, 'candle': 3839, 'mat': 3840, 'collection': 3841, 'spear': 3842, 'assegais': 3843, 'shield': 3844, 'knife': 3845, 'trophy': 3846, 'business': 3847, 'intrust': 3848, 'inform': 3849, 'fragment': 3850, 'straw': 3851, 'maybe': 3852, 'anyways': 3853, 'likely': 3854, 'uncongenial': 3855, 'occupation': 3856, 'beguile': 3857, 'backbite': 3858, 'foolish': 3859, 'appoint': 3860, 'slander': 3861, 'effectually': 3862, 'heaven': 3863, 'horse': 3864, 'halter': 3865, 'charitable': 3866, 'saint': 3867, 'standpoint': 3868, 'evaluation': 3869, 'implementation': 3870, 'budget': 3871, 'dimension': 3872, 'override': 3873, 'legality': 3874, 'regularity': 3875, 'vote': 3876, 'Council': 3877, 'extremely': 3878, 'concerned': 3879, 'serious': 3880, 'decision': 3881, 'regard': 3882, 'Ojala': 3883, 'recommendation': 3884, 'reading': 3885, 'A4': 3886, '0072/97': 3887, 'Conservatives': 3888, 'Commission': 3889, 'forward': 3890, 'proposal': 3891, 'European': 3892, 'Single': 3893, 'Market': 3894, 'Union': 3895, 'resale': 3896, 'legislation': 3897, 'eleven': 3898, 'Member': 3899, 'maintain': 3900, 'preparatory': 3901, 'economic': 3902, 'aid': 3903, 'Albania': 3904, 'Greece': 3905, 'Italy': 3906, 'Spain': 3907, 'Austria': 3908, 'transition': 3909, 'successfully': 3910, 'continuity': 3911, 'Kong': 3912, 'Hong': 3913, 'rooted': 3914, 'House': 3915, 'firmly': 3916, 'unsuccessful': 3917, 'equally': 3918, 'damage': 3919, 'disagreement': 3920, 'technical': 3921, 'today': 3922, 'refiner': 3923, 'refinery': 3924, 'diesel': 3925, 'Japan': 3926, 'precisely': 3927, 'friendly': 3928, 'fuel': 3929, 'issue': 3930, 'employment': 3931, 'enlargement': 3932, 'politically': 3933, 'Membership': 3934, 'million': 3935, 'ecu': 3936, 'promote': 3937, 'confidence': 3938, 'naturally': 3939, 'turkish': 3940, 'cypriot': 3941, 'representation': 3942, 'lawful': 3943, 'internationally': 3944, 'no-6': 3945, 'Pirker': 3946, 'H-0218/97': 3947, 'Subject': 3948, 'Europol': 3949, 'major': 3950, 'obstacle': 3951, 'ratification': 3952, 'transitional': 3953, 'accession': 3954, 'guarantee': 3955, 'membership': 3956, 'negotiation': 3957, 'Portugal': 3958, 'Lomas': 3959, 'widely': 3960, 'servant': 3961, 'national': 3962, 'Britain': 3963, 'electioneering': 3964, 'Commissioners': 3965, 'boot': 3966, 'adopt': 3967, 'directive': 3968, '96/23': 3969, 'supervisory': 3970, 'EU': 3971, 'association': 3972, 'independent': 3973, 'interpreting': 3974, 'correctly': 3975, 'Sjöstedt': 3976, 'No-15': 3977, 'Medina': 3978, 'Ortega': 3979, 'H-0237/97': 3980, 'industry': 3981, 'prosperity': 3982, 'research': 3983, 'conclusion': 3984, 'STOA': 3985, 'indicate': 3986, 'sulphur': 3987, 'secondly': 3988, 'refurbish': 3989, 'invest': 3990, 'continuously': 3991, 'rapporteur': 3992, '50': 3993, '30': 3994, 'ppm': 3995, 'excessive': 3996, 'appreciable': 3997, 'fiscal': 3998, 'vehicle': 3999, 'introduce': 4000, 'emerge': 4001, 'hearing': 4002, 'petrol': 4003, 'nine': 4004, 'Madam': 4005, 'President': 4006, 'improve': 4007, 'confrontation': 4008, 'concept': 4009, 'actual': 4010, 'driving': 4011, 'programme': 4012, 'innovation': 4013, 'April': 4014, 'September': 4015, 'concession': 4016, 'speaker': 4017, '2005': 4018, 'Amendments': 4019, 'Nos': 4020, '23': 4021, '37': 4022, '38': 4023, 'propose': 4024, 'clearly': 4025, 'misunderstanding': 4026, 'judge': 4027, 'frequently': 4028, 'indirect': 4029, 'discrimination': 4030, 'codify': 4031, 'Court': 4032, 'Justice': 4033, 'consistently': 4034, 'entitle': 4035, 'treatment': 4036, 'colleague': 4037, 'employer': 4038, 'mep': 4039, 'immediate': 4040, 'monitoring': 4041, 'absence': 4042, 'transparency': 4043, 'emphasize': 4044, 'responsibility': 4045, 'Mrs': 4046, 'Oomen': 4047, 'Ruijten': 4048, 'Glase': 4049, 'Minutes': 4050, 'session': 4051, 'Thursday': 4052, '29': 4053, 'May': 4054, '1997': 4055, 'raise': 4056, 'Green': 4057, 'agriculture': 4058, 'bee': 4059, 'petition': 4060, '1996': 4061, 'sadly': 4062, 'plaudit': 4063, 'Petitions': 4064, 'fully': 4065, 'win': 4066, 'Greek': 4067, 'owe': 4068, 'Commissioner': 4069, 'audio': 4070, 'boundary': 4071, 'inspector': 4072, 'Morse': 4073, 'Derrick': 4074, 'remedy': 4075, 'parliament': 4076, 'copyright': 4077, 'principle': 4078, 'competition': 4079, 'televising': 4080, 'sport': 4081, 'broadcaster': 4082, 'consideration': 4083, 'increasingly': 4084, 'noisy': 4085, 'complaint': 4086, 'competence': 4087, 'environmental': 4088, 'airport': 4089, 'motorway': 4090, 'refusal': 4091, 'encouragement': 4092, 'impunity': 4093, 'immunity': 4094, 'resignation': 4095, 'Vice': 4096, 'Cornelissen': 4097, 'agenda': 4098, 'Tuesday': 4099, 'oral': 4100, 'congratulation': 4101, 'non': 4102, 'practise': 4103, 'activity': 4104, 'doctor': 4105, 'teacher': 4106, 'Bonino': 4107, 'wholeheartedly': 4108, 'behalf': 4109, 'Kabul': 4110, 'Barbaric': 4111, 'closed': 4112, 'isolated': 4113, 'amendment': 4114, 'oppose': 4115, 'subsequently': 4116, 'reject': 4117, 'postpone': 4118, 'indefinitely': 4119, 'provision': 4120, 'restrict': 4121, 'physical': 4122, 'everyday': 4123, 'bemused': 4124, 'pragmatic': 4125, 'capital': 4126, 'income': 4127, 'compromise': 4128, 'finance': 4129, 'coordinate': 4130, 'objective': 4131, 'manoeuvring': 4132, 'distortion': 4133, 'market': 4134, 'simplification': 4135, 'accessory': 4136, 'sitting': 4137, 'suspend': 4138, '11.25': 4139, 'a.m.': 4140, '11.30': 4141, 'a.m': 4142, '..': 4143, 'predecessor': 4144, 'finish': 4145, 'barely': 4146, 'Macao': 4147, 'resolution': 4148, 'vital': 4149, 'influence': 4150, 'economy': 4151, 'prospect': 4152, 'Directive': 4153, '96/96': 4154, '/': 4155, 'EC': 4156, 'undergo': 4157, 'annual': 4158, 'roadworthiness': 4159, 'testing': 4160, 'centre': 4161, 'introduction': 4162, 'enthusiastically': 4163, 'solution': 4164, 'blindly': 4165, 'Community': 4166, 'intervention': 4167, 'exclusive': 4168, 'communication': 4169, 'consistency': 4170, 'regional': 4171, 'entrench': 4172, 'combat': 4173, 'unemployment': 4174, 'hearten': 4175, 'recognise': 4176, 'willing': 4177, 'dire': 4178, 'committee': 4179, 'exempt': 4180, 'intensive': 4181, 'disadvantage': 4182, 'exemption': 4183, 'kerosene': 4184, 'abolish': 4185, 'indexing': 4186, 'minimum': 4187, 'Cox': 4188, 'regulation': 4189, 'reliable': 4190, 'complex': 4191, 'criticism': 4192, 'Legal': 4193, 'Affairs': 4194, 'sided': 4195, 'salute': 4196, 'regulate': 4197, 'digital': 4198, 'safeguard': 4199, 'rightholder': 4200, 'Socialist': 4201, 'Group': 4202, 'limitation': 4203, 'context': 4204, 'logically': 4205, 'compensation': 4206, 'creator': 4207, 'sharing': 4208, 'cultural': 4209, 'mandatory': 4210, 'artwork': 4211, 'being': 4212, 'noticeable': 4213, 'balanced': 4214, 'achieve': 4215, 'incur': 4216, 'Barzanti': 4217, 'frankly': 4218, 'Blank': 4219, 'screen': 4220, 'enrich': 4221, 'La': 4222, 'Bohéme': 4223, 'garret': 4224, 'argue': 4225, 'Kingdom': 4226, 'tape': 4227, 'holder': 4228, 'absolute': 4229, 'banning': 4230, 'agricultural': 4231, 'trans': 4232, 'transport': 4233, 'network': 4234, 'priority': 4235, 'knell': 4236, 'recital': 4237, 'court': 4238, 'hit': 4239, 'producer': 4240, 'stranglehold': 4241, 'evolve': 4242, 'global': 4243, 'Parliament': 4244, 'uphold': 4245, 'remuneration': 4246, 'distinction': 4247, 'equity': 4248, 'measured': 4249, 'forwards': 4250, 'legal': 4251, 'sector': 4252, 'formula': 4253, 'harmonisation': 4254, 'C4': 4255, '0497/98': 4256, '98/0126': 4257, 'CNS': 4258, 'COM': 4259, 'industrial': 4260, 'sincere': 4261, 'Martin': 4262, 'Fischler': 4263, 'Agriculture': 4264, 'framework': 4265, 'overproduction': 4266, 'comprehensive': 4267, 'quantity': 4268, 'preserve': 4269, 'Article': 4270, '43': 4271, 'Van': 4272, 'Miert': 4273, 'progress': 4274, 'internal': 4275, 'medicinal': 4276, 'consumer': 4277, 'constitute': 4278, 'electricity': 4279, 'anxious': 4280, 'congratulate': 4281, 'Thors': 4282, 'Swedish': 4283, 'Finnish': 4284, 'habit': 4285, 'transfer': 4286, 'February': 4287, 'detailed': 4288, 'release': 4289, 'especial': 4290, 'No-46': 4291, 'Christine': 4292, 'Oddy': 4293, 'h-0002/99': 4294, 'pleased': 4295, 'honourable': 4296, 'Hatzidakis': 4297, 'van': 4298, 'den': 4299, 'Broek': 4300, 'No-59': 4301, 'Alex': 4302, 'Smith': 4303, 'H-0045/99': 4304, 'confess': 4305, 'totally': 4306, 'sensitivity': 4307, 'supplementary': 4308, 'protest': 4309, 'namely': 4310, 'closing': 4311, 'Sellafield': 4312, 'fitzsimon': 4313, 'invitation': 4314, 'tunnel': 4315, '7.15': 4316, 'p.m': 4317, 'resume': 4318, '9': 4319, 'p.m.': 4320, 'organisation': 4321, 'continuation': 4322, 'dynamic': 4323, 'equilibrium': 4324, 'draft': 4325, 'cap': 4326, 'reform': 4327, 'embed': 4328, 'rut': 4329, 'Rural': 4330, 'Development': 4331, 'growing': 4332, 'wholly': 4333, 'derive': 4334, 'vine': 4335, 'unfortunately': 4336, 'enormous': 4337, 'lady': 4338, 'gentleman': 4339, 'favour': 4340, 'commissioner': 4341, 'Brittan': 4342, 'forum': 4343, 'Trade': 4344, 'Organisation': 4345, 'urge': 4346, 'presidency': 4347, 'Bonn': 4348, 'US': 4349, 'summit': 4350, 'wallet': 4351, 'negotiate': 4352, 'condemn': 4353, 'pirate': 4354, 'Structural': 4355, 'Funds': 4356, 'financing': 4357, 'radical': 4358, 'Santer': 4359, 'rightly': 4360, 'pillar': 4361, 'Agenda': 4362, 'discussion': 4363, 'wane': 4364, 'headache': 4365, 'fraud': 4366, 'circumvention': 4367, 'evasion': 4368, 'compliment': 4369, 'Haug': 4370, 'appropriateness': 4371, 'unanimity': 4372, 'Cresson': 4373, 'reply': 4374, 'Valverde': 4375, 'premise': 4376, 'educate': 4377, 'guess': 4378, 'representative': 4379, 'Nicaragua': 4380, 'indicative': 4381, 'crystal': 4382, 'Rio': 4383, 'Coco': 4384, 'dialogue': 4385, 'Rules': 4386, 'originally': 4387, 'grateful': 4388, 'opening': 4389, 'damn': 4390, 'Kinnock': 4391, 'No-44': 4392, 'Bernie': 4393, 'Malone': 4394, 'H-0209/99': 4395, 'rectify': 4396, '7': 4397, '-%': 4398, 'sustainable': 4399, 'fishery': 4400, 'overall': 4401, '6500': 4402, 'tonne': 4403, 'trend': 4404, 'consumption': 4405, 'trafficking': 4406, 'depredation': 4407, 'smuggler': 4408, 'Morocco': 4409, 'grim': 4410, 'EDU': 4411, 'mandate': 4412, 'smuggling': 4413, 'ply': 4414, 'Gibraltar': 4415, 'authority': 4416, 'cooperate': 4417, 'route': 4418, 'No-49': 4419, 'written': 4420, 'monitor': 4421, 'origin': 4422, 'individual': 4423, 'statistic': 4424, 'Cuba': 4425, 'scottish': 4426, '84': 4427, 'exporter': 4428, 'undertaking': 4429, 'adoption': 4430, 'Burma': 4431, 'withdrawal': 4432, 'GSP': 4433, 'meat': 4434, 'modest': 4435, 'reimburse': 4436, 'bill': 4437, '60': 4438, '111': 4439, 'Time': 4440, 'electoral': 4441, 'masse': 4442, 'stage': 4443, 'Labour': 4444, 'dissent': 4445, 'Germany': 4446, 'surplus': 4447, 'billion': 4448, 'firstly': 4449, 'receipt': 4450, 'requirement': 4451, 'sincerely': 4452, 'purely': 4453, 'linguistic': 4454, 'conciliation': 4455, 'declare': 4456, 'seaport': 4457, 'famous': 4458, 'no-8': 4459, '14': 4460, 'endorse': 4461, 'Essen': 4462, 'summarise': 4463, 'gain': 4464, 'accurate': 4465, 'mediterranean': 4466, 'viability': 4467, 'infrastructure': 4468, 'investment': 4469, 'competitive': 4470, 'revenue': 4471, 'No-6': 4472, 'guideline': 4473, 'prolonged': 4474, 'privatisation': 4475, 'liberalisation': 4476, 'cooperation': 4477, 'jurisdiction': 4478, 'consequently': 4479, 'intend': 4480, 'worried': 4481, 'opportunity': 4482, 'renaissance': 4483, 'strive': 4484, 'authorised': 4485, 'applicant': 4486, 'capacity': 4487, 'recent': 4488, 'effort': 4489, 'secure': 4490, 'unnecessary': 4491, 'sympathy': 4492, 'prescriptive': 4493, 'reliance': 4494, 'commitment': 4495, 'constructive': 4496, 'practical': 4497, 'discretion': 4498, 'soft': 4499, 'breathe': 4500, 'dragon': 4501, 'oil': 4502, 'heating': 4503, 'silky': 4504, 'colour': 4505, 'Olivia': 4506, 'cherry-': 4507, 'satin': 4508, 'pot': 4509, 'beadwork': 4510, 'carving': 4511, 'Congo': 4512, 'progression': 4513, 'Mackie': 4514, 'knowing': 4515, 'dare': 4516, 'measurement': 4517, 'trouser': 4518, 'elastic': 4519, 'Adamson': 4520, 'Mweta': 4521, 'steak': 4522, 'Kensington': 4523, 'fullness': 4524, 'twilight': 4525, 'housing': 4526, 'estate': 4527, 'overrun': 4528, 'reverse': 4529, 'manor': 4530, 'priory': 4531, 'nineteenth': 4532, 'depopulate': 4533, 'industrialize': 4534, 'autonomy': 4535, 'cum': 4536, 'cottage': 4537, 'renewal': 4538, 'reassurance': 4539, 'stubborn': 4540, 'fecundity': 4541, 'daughter': 4542, 'independence': 4543, 'confer': 4544, 'Colonial': 4545, 'smooth': 4546, 'delegation': 4547, 'central': 4548, 'territory': 4549, 'colonial': 4550, 'succeed': 4551, 'recall': 4552, 'deport': 4553, 'People': 4554, 'Independence': 4555, 'Party': 4556, 'guest': 4557, 'celebration': 4558, 'marvellous': 4559, 'cycle': 4560, 'Gala': 4561, 'province': 4562, 'weekend': 4563, 'meeting': 4564, 'eld': 4565, 'shy': 4566, 'powerful': 4567, 'Venetia': 4568, 'Englishman': 4569, 'Bray': 4570, 'baby': 4571, \"celebrations'll\": 4572, 'taxi': 4573, 'uprush': 4574, 'quick': 4575, 'bicep': 4576, 'constitutional': 4577, 'tactic': 4578, 'impersonal': 4579, 'consciousness': 4580, 'stimulant': 4581, 'inject': 4582, 'ours': 4583, 'façade': 4584, 'lintel': 4585, 'sill': 4586, 'soap': 4587, 'shelter': 4588, 'grassy': 4589, 'fuzzy': 4590, 'moth': 4591, 'desultorily': 4592, 'pull': 4593, 'rank': 4594, 'weed': 4595, 'yield': 4596, 'humus': 4597, 'crumb': 4598, 'underground': 4599, 'cake': 4600, 'walnut': 4601, 'damp': 4602, 'whisky': 4603, 'waver': 4604, 'golden': 4605, 'meadow': 4606, 'partridge': 4607, 'fade': 4608, 'convey': 4609, 'satisfaction': 4610, 'Stravinsky': 4611, 'Poulenc': 4612, 'knit': 4613, 'grandmother': 4614, 'stuff': 4615, 'niece': 4616, 'nephew': 4617, 'dissemble': 4618, 'confront': 4619, 'glibness': 4620, 'posit': 4621, 'calmly': 4622, 'youngish': 4623, 'schoolgirl': 4624, 'historically': 4625, 'possession': 4626, 'quit': 4627, 'pride': 4628, 'victory': 4629, 'Henry': 4630, 'Davis': 4631, 'M.P.': 4632, 'banish': 4633, 'Province': 4634, 'marriage': 4635, 'deeply': 4636, 'Wiltshire': 4637, 'definitive': 4638, 'Englishwoman': 4639, 'storage': 4640, 'furniture': 4641, 'inevitably': 4642, 'arrangement': 4643, 'grandfather': 4644, 'morocco': 4645, 'erase': 4646, 'boxwood': 4647, 'empirical': 4648, 'scribble': 4649, 'scented': 4650, 'mothy': 4651, 'premonition': 4652, 'lover': 4653, 'stock': 4654, 'discovery': 4655, 'tobacco': 4656, 'sensible': 4657, 'inquire': 4658, 'misunderstand': 4659, 'usually': 4660, 'Good': 4661, 'Lord': 4662, 'unexpectedly': 4663, 'Mozart': 4664, 'harp': 4665, 'Mute': 4666, 'concerto': 4667, 'herb': 4668, 'branch': 4669, 'dill': 4670, 'youngster': 4671, 'hatch': 4672, 'barrel': 4673, 'steady': 4674, 'bleary': 4675, 'shopwindow': 4676, 'blurred': 4677, 'Athens': 4678, 'icy': 4679, 'wet': 4680, 'Aegean': 4681, 'thyme': 4682, 'crinkly': 4683, 'grey': 4684, 'filthy': 4685, 'cleaning': 4686, 'ease': 4687, 'cramp': 4688, 'knee': 4689, 'circumference': 4690, 'oneself': 4691, 'embroider': 4692, 'apron': 4693, 'evzone': 4694, 'badge': 4695, 'canton': 4696, 'Switzerland': 4697, 'sew': 4698, 'postcard': 4699, 'dazzle': 4700, 'Cambridge': 4701, 'spre': 4702, 'yell': 4703, 'mistake': 4704, 'Kano': 4705, 'moon': 4706, 'bright': 4707, 'tarmac': 4708, 'resistance': 4709, 'persist': 4710, 'woodsmoke': 4711, 'beneath': 4712, 'belly': 4713, 'bare': 4714, 'aboard': 4715, 'airless': 4716, 'hamper': 4717, 'rearrange': 4718, 'gear': 4719, 'anticipation': 4720, 'arrival': 4721, 'arouse': 4722, 'instinct': 4723, 'herd': 4724, 'slump': 4725, 'sleep': 4726, 'beam': 4727, 'hairnet': 4728, 'stubble': 4729, 'immigration': 4730, 'BRAY': 4731, 'Evelyn': 4732, 'passport': 4733, 'flex': 4734, 'awkwardly': 4735, 'mild': 4736, 'embarrassment': 4737, 'notch': 4738, 'sponge': 4739, 'vacant': 4740, 'greet': 4741, 'doze': 4742, 'intimate': 4743, 'cage': 4744, 'wedge': 4745, 'distant': 4746, 'apologetically': 4747, 'cologne': 4748, 'freckle': 4749, 'curtain': 4750, 'oval': 4751, 'glorious': 4752, 'animation': 4753, 'furze': 4754, 'growth': 4755, 'runway': 4756, 'unhook': 4757, 'safety': 4758, 'belt': 4759, 'angle': 4760, 'lens': 4761, 'distorted': 4762, 'thinking': 4763, 'underfoot': 4764, 'khaki': 4765, 'stocking': 4766, 'spray': 4767, 'cloyingly': 4768, 'insecticide': 4769, 'precaution': 4770, 'harbouring': 4771, 'mosquito': 4772, 'tsetse': 4773, 'heady': 4774, 'potato': 4775, 'undergrowth': 4776, 'warmth': 4777, 'cool': 4778, 'metallic': 4779, 'taste': 4780, 'storm': 4781, 'throat': 4782, 'disembarking': 4783, 'mouthing': 4784, 'balcony': 4785, 'processional': 4786, 'reception': 4787, 'insect': 4788, 'sweep': 4789, 'summon': 4790, 'booth': 4791, 'companion': 4792, 'convention': 4793, 'insist': 4794, 'Colonel': 4795, 'coarse': 4796, 'strand': 4797, 'ear': 4798, 'sunglass': 4799, 'nordic': 4800, 'cheekbone': 4801, 'baldish': 4802, 'accent': 4803, 'recently': 4804, 'Hjalmar': 4805, 'Wentz': 4806, 'rhino': 4807, 'Denmark': 4808, 'charcoal': 4809, 'grill': 4810, 'whatnot': 4811, 'McGowan': 4812, 'miner': 4813, 'pub': 4814, 'overawing': 4815, 'genteel': 4816, 'gentle': 4817, 'lamb': 4818, 'Barry': 4819, 'Forsyth': 4820, 'Construction': 4821, 'Isoza': 4822, 'River': 4823, 'reclamation': 4824, 'scheme': 4825, 'Poland': 4826, 'spider': 4827, 'flatten': 4828, 'starfish': 4829, 'fat': 4830, 'intensely': 4831, 'sociable': 4832, 'pitch': 4833, 'Dando': 4834, 'cook': 4835, 'Festus': 4836, 'fridge': 4837, 'pink': 4838, 'specially': 4839, 'muddle': 4840, 'obstinate': 4841, 'righteously': 4842, 'maid': 4843, 'retail': 4844, 'interruption': 4845, 'exaggeration': 4846, 'paternalist': 4847, 'discipline': 4848, 'District': 4849, 'district': 4850, 'magistrate': 4851, 'ambulance': 4852, 'instance': 4853, 'Public': 4854, 'Health': 4855, 'D.C.': 4856, 'dependency': 4857, 'resentment': 4858, 'worry': 4859, 'Bench': 4860, 'bottomless': 4861, 'distaste': 4862, 'wrinkle': 4863, 'mug': 4864, 'breed': 4865, 'Gwenzi': 4866, 'Inn': 4867, 'African': 4868, 'deportation': 4869, 'warrant': 4870, 'arrest': 4871, 'mouthful': 4872, 'granadilla': 4873, 'pudding': 4874, 'tremor': 4875, 'dando': 4876, 'fool': 4877, 'Prosecutor': 4878, 'Shinza': 4879, 'bloody': 4880, 'discount': 4881, 'opposition': 4882, 'trick': 4883, 'PIP': 4884, 'Lambala': 4885, 'boycott': 4886, 'beatingsup': 4887, 'poll': 4888, 'burning': 4889, 'contented': 4890, 'loud': 4891, 'refill': 4892, 'brandy': 4893, 'confident': 4894, 'verdict': 4895, 'biased': 4896, 'midnight': 4897, 'cockroach': 4898, 'flee': 4899, 'twirl': 4900, 'antennae': 4901, 'furry': 4902, 'band': 4903, 'cupboard': 4904, 'flick': 4905, 'plate': 4906, 'avocado': 4907, 'pear': 4908, 'pip': 4909, 'matchstick': 4910, 'pickle': 4911, 'jar': 4912, 'giddy': 4913, 'volition': 4914, 'Labrador': 4915, 'reproachfully': 4916, 'assistant': 4917, 'tea': 4918, 'snore': 4919, 'greeting': 4920, 'expunge': 4921, 'satisfied': 4922, 'symbol': 4923, 'inseparable': 4924, 'relevant': 4925, 'stadium': 4926, 'perimeter': 4927, 'Kenyatta': 4928, 'Vivien': 4929, 'Bayley': 4930, 'registrar': 4931, 'university': 4932, 'collide': 4933, 'alert': 4934, 'apprehension': 4935, 'flip': 4936, 'crown': 4937, 'publicity': 4938, 'stunt': 4939, 'Neil': 4940, 'visitor': 4941, 'bray': 4942, 'tension': 4943, 'couple': 4944, 'tier': 4945, 'canopy': 4946, 'dai': 4947, 'photographer': 4948, 'solemnity': 4949, 'bent': 4950, 'tiptoe': 4951, 'thrust': 4952, 'contraption': 4953, 'shutter': 4954, 'flashlight': 4955, 'ready': 4956, 'theatrical': 4957, 'performance': 4958, 'workman': 4959, 'risen': 4960, 'temper': 4961, 'distraction': 4962, 'disorderly': 4963, 'symbolic': 4964, 'attainment': 4965, 'willed': 4966, 'roar': 4967, 'interval': 4968, 'togas': 4969, 'medal': 4970, 'ululate': 4971, 'clash': 4972, 'brass': 4973, 'icecream': 4974, 'tricycle': 4975, 'amphitheatre': 4976, 'mongrel': 4977, 'presidential': 4978, 'mummify': 4979, 'vessel': 4980, 'ritual': 4981, 'irresistibly': 4982, 'spectator': 4983, 'spectacle': 4984, 'embarrassed': 4985, 'elderly': 4986, 'english': 4987, 'princess': 4988, 'neatly': 4989, 'Royal': 4990, 'curiously': 4991, 'contingent': 4992, 'whiten': 4993, 'joy': 4994, 'troop': 4995, 'musician': 4996, 'dancer': 4997, 'occasion': 4998, 'Ball': 4999, 'cocktail': 5000, 'banquet': 5001, 'luncheon': 5002, 'mood': 5003, 'palace': 5004, 'gate': 5005, 'Roly': 5006, 'mock': 5007, 'surprise': 5008, 'spontaneously': 5009, 'Bayleys': 5010, 'Clough': 5011, 'governor': 5012, 'junior': 5013, 'Tanganyika': 5014, 'Cyprian': 5015, 'Kente': 5016, 'Interior': 5017, 'Tindi': 5018, 'Timothy': 5019, 'Odara': 5020, 'Poles': 5021, 'Ghanaians': 5022, 'Hungarians': 5023, 'refugee': 5024, 'marquee': 5025, 'congolese': 5026, 'whip': 5027, 'thrilling': 5028, 'cosy': 5029, 'gaiety': 5030, 'tent': 5031, 'divan': 5032, 'collage': 5033, 'yawning': 5034, 'curiosity': 5035, 'threaten': 5036, 'finery': 5037, 'queenly': 5038, 'mannered': 5039, 'permutation': 5040, 'drunk': 5041, 'overlook': 5042, 'stiffly': 5043, 'gyration': 5044, 'ashamed': 5045, 'politeness': 5046, 'vanity': 5047, 'flirt': 5048, 'wriggle': 5049, 'Andrew': 5050, 'friendliness': 5051, 'relationship': 5052, 'expose': 5053, 'crowded': 5054, 'purse': 5055, 'spare': 5056, 'stomach': 5057, 'heighten': 5058, 'neighbour': 5059, 'fingerprint': 5060, 'relinquish': 5061, 'Ras': 5062, 'Asahe': 5063, 'broadcast': 5064, 'Services': 5065, 'Joseph': 5066, 'Edward': 5067, 'lieutenant': 5068, 'suggestion': 5069, 'cufflink': 5070, 'Mussolini': 5071, 'jaw': 5072, 'lyrical': 5073, 'delicately': 5074, 'blandness': 5075, 'businessman': 5076, 'marvel': 5077, 'brutalizing': 5078, 'hardship': 5079, 'coverage': 5080, 'classroom': 5081, 'considerably': 5082, 'shortage': 5083, 'qualified': 5084, 'keen': 5085, 'General': 5086, 'serving': 5087, 'roast': 5088, 'sheep': 5089, 'stocky': 5090, 'Roland': 5091, 'Rhino': 5092, 'Margot': 5093, 'fuss': 5094, 'spit': 5095, 'shiny': 5096, 'forehead': 5097, 'capable': 5098, 'tidbit': 5099, 'crisp': 5100, 'literally': 5101, 'wellshape': 5102, 'eager': 5103, 'justice': 5104, 'labour': 5105, 'us': 5106, 'softly': 5107, 'majestically': 5108, 'd': 5109, 'mango': 5110, 'crazy': 5111, 'excitedly': 5112, 'slighter': 5113, 'proprietor': 5114, 'Silver': 5115, 'anyway': 5116, 'ugliness': 5117, 'noone': 5118, 'contempt': 5119, 'Stephen': 5120, 'amazing': 5121, 'education': 5122, 'glimmer': 5123, 'innocently': 5124, 'rejection': 5125, 'chilly': 5126, 'indoor': 5127, 'fireplace': 5128, 'bang': 5129, 'Governor': 5130, 'panga': 5131, 'picannin': 5132, 'snotty': 5133, 'sulky': 5134, 'department': 5135, 'glittering': 5136, 'Doris': 5137, 'Manyema': 5138, 'graduate': 5139, 'appreciation': 5140, 'apart': 5141, 'blackness': 5142, 'figurehead': 5143, 'hulk': 5144, 'chin': 5145, 'handsome': 5146, 'magnificent': 5147, 'underline': 5148, 'fatigue': 5149, 'absent': 5150, 'colonialism': 5151, 'indefensible': 5152, 'shanty': 5153, 'dirt': 5154, 'alphabet': 5155, 'malaria': 5156, 'Finns': 5157, 'Russians': 5158, 'anybody': 5159, 'sweat': 5160, 'luckily': 5161, 'colonialist': 5162, 'compound': 5163, 'neo': 5164, 'Curtis': 5165, 'ach': 5166, 'healthy': 5167, 'missionary': 5168, 'Pettigrew': 5169, 'Europeans': 5170, 'reasonably': 5171, 'grimace': 5172, 'mistaken': 5173, 'grandly': 5174, 'Hitler': 5175, 'tooth': 5176, 'impatient': 5177, 'pleasantness': 5178, 'killing': 5179, 'slave': 5180, 'eighteenth': 5181, 'gipsy': 5182, 'seventeenth': 5183, 'birthday': 5184, 'Fort': 5185, 'Howard': 5186, 'Majesty': 5187, 'Auschwitz': 5188, 'Jo': 5189, 'Ann': 5190, 'blob': 5191, 'marshmallow': 5192, 'countryman': 5193, 'assumption': 5194, 'angrily': 5195, 'waggle': 5196, 'sticky': 5197, 'handkerchief': 5198, 'Pettigrews': 5199, 'Sputnik': 5200, 'Bar': 5201, 'Odaras': 5202, 'Wentzes': 5203, 'Rebecca': 5204, 'terrific': 5205, 'hey': 5206, 'Laughter': 5207, 't': 5208, 'enthusiasm': 5209, 'spring': 5210, 'diademe': 5211, 'raindrop': 5212, 'anthropologist': 5213, 'ras': 5214, 'Edwards': 5215, 'naturedly': 5216, 'inquiringly': 5217, 'film': 5218, 'INDEPENDENCE': 5219, 'HURRAH': 5220, 'hers': 5221, 'desperate': 5222, 'buffeting': 5223, 'chase': 5224, 'moonlit': 5225, 'Bwana': 5226, 'hedgehog': 5227, 'pinkness': 5228, 'aggression': 5229, 'moonlight': 5230, 'beast': 5231, 'donkey': 5232, 'cropping': 5233, 'china': 5234, 'mosque': 5235, 'silvered': 5236, 'burglar': 5237, 'indian': 5238, 'haphazardly': 5239, 'crop': 5240, 'plunge': 5241, 'Privet': 5242, 'Vernon': 5243, 'Dursley': 5244, 'hoot': 5245, 'Harry': 5246, 'Petunia': 5247, 'belch': 5248, 'Dursleys': 5249, 'Dudley': 5250, 'feed': 5251, 'droop': 5252, 'sentence': 5253, 'scream': 5254, 'clap': 5255, 'throbbing': 5256, 'temple': 5257, 'purple': 5258, 'uncle': 5259, 'aunt': 5260, 'heave': 5261, 'Uncle': 5262, 'rhinoceros': 5263, 'holiday': 5264, 'Potter': 5265, 'normal': 5266, 'wizard': 5267, 'Hogwarts': 5268, 'School': 5269, 'Witchcraft': 5270, 'Wizardry': 5271, 'miss': 5272, 'hogwart': 5273, 'ache': 5274, 'spellbook': 5275, 'wand': 5276, 'robe': 5277, 'cauldron': 5278, 'Nimbus': 5279, 'Two': 5280, 'Thousand': 5281, 'broomstick': 5282, 'stair': 5283, 'Quidditch': 5284, 'team': 5285, 'homework': 5286, 'muggle': 5287, 'magical': 5288, 'shame': 5289, 'padlock': 5290, 'Hedwig': 5291, 'message': 5292, 'wizarde': 5293, 'neckless': 5294, 'moustache': 5295, 'Aunt': 5296, 'bony': 5297, 'porky': 5298, 'skinny': 5299, 'jet': 5300, 'untidy': 5301, 'unusual': 5302, 'dursley': 5303, 'doorstep': 5304, 'curse': 5305, 'sorcer': 5306, 'Voldemort': 5307, 'witch': 5308, 'voldemort': 5309, 'destroy': 5310, 'smelly': 5311, 'twelfth': 5312, 'career': 5313, 'bitterly': 5314, 'fortnight': 5315, 'builder': 5316, 'drill': 5317, 'simper': 5318, 'Excellent': 5319, 'viciously': 5320, 'Mason': 5321, 'hug': 5322, 'duck': 5323, 'forcefully': 5324, 'lounge': 5325, 'luck': 5326, 'Ten': 5327, 'excited': 5328, 'Majorca': 5329, 'lawn': 5330, 'card': 5331, 'miserably': 5332, 'hedge': 5333, 'Ron': 5334, 'Weasley': 5335, 'Hermione': 5336, 'Granger': 5337, 'countless': 5338, 'unlock': 5339, 'magic': 5340, 'underage': 5341, 'terror': 5342, 'dung': 5343, 'beetle': 5344, 'arch': 5345, 'Draco': 5346, 'Malfoy': 5347, 'fun': 5348, 'terrifying': 5349, 'cunning': 5350, 'determined': 5351, 'regain': 5352, 'clutch': 5353, 'drench': 5354, 'livid': 5355, 'bolt': 5356, 'upright': 5357, 'mindedly': 5358, 'jeering': 5359, 'hitch': 5360, 'suspiciously': 5361, 'stumble': 5362, 'backwards': 5363, 'panic': 5364, 'MUUUUUUM': 5365, 'howl': 5366, 'dearly': 5367, 'hurt': 5368, 'soapy': 5369, 'fry': 5370, 'pan': 5371, 'loll': 5372, 'mow': 5373, 'trim': 5374, 'flowerbeds': 5375, 'prune': 5376, 'rose': 5377, 'repaint': 5378, 'overhead': 5379, 'burn': 5380, 'bait': 5381, 'Wish': 5382, 'savagely': 5383, 'manure': 5384, 'gladly': 5385, 'sugar': 5386, 'violet': 5387, 'pork': 5388, 'sizzle': 5389, 'oven': 5390, 'salmon': 5391, 'supper': 5392, 'whisk': 5393, 'upstairs': 5394, 'landing': 5395, 'bell': 5396, 'creature': 5397, 'bat': 5398, 'bulge': 5399, 'tennis': 5400, 'instantly': 5401, 'pillowcase': 5402, 'rip': 5403, 'th': 5404, 'Dobby': 5405, 'er': 5406, 'rude': 5407, 'elf': 5408, 'Petunias': 5409, 'false': 5410, 'starve': 5411, 'Moonlight': 5412, 'nosed': 5413, 'impact': 5414, 'turquoise': 5415, 'Fred': 5416, 'George': 5417, 'twin': 5418, 'gibber': 5419, 'tightly': 5420, 'rev': 5421, 'realise': 5422, 'louder': 5423, 'crunching': 5424, 'panting': 5425, 'anxiously': 5426, 'hairpin': 5427, 'click': 5428, 'creak': 5429, 'cough': 5430, 'slide': 5431, 'thunder': 5432, 'snatch': 5433, 'scramble': 5434, 'drawer': 5435, 'hammer': 5436, 'unlocked': 5437, 'split': 5438, 'doorway': 5439, 'bellow': 5440, 'angry': 5441, 'bull': 5442, 'dive': 5443, 'ankle': 5444, 'seize': 5445, 'Weasleys': 5446, 'shrink': 5447, 'rooftop': 5448, 'dumbstruck': 5449, 'soar': 5450, 'joyfully': 5451, 'alongside': 5452, 'ghost': 5453, 'fiasco': 5454, 'shocked': 5455, 'definitely': 5456, 'dodgy': 5457, 'master': 5458, 'permission': 5459, 'reckon': 5460, 'supporter': 5461, 'rumour': 5462, 'yeah': 5463, 'Mum': 5464, 'ironing': 5465, 'strut': 5466, 'Errol': 5467, 'fault': 5468, 'delivery': 5469, 'Dad': 5470, 'Percy': 5471, 'compass': 5472, 'dashboard': 5473, 'twiddle': 5474, 'steering': 5475, 'boring': 5476, 'antique': 5477, 'Muggle': 5478, 'pinkish': 5479, 'horizon': 5480, 'patchwork': 5481, 'Touchdown': 5482, 'tumbledown': 5483, 'garage': 5484, 'pigsty': 5485, 'extra': 5486, 'storey': 5487, 'chimney': 5488, 'perch': 5489, 'jumble': 5490, 'wellington': 5491, 'downstairs': 5492, 'greenish': 5493, 'plump': 5494, 'remarkable': 5495, 'saber': 5496, 'toothe': 5497, 'tiger': 5498, 'halt': 5499, 'cower': 5500, 'Bill': 5501, 'hoarse': 5502, 'nod': 5503, 'encouragingly': 5504, 'scrubbed': 5505, 'clock': 5506, 'mantelpiece': 5507, 'Charm': 5508, 'Cheese': 5509, 'enchantment': 5510, 'Baking': 5511, 'Minute': 5512, 'Feasts': 5513, 'clatter': 5514, 'sausage': 5515, 'Arthur': 5516, 'Friday': 5517, 'casually': 5518, 'washing': 5519, 'softened': 5520, 'bread': 5521, 'diversion': 5522, 'figure': 5523, 'nightdress': 5524, 'squeal': 5525, 'surprisingly': 5526, 'Blimey': 5527, 'yawn': 5528, 'groan': 5529, 'Gilderoy': 5530, 'Lockhart': 5531, 'Guide': 5532, 'Household': 5533, 'Pests': 5534, 'molly': 5535, 'Floo': 5536, 'powder': 5537, 'pinch': 5538, 'breeze': 5539, 'swallow': 5540, 'ash': 5541, 'giant': 5542, 'plug': 5543, 'roaring': 5544, 'deafen': 5545, 'whirl': 5546, 'tuck': 5547, 'squint': 5548, 'bacon': 5549, 'churn': 5550, 'Dizzy': 5551, 'bruise': 5552, 'gingerly': 5553, 'dimly': 5554, 'withered': 5555, 'stain': 5556, 'assortment': 5557, 'spiked': 5558, 'instrument': 5559, 'ceiling': 5560, 'dusty': 5561, 'Diagon': 5562, 'Alley': 5563, 'cabinet': 5564, 'peer': 5565, 'clang': 5566, 'identical': 5567, 'racing': 5568, 'broom': 5569, 'drum': 5570, 'Dumbledore': 5571, 'Gryffindor': 5572, 'shelf': 5573, 'skull': 5574, 'Borgin': 5575, 'assistance': 5576, 'Ministry': 5577, 'parchment': 5578, 'unravel': 5579, 'pince': 5580, 'nez': 5581, 'curl': 5582, 'meddlesome': 5583, 'surge': 5584, 'poison': 5585, 'Insert': 5586, 'thief': 5587, 'plunderer': 5588, 'favourite': 5589, 'flaring': 5590, 'haggle': 5591, 'nervously': 5592, 'hiding': 5593, 'coil': 5594, 'hangman': 5595, 'smirk': 5596, 'prop': 5597, 'necklace': 5598, 'opal': 5599, 'caution': 5600, 'Owners': 5601, 'Date': 5602, 'Come': 5603, 'darkly': 5604, 'dingy': 5605, 'alleyway': 5606, 'devote': 5607, 'Dark': 5608, 'Arts': 5609, 'Burkes': 5610, 'shrunken': 5611, 'shabby': 5612, 'jumpy': 5613, 'poisonous': 5614, 'Knockturn': 5615, 'ashe': 5616, 'aged': 5617, 'fingernail': 5618, 'leer': 5619, 'mossy': 5620, 'leapt': 5621, 'Hagrid': 5622, 'scruff': 5623, 'shriek': 5624, 'twisting': 5625, 'snow': 5626, 'marble': 5627, 'Gringotts': 5628, 'Bank': 5629, 'steer': 5630, 'yer': 5631, 'gruffly': 5632, 'brushing': 5633, 'apothecary': 5634, 'ruinin': 5635, 'cabbage': 5636, 'Ruddy': 5637, 'Muggles': 5638, 'growl': 5639, 'bushy': 5640, 'Oh': 5641, 'sprint': 5642, 'mop': 5643, 'ruddy': 5644, 'came': 5645, 'gallop': 5646, 'handbag': 5647, 'swinge': 5648, 'wildly': 5649, 'Ginny': 5650, 'tap': 5651, 'Lucius': 5652, 'tenpound': 5653, 'vault': 5654, 'goblin': 5655, 'cart': 5656, 'miniature': 5657, 'breakneck': 5658, 'dreadful': 5659, 'pile': 5660, 'Sickles': 5661, 'Galleon': 5662, 'shove': 5663, 'handful': 5664, 'coin': 5665, 'leather': 5666, 'quill': 5667, 'Lee': 5668, 'Jordan': 5669, 'Grangers': 5670, 'Leaky': 5671, 'Cauldron': 5672, 'winding': 5673, 'cobble': 5674, 'bronze': 5675, 'jangling': 5676, 'cheerfully': 5677, 'clamour': 5678, 'strawberry': 5679, 'peanut': 5680, 'slurp': 5681, 'happily': 5682, 'alley': 5683, 'fascinating': 5684, 'aloud': 5685, 'Flourish': 5686, 'Blotts': 5687, 'bookshop': 5688, 'jostle': 5689, 'proclaim': 5690, 'banner': 5691, 'GILDEROY': 5692, 'LOCKHART': 5693, 'autobiography': 5694, 'MAGICAL': 5695, 'ME': 5696, '12:30': 5697, '4:30': 5698, 'pm': 5699, 'booklist': 5700, 'Break': 5701, 'Banshee': 5702, 'sneak': 5703, 'breathless': 5704, 'pat': 5705, 'wink': 5706, 'dazzlingly': 5707, 'jaunty': 5708, 'wavy': 5709, 'camera': 5710, 'emit': 5711, 'bunione': 5712, 'bulrush': 5713, 'butt': 5714, 'tenacious': 5715, 'buckaroo': 5716, 'Wheel': 5717, 'Fortune': 5718, 'dizzy': 5719, 'Stella': 5720, 'Honest': 5721, 'Guv': 5722, 'cope': 5723, '1960': 5724, 'Skirts': 5725, 'orange': 5726, 'vampire': 5727, 'Matisse': 5728, 'peculiarly': 5729, 'assault': 5730, 'Liverpool': 5731, 'slumber': 5732, 'Sixties': 5733, 'Beatles': 5734, 'victim': 5735, 'Merseybeat': 5736, 'whelp': 5737, 'blanket': 5738, 'noctivagant': 5739, 'tow': 5740, 'seriousness': 5741, 'emotion': 5742, 'easily': 5743, 'relief': 5744, 'Daddy': 5745, 'Grandmother': 5746, 'woollen': 5747, 'balaclava': 5748, 'cocoa': 5749, 'daze': 5750, 'massacre': 5751, 'amputate': 5752, 'Snow': 5753, 'scissored': 5754, 'chrome': 5755, 'shrine': 5756, 'Chanel': 5757, 'flimsy': 5758, 'barrier': 5759, 'policeman': 5760, 'lorry': 5761, 'excite': 5762, 'impress': 5763, 'Alice': 5764, 'pill': 5765, 'gin': 5766, 'maddening': 5767, 'magnet': 5768, 'diner': 5769, 'menacingly': 5770, 'nice': 5771, 'cloth': 5772, 'carnation': 5773, 'rod': 5774, 'grissini': 5775, 'carafe': 5776, 'olive': 5777, 'Borgias': 5778, 'drain': 5779, 'Uncharacteristically': 5780, 'complacent': 5781, 'Zeus': 5782, 'yowl': 5783, 'firmament': 5784, 'Hermes': 5785, 'Hephaestus': 5786, 'lame': 5787, 'god': 5788, 'smithy': 5789, 'Athene': 5790, 'bore': 5791, '1959': 5792, 'guitar': 5793, 'drumstick': 5794, 'Husband': 5795, 'herring': 5796, 'mink': 5797, 'pearl': 5798, 'transvestite': 5799, 'silk': 5800, 'manifest': 5801, 'onion': 5802, 'torture': 5803, 'twisted': 5804, 'kipper': 5805, 'skewer': 5806, 'pair': 5807, 'knitting': 5808, 'coal': 5809, 'homemade': 5810, 'rabbit': 5811, 'bobbed': 5812, 'buckle': 5813, 'lid': 5814, 'hobby': 5815, 'underwater': 5816, 'rare': 5817, 'unexplained': 5818, 'Tha': 5819, 'birth': 5820, 'resourceful': 5821, 'soup': 5822, 'christen': 5823, 'frost': 5824, 'petrified': 5825, 'frozen': 5826, 'headmaster': 5827, 'secondary': 5828, 'inattentive': 5829, 'rugger': 5830, 'square': 5831, 'misery': 5832, 'agony': 5833, 'windscreen': 5834, 'prey': 5835, 'devilishly': 5836, 'sycamore': 5837, 'enamel': 5838, 'unmatched': 5839, 'Rayburn': 5840, 'scone': 5841, 'nightcase': 5842, 'disinfectant': 5843, 'honorary': 5844, 'toilet': 5845, 'strictly': 5846, 'forbid': 5847, 'monthly': 5848, 'dread': 5849, 'drunker': 5850, 'reluctant': 5851, 'unhygienic': 5852, 'foundation': 5853, 'Tupperware': 5854, \"why?'and\": 5855, 'mob': 5856, 'Southampton': 5857, 'pouch': 5858, 'faced': 5859, 'narcotic': 5860, 'promising': 5861, 'addicted': 5862, 'sentimentality': 5863, 'cruel': 5864, 'cruelty': 5865, 'observation': 5866, 'unable': 5867, 'bon': 5868, 'viveur': 5869, 'recipe': 5870, 'canapés': 5871, 'relative': 5872, 'dock': 5873, 'loading': 5874, 'bay': 5875, '8': 5876, 'Sun': 5877, 'Gemini': 5878, 'whilst': 5879, 'adjust': 5880, 'apparition': 5881, 'Twist': 5882, 'Wiggle': 5883, 'mobile': 5884, 'plant': 5885, 'brand': 5886, 'Danette': 5887, 'turntable': 5888, '45r.p.m': 5889, 'singing': 5890, 'scoop': 5891, 'dunny': 5892, 'sawdust': 5893, 'midden': 5894, 'memorial': 5895, 'oilskin': 5896, 'wheeze': 5897, 'whir': 5898, 'scratching': 5899, 'fluff': 5900, 'player': 5901, 'ITALIAN': 5902, 'inherit': 5903, 'crieth': 5904, 'Aha': 5905, 'wrestle': 5906, 'angel': 5907, 'unfixed': 5908, 'spine': 5909, 'solemnly': 5910, 'vision': 5911, 'intent': 5912, 'reveal': 5913, 'religion': 5914, 'superstition': 5915, 'Original': 5916, 'Sin': 5917, 'unhappiness': 5918, 'gothic': 5919, 'disposition': 5920, 'mercy': 5921, 'hood': 5922, 'upside': 5923, 'genital': 5924, 'stethoscope': 5925, 'resent': 5926, 'overweight': 5927, 'careless': 5928, 'poetically': 5929, 'besocke': 5930, 'sandalle': 5931, 'museum': 5932, 'exhibit': 5933, 'flesh': 5934, 'escaping': 5935, 'trap': 5936, 'sump': 5937, 'did': 5938, 'sanitation': 5939, 'eczema': 5940, 'asthma': 5941, 'allergic': 5942, 'reaction': 5943, 'itchy': 5944, 'bleach': 5945, 'drug': 5946, 'fume': 5947, 'nylon': 5948, 'athlete': 5949, 'weal': 5950, 'lace': 5951, 'knicker': 5952, 'secular': 5953, 'papa': 5954, 'beckon': 5955, 'unwatched': 5956, 'navigate': 5957, 'confession': 5958, 'broil': 5959, 'frighten': 5960, 'scarf': 5961, 'idle': 5962, 'poverty': 5963, 'Admiral': 5964, 'Arms': 5965, 'ration': 5966, 'unpaid': 5967, 'desperately': 5968, 'sixth': 5969, 'suitcase': 5970, 'jigsaw': 5971, 'inadequate': 5972, 'melt': 5973, 'icicle': 5974, 'kiss': 5975, 'seam': 5976, 'picnic': 5977, 'whore': 5978, 'slacken': 5979, 'cocked': 5980, 'snap': 5981, 'shovel': 5982, 'compost': 5983, 'cloaca': 5984, 'mould': 5985, 'ballad': 5986, 'swig': 5987, 'unmarked': 5988, 'billy': 5989, 'grog': 5990, 'blossom': 5991, 'generosity': 5992, 'travel': 5993, 'recklessness': 5994, 'inevitable': 5995, 'prefer': 5996, 'shipping': 5997, 'unsustainable': 5998, 'loss': 5999, 'Trident': 6000, 'Shipping': 6001, 'fund': 6002, '1809': 6003, 'bankrupt': 6004, 'director': 6005, 'celebrate': 6006, 'conceive': 6007, 'unpack': 6008, 'Bible': 6009, 'marker': 6010, 'Book': 6011, 'Job': 6012, 'tribulation': 6013, 'intensity': 6014, 'indifferent': 6015, 'undeterred': 6016, 'imitate': 6017, 'soak': 6018, 'paperwork': 6019, 'secretary': 6020, 'Remington': 6021, 'piano': 6022, 'gap': 6023, 'pier': 6024, 'privy': 6025, 'dancing': 6026, 'unnamed': 6027, 'teenage': 6028, 'vinyl': 6029, 'zip': 6030, 'polka': 6031, 'dot': 6032, 'thy': 6033, 'Cunard': 6034, 'illustrious': 6035, 'prestigious': 6036, 'Trafalgar': 6037, 'Investments': 6038, 'flagship': 6039, 'QE2': 6040, 'foie': 6041, 'gras': 6042, 'reorganisation': 6043, 'atlantic': 6044, 'headquarter': 6045, 'pelt': 6046, 'Dior': 6047, 'cruise': 6048, 'comet': 6049, 'Kohoutek': 6050, 'Czech': 6051, 'astronomer': 6052, 'millennium': 6053, 'portent': 6054, 'popular': 6055, 'atheist': 6056, 'adult': 6057, 'certificate': 6058, 'eighteen': 6059, 'lowly': 6060, 'Progress': 6061, 'Tradition': 6062, 'Integrity': 6063, 'boil': 6064, 'bath': 6065, 'packet': 6066, 'flake': 6067, 'grease': 6068, 'success': 6069, 'Battery': 6070, 'Legend': 6071, 'seek': 6072, 'Holy': 6073, 'Grail': 6074, 'forever': 6075, 'conjunction': 6076, 'timelessness': 6077, 'unfathomable': 6078, 'sighing': 6079, 'straighten': 6080, 'uncenturied': 6081, 'unquantified': 6082, 'alchemy': 6083, 'Godspeed': 6084, 'skirt': 6085, 'perfect': 6086, 'SHE': 6087, 'me': 6088, 'esteem': 6089, 'glue': 6090, 'deceit': 6091, 'pattern': 6092, 'coherence': 6093, 'convince': 6094, 'unfrightened': 6095, 'distress': 6096, 'flare': 6097, 'phosphorous': 6098, 'patrol': 6099, 'Miracle': 6100, 'Sardines': 6101, 'Gin': 6102, 'Algonquin': 6103, 'Hotel': 6104, 'Dorothy': 6105, 'Parker': 6106, 'Thurber': 6107, 'Yorker': 6108, '1957': 6109, 'reservation': 6110, 'stubbornness': 6111, 'gene': 6112, 'freezing': 6113, 'riddle': 6114, 'rhinegold': 6115, 'Rhinegold': 6116, 'Wagner': 6117, 'Ring': 6118, 'dabble': 6119, 'harden': 6120, 'frock': 6121, 'vomit': 6122, 'Mother': 6123, 'absurdity': 6124, 'plus': 6125, 'incipient': 6126, 'irresistible': 6127, 'salt': 6128, 'oyster': 6129, 'floral': 6130, 'octave': 6131, 'admire': 6132, 'soprano': 6133, 'singer': 6134, 'heel': 6135, 'warrior': 6136, 'cleavage': 6137, 'insole': 6138, 'opponent': 6139, 'Mama': 6140, 'sevenyear': 6141, 'rattling': 6142, 'fox': 6143, 'trilby': 6144, 'driver': 6145, 'struggle': 6146, 'sleigh': 6147, 'fur': 6148, 'huddle': 6149, 'hurrying': 6150, 'bark': 6151, 'geyser': 6152, 'wolf': 6153, 'sledge': 6154, 'lick': 6155, 'parma': 6156, 'tongue': 6157, 'Genesis': 6158, 'trial': 6159, 'sympathise': 6160, 'avail': 6161, 'gut': 6162, 'symmetry': 6163, 'remora': 6164, 'greek': 6165, 'fisherman': 6166, 'slim': 6167, 'greyhound': 6168, 'contour': 6169, 'starch': 6170, 'Tiffany': 6171, 'dogwood': 6172, 'suppleness': 6173, 'gift': 6174, 'artful': 6175, 'artless': 6176, 'rat': 6177, 'irish': 6178, 'Cork': 6179, 'Annual': 6180, 'Dinner': 6181, 'Dance': 6182, 'vow': 6183, 'romance': 6184, 'persistence': 6185, 'wedding': 6186, 'Ra': 6187, 'décor': 6188, 'Merseyside': 6189, 'qua': 6190, 'violent': 6191, 'shuddering': 6192, 'desirer': 6193, 'frankness': 6194, 'desirability': 6195, 'drinker': 6196, 'levitate': 6197, 'tranced': 6198, 'hypnotise': 6199, 'Institute': 6200, 'Advanced': 6201, 'Studies': 6202, 'legend': 6203, 'lust': 6204, 'Titan': 6205, 'Metis': 6206, 'eventually': 6207, 'oracle': 6208, 'overthrough': 6209, 'depose': 6210, 'Kronos': 6211, 'stroke': 6212, 'eclipse': 6213, 'gradual': 6214, 'chilliness': 6215, 'cheat': 6216, 'salary': 6217, 'insufficient': 6218, 'bonus': 6219, 'challenge': 6220, 'puny': 6221, 'achievement': 6222, 'hooded': 6223, 'instructed': 6224, 'bubble': 6225, 'Sunday': 6226, 'elevation': 6227, 'pension': 6228, 'adversary': 6229, 'footlight': 6230, 'performer': 6231, 'German': 6232, 'claque': 6233, 'frightened': 6234, 'detachment': 6235, 'weekly': 6236, 'preposterous': 6237, 'slipper': 6238, 'length': 6239, 'Polo': 6240, 'mint': 6241, 'batter': 6242, 'Oilskin': 6243, 'chessboard': 6244, 'manoeuvre': 6245, 'Martinis': 6246, 'appreciative': 6247, 'sodomise': 6248}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsBor70gV-yZ"
      },
      "source": [
        "### Create the Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 300\n",
        "EMBEDDING_DIM = embeddings.vectors.shape[1]\n",
        "\n",
        "\n",
        "# Get the embedding matrix\n",
        "vocab_size = len(word_index)  # +1 for OOV, +1 for pad\n",
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "# Add OOV and pad vectors\n",
        "embedding_matrix[0] = np.random.uniform(-0.25, 0.25, EMBEDDING_DIM)  # OOV vector\n",
        "embedding_matrix[1] = np.zeros(embeddings.vectors.shape[1])  # pad vector\n",
        "# Add pre-trained embeddings for known words\n",
        "for word, i in word_index.items():\n",
        "  try:\n",
        "      embedding_matrix[i+2] = embeddings[word]  # +2 to account for OOV and pad vectors\n",
        "  except:\n",
        "      pass"
      ],
      "metadata": {
        "id": "6VLz1vm0pttk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CsL4kFHh3KZ"
      },
      "source": [
        "### Encode the classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X']\n",
        "\n",
        "\n",
        "def mapping(my_list):\n",
        "    mapping = {}\n",
        "    for i, string in enumerate(my_list, start=1): # start from 1 so we don't mix classes with pads\n",
        "        mapping[string] = i\n",
        "    return mapping\n",
        "\n",
        "encoded_classes = mapping(classes)"
      ],
      "metadata": {
        "id": "30FulPpBpwWV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBXBHwHMWJoI"
      },
      "source": [
        "### Cut the sentences and encode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cut(sentences):\n",
        "    new=[]\n",
        "    for data in sentences:\n",
        "        new.append(([data[x:x+MAX_SEQUENCE_LENGTH] for x in range(0, len(data), MAX_SEQUENCE_LENGTH)]))\n",
        "    new = [val for sublist in new for val in sublist]\n",
        "    return new\n",
        "\n",
        "train_sentences = cut(train_tuples)\n",
        "dev_sentences = cut(dev_tuples)\n",
        "test_sentences = cut(test_tuples)"
      ],
      "metadata": {
        "id": "mTQTP3r0p1j0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function that takes tuples (x, y) and returns the corresponding x_train and y_train \n",
        "def processing_cnn(tuples):\n",
        "  \n",
        "  x = []\n",
        "  y = []\n",
        "  for sent in tuples:\n",
        "    temp_x = []\n",
        "    for word, index in sent:\n",
        "      if word in word_index:\n",
        "        temp_x.append(word_index[word])\n",
        "      else:\n",
        "        temp_x.append(word_index['oov']) # oov\n",
        "    x.append(temp_x)\n",
        "\n",
        "  for sent in tuples:\n",
        "    temp_y = []\n",
        "    for word, index in sent:\n",
        "      if index in encoded_classes:\n",
        "        temp_y.append(encoded_classes[index])\n",
        "      else:\n",
        "        temp_y.append(encoded_classes['X']) # if its something else then tag it as 'X'\n",
        "\n",
        "    y.append(temp_y)\n",
        "\n",
        "\n",
        "  return x, y\n",
        "\n",
        "  \n",
        "x_train_rnn, y_train_rnn = processing_cnn(train_sentences)\n",
        "x_dev_rnn, y_dev_rnn = processing_cnn(dev_sentences) \n",
        "x_test_rnn, y_test_rnn = processing_cnn(test_sentences) "
      ],
      "metadata": {
        "id": "BGHdw8f2p2po"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-88_mn7jiGc3"
      },
      "source": [
        "### Generate x_train and 1-hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_padded = tf.keras.preprocessing.sequence.pad_sequences(x_train_rnn, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "y_train_padded = tf.keras.preprocessing.sequence.pad_sequences(y_train_rnn, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "y_train_cat_padded = to_categorical(y_train_padded, num_classes= len(encoded_classes) + 1)\n",
        "\n",
        "x_dev_padded = tf.keras.preprocessing.sequence.pad_sequences(x_dev_rnn, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "y_dev_padded = tf.keras.preprocessing.sequence.pad_sequences(y_dev_rnn, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "y_dev_cat_padded = to_categorical(y_dev_padded, num_classes= len(encoded_classes) + 1)\n",
        "\n",
        "x_test_padded = tf.keras.preprocessing.sequence.pad_sequences(x_test_rnn, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "y_test_padded = tf.keras.preprocessing.sequence.pad_sequences(y_test_rnn, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "y_test_cat_padded = to_categorical(y_test_padded, num_classes= len(encoded_classes) + 1)"
      ],
      "metadata": {
        "id": "DNb_esESp5nP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln_KI0hpiRuf"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create and train a CNN model with (2,3,4)-gram filters using Keras functional API\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  inputs = keras.Input((x_train_padded.shape[1],),)\n",
        "  mask = keras.layers.Masking(mask_value=0)(inputs) # Mask the pads\n",
        "  embeddings_layer = keras.layers.Embedding(input_dim = vocab_size, output_dim = embeddings.vectors.shape[1],  input_length = MAX_SEQUENCE_LENGTH,\n",
        "                                            weights = [embedding_matrix], mask_zero = True, trainable = True)(mask)\n",
        "  # 2grams\n",
        "  channel_1 = Conv1D(filters = 128, kernel_size=2, padding='same')(embeddings_layer)\n",
        "  channel_1_2 = Conv1D(filters = 128, kernel_size=2, padding='same')(channel_1)\n",
        "  channel_1 = add([channel_1, channel_1_2]) # residual connection\n",
        "  channel_1 = Dropout(0.5)(channel_1) \n",
        "\n",
        "  # 3grams\n",
        "  channel_2 = Conv1D(filters = 128, kernel_size=3, padding='same')(embeddings_layer)\n",
        "  channel_2_2 = Conv1D(filters= 128, kernel_size=3, padding='same')(channel_2)\n",
        "  channel_2 = add([channel_2, channel_2_2]) # residual connection\n",
        "  channel_2 = Dropout(0.5)(channel_2)  \n",
        "\n",
        "  # 4grams\n",
        "  channel_3 = Conv1D(filters= 128, kernel_size = 4, padding='same')(embeddings_layer)\n",
        "  channel_3_2 = Conv1D(filters = 128, kernel_size = 4, padding='same')(channel_3)\n",
        "  channel_3 = add([channel_3, channel_3_2]) # residual connection\n",
        "  channel_3 = Dropout(0.5)(channel_3) \n",
        "  \n",
        "  concat = concatenate([channel_1, channel_2, channel_3])\n",
        "\n",
        "  outputs = Dense(y_train_cat_padded.shape[2], activation='softmax')(concat)  # softmax output layer   \n",
        "  cnn_model = keras.Model(inputs, outputs)\n",
        "\n",
        "  print(cnn_model.summary())\n",
        "\n",
        "  cnn_model.compile(optimizer=Adam(learning_rate = 0.001),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  if not os.path.exists('./my_CNN_checkpoint'):\n",
        "    os.makedirs('./my_CNN_checkpoint')\n",
        "\n",
        "  cnn_callbacks = [\n",
        "      keras.callbacks.ModelCheckpoint(\n",
        "          './my_CNN_checkpoint/weights.hdf5',\n",
        "          monitor='val_accuracy', \n",
        "          mode='max', \n",
        "          verbose=2,\n",
        "          save_best_only=True,\n",
        "          save_weights_only=True)\n",
        "  ]\n",
        "\n",
        "  history = cnn_model.fit(\n",
        "  x_train_padded,\n",
        "  y_train_cat_padded,\n",
        "  batch_size = 128,\n",
        "  epochs = 20,\n",
        "  validation_data = (x_dev_padded, y_dev_cat_padded),\n",
        "  callbacks= cnn_callbacks,\n",
        "  shuffle = True)\n",
        "\n",
        "\n",
        "  print(f\"Test Accuracy: {cnn_model.evaluate(x_test_padded, y_test_cat_padded)[1]:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKNMA1HHp8U8",
        "outputId": "bb0a2df8-5223-4507-9eb2-c187299122e0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " masking (Masking)              (None, 300)          0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 300, 300)     1874700     ['masking[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 300, 128)     76928       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 300, 128)     115328      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 300, 128)     153728      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 300, 128)     32896       ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 300, 128)     49280       ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 300, 128)     65664       ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 300, 128)     0           ['conv1d[0][0]',                 \n",
            "                                                                  'conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 300, 128)     0           ['conv1d_2[0][0]',               \n",
            "                                                                  'conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 300, 128)     0           ['conv1d_4[0][0]',               \n",
            "                                                                  'conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 300, 128)     0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 300, 128)     0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 300, 128)     0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 300, 384)     0           ['dropout[0][0]',                \n",
            "                                                                  'dropout_1[0][0]',              \n",
            "                                                                  'dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 300, 19)      7315        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,375,839\n",
            "Trainable params: 2,375,839\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.9089\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96718, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 91s 4s/step - loss: 0.3091 - accuracy: 0.9089 - val_loss: 0.1318 - val_accuracy: 0.9672\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9721\n",
            "Epoch 2: val_accuracy improved from 0.96718 to 0.98139, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 88s 4s/step - loss: 0.1084 - accuracy: 0.9721 - val_loss: 0.0773 - val_accuracy: 0.9814\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9839\n",
            "Epoch 3: val_accuracy improved from 0.98139 to 0.98771, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 88s 4s/step - loss: 0.0628 - accuracy: 0.9839 - val_loss: 0.0468 - val_accuracy: 0.9877\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9898\n",
            "Epoch 4: val_accuracy improved from 0.98771 to 0.99126, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 87s 4s/step - loss: 0.0385 - accuracy: 0.9898 - val_loss: 0.0321 - val_accuracy: 0.9913\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9931\n",
            "Epoch 5: val_accuracy improved from 0.99126 to 0.99312, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 98s 4s/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.0242 - val_accuracy: 0.9931\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9952\n",
            "Epoch 6: val_accuracy improved from 0.99312 to 0.99419, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 87s 4s/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.0199 - val_accuracy: 0.9942\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9965\n",
            "Epoch 7: val_accuracy improved from 0.99419 to 0.99479, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 88s 4s/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.0174 - val_accuracy: 0.9948\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9973\n",
            "Epoch 8: val_accuracy improved from 0.99479 to 0.99521, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 85s 3s/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.0159 - val_accuracy: 0.9952\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9978\n",
            "Epoch 9: val_accuracy improved from 0.99521 to 0.99537, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 87s 4s/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0149 - val_accuracy: 0.9954\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9982\n",
            "Epoch 10: val_accuracy improved from 0.99537 to 0.99544, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 90s 4s/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0145 - val_accuracy: 0.9954\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
            "Epoch 11: val_accuracy improved from 0.99544 to 0.99552, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 85s 3s/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0141 - val_accuracy: 0.9955\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9986\n",
            "Epoch 12: val_accuracy improved from 0.99552 to 0.99561, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 99s 4s/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0140 - val_accuracy: 0.9956\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy improved from 0.99561 to 0.99563, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 89s 4s/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9956\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
            "Epoch 14: val_accuracy did not improve from 0.99563\n",
            "25/25 [==============================] - 85s 3s/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0139 - val_accuracy: 0.9956\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
            "Epoch 15: val_accuracy did not improve from 0.99563\n",
            "25/25 [==============================] - 90s 4s/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0139 - val_accuracy: 0.9956\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 16: val_accuracy did not improve from 0.99563\n",
            "25/25 [==============================] - 89s 4s/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0139 - val_accuracy: 0.9956\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 17: val_accuracy improved from 0.99563 to 0.99567, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 87s 4s/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0140 - val_accuracy: 0.9957\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
            "Epoch 18: val_accuracy did not improve from 0.99567\n",
            "25/25 [==============================] - 87s 3s/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0141 - val_accuracy: 0.9957\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
            "Epoch 19: val_accuracy improved from 0.99567 to 0.99571, saving model to ./my_CNN_checkpoint/weights.hdf5\n",
            "25/25 [==============================] - 91s 4s/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0143 - val_accuracy: 0.9957\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 20: val_accuracy did not improve from 0.99571\n",
            "25/25 [==============================] - 93s 4s/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0143 - val_accuracy: 0.9957\n",
            "32/32 [==============================] - 6s 182ms/step - loss: 0.0136 - accuracy: 0.9959\n",
            "Test Accuracy: 0.99589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hnQBqjCG9o4"
      },
      "source": [
        "### Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.ylim(0,1)\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "UpAfX8Qdp_O8",
        "outputId": "0a4314a7-2240-4228-dee2-a4cfb90d2089"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpQVAtEuHFMB"
      },
      "source": [
        "### Helping Functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_dict(dictionary):\n",
        "    reversed_dict = {}\n",
        "    for key, value in dictionary.items():\n",
        "        reversed_dict[value] = key\n",
        "    return reversed_dict\n",
        "\n",
        "reversed_dictionary = reverse_dict(encoded_classes)"
      ],
      "metadata": {
        "id": "8uBrd15yqy4I"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_pads(zipped, mask = 0):\n",
        "    out_true = []\n",
        "    out_pred = []\n",
        "    for zip_i in zipped:\n",
        "        a, b = tuple(zip_i)\n",
        "        if a != mask: # Exclude -PAD- term\n",
        "          out_true.append(reversed_dictionary[a])\n",
        "          if b not in reversed_dictionary: # The model classified something as 0 which is the pad class\n",
        "            random.seed(213)\n",
        "            random_number = random.randint(1, 18)\n",
        "            b = b + random_number # classify it as something else\n",
        "            if a==b:\n",
        "              if a<10: # if randomly we get b=a change b's value because we will get a correct classification but we don't want that\n",
        "                b = b + 1\n",
        "              else:\n",
        "                b = b - 1\n",
        "          out_pred.append(reversed_dictionary[b])\n",
        "\n",
        "    return out_true, out_pred\n",
        "\n",
        "def my_classification_report(x, y, model):\n",
        "\n",
        "  y_pred = model.predict(x, verbose=1).argmax(-1)\n",
        "  y_pred_flat = [item for sublist in y_pred for item in sublist] # flatten y_pred\n",
        "  y_true_flat = [item for sublist in y for item in sublist] # flatten y_true\n",
        "\n",
        "  tuples = zip(y_true_flat, y_pred_flat)\n",
        "  y_true, y_pred = remove_pads(tuples, 0)\n",
        "  return y_true, y_pred"
      ],
      "metadata": {
        "id": "2NtvK3trq0Cf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws4K9k7DW2Wz"
      },
      "source": [
        "### Model Assessment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  inputs = keras.Input((x_train_padded.shape[1],),)\n",
        "  mask = keras.layers.Masking(mask_value=0)(inputs) # Mask the pads\n",
        "  embeddings_layer = keras.layers.Embedding(input_dim = vocab_size, output_dim = embeddings.vectors.shape[1],  input_length = MAX_SEQUENCE_LENGTH,\n",
        "                                            weights = [embedding_matrix], mask_zero = True, trainable = True)(mask)\n",
        "  # 2grams\n",
        "  channel_1 = Conv1D(filters = 128, kernel_size=2, padding='same')(embeddings_layer)\n",
        "  channel_1_2 = Conv1D(filters = 128, kernel_size=2, padding='same')(channel_1)\n",
        "  channel_1 = add([channel_1, channel_1_2])\n",
        "  channel_1 = Dropout(0.5)(channel_1) \n",
        "\n",
        "  # 3grams\n",
        "  channel_2 = Conv1D(filters = 128, kernel_size=3, padding='same')(embeddings_layer)\n",
        "  channel_2_2 = Conv1D(filters= 128, kernel_size=3, padding='same')(channel_2)\n",
        "  channel_2 = add([channel_2, channel_2_2])\n",
        "  channel_2 = Dropout(0.5)(channel_2)  \n",
        "\n",
        "  # 4grams\n",
        "  channel_3 = Conv1D(filters= 128, kernel_size = 4, padding='same')(embeddings_layer)\n",
        "  channel_3_2 = Conv1D(filters = 128, kernel_size = 4, padding='same')(channel_3)\n",
        "  channel_3 = add([channel_3, channel_3_2])\n",
        "  channel_3 = Dropout(0.5)(channel_3) \n",
        "  \n",
        "  concat = concatenate([channel_1, channel_2, channel_3])\n",
        "\n",
        "  outputs = Dense(y_train_cat_padded.shape[2], activation='softmax')(concat)  # softmax output layer   \n",
        "  cnn_model = keras.Model(inputs, outputs)\n",
        "  \n",
        "  # Load weights from the pre-trained model\n",
        "  cnn_model.load_weights(\"./my_CNN_checkpoint/weights.hdf5\")\n",
        "  cnn_model.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer= Adam(learning_rate=0.001),\n",
        "      metrics=[\"accuracy\"]\n",
        "      )\n",
        "\n",
        "y_train_true, y_train_pred_CNN = my_classification_report(x_train_padded, y_train_padded, cnn_model)\n",
        "m_train_f1_score = f1_score(y_train_true, y_train_pred_CNN, average = 'macro')\n",
        "print(\"Train f1-score: {:.2f}% \\n\".format(m_train_f1_score*100))\n",
        "\n",
        "y_dev_true, y_dev_pred_CNN = my_classification_report(x_dev_padded, y_dev_padded, cnn_model)\n",
        "m_dev_f1_score = f1_score(y_dev_true, y_dev_pred_CNN, average = 'macro')\n",
        "print(\"Evaluation f1-score: {:.2f}% \\n\".format(m_dev_f1_score*100))\n",
        "\n",
        "y_test_true, y_test_pred_CNN = my_classification_report(x_test_padded, y_test_padded, cnn_model)\n",
        "m_test_f1_score = f1_score(y_test_true, y_test_pred_CNN, average = 'macro')\n",
        "print(\"Test f1-score: {:.2f}% \\n\".format(m_test_f1_score*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlzJrxOLqKno",
        "outputId": "da775fe4-ea72-4cd4-8fdb-86e125b2dbe6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97/97 [==============================] - 21s 215ms/step\n",
            "Train f1-score: 91.42% \n",
            "\n",
            "33/33 [==============================] - 8s 241ms/step\n",
            "Evaluation f1-score: 79.76% \n",
            "\n",
            "32/32 [==============================] - 6s 201ms/step\n",
            "Test f1-score: 80.07% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9vyWiQNW5d2"
      },
      "source": [
        "### Precision, Recall, AUC, ROC-AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BE CAREFUL! This function is used only for the next chunk of code. It is used to scale the dictionary from (1-18) to (0-17) in order to avoid index error. Do not use for any other code chunk!\n",
        "def encode_1d_list(list_1d, encoding_dict):\n",
        "    encoded_list_1d = []\n",
        "    for item in list_1d:\n",
        "        encoded_list_1d.append(encoding_dict[item])\n",
        "    for i in range(len(encoded_list_1d)):\n",
        "        encoded_list_1d[i] -= 1\n",
        "    return encoded_list_1d"
      ],
      "metadata": {
        "id": "hpq6OZIsq_45"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def errorCheck(y_true, y_pred):\n",
        "\n",
        "  # Find the unique classes in y_true and y_pred\n",
        "  unique_classes = np.unique(np.concatenate((y_true, y_pred)))\n",
        "\n",
        "  # Find the classes present in y_true but not in y_pred\n",
        "  missing_classes_y_pred = unique_classes[np.in1d(unique_classes, y_true) & ~np.in1d(unique_classes, y_pred)]\n",
        "\n",
        "  # Find the classes present in y_pred but not in y_true\n",
        "  missing_classes_y_true = unique_classes[np.in1d(unique_classes, y_pred) & ~np.in1d(unique_classes, y_true)]\n",
        "\n",
        "  # Calculate the sample size before modifying y_pred and y_true and my_max to know which has the extra class\n",
        "  if len(y_pred) > len(y_true):\n",
        "    my_max = y_pred\n",
        "  else:\n",
        "    my_max = y_true\n",
        "\n",
        "  sample_size = max(len(y_pred), len(y_true))\n",
        "\n",
        "  # Modify y_pred to include all the classes present in y_true\n",
        "  for c in missing_classes_y_pred:\n",
        "      y_pred = np.append(y_pred, c)\n",
        "\n",
        "  # Modify y_true to include all the classes present in y_pred\n",
        "  for c in missing_classes_y_true:\n",
        "      y_true = np.append(y_true, c)\n",
        "  \n",
        "  y_pred_onehot = np.eye(len(unique_classes))[y_pred[:sample_size]]\n",
        "  y_true_onehot = np.eye(len(unique_classes))[y_true[:sample_size]]\n",
        "\n",
        "  return y_true, y_true_onehot, y_pred, y_pred_onehot, my_max"
      ],
      "metadata": {
        "id": "2EGtbuetrBM4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_CNN_Results(x, y_true, y_pred):\n",
        "\n",
        "  y_pred_enc = encode_1d_list(y_pred, encoded_classes)\n",
        "  y_true_enc = encode_1d_list(y_true, encoded_classes)\n",
        "\n",
        "  train_precision_score = precision_score(y_true_enc, y_pred_enc, average = None)\n",
        "  train_recall_score = recall_score(y_true_enc, y_pred_enc, average = None)\n",
        "  train_f1_score = f1_score(y_true_enc, y_pred_enc, average = None)\n",
        "\n",
        "\n",
        "  m_train_precision_score = precision_score(y_true_enc, y_pred_enc, average = 'macro')\n",
        "  m_train_recall_score = recall_score(y_true_enc, y_pred_enc, average = 'macro')\n",
        "  m_train_f1_score = f1_score(y_true_enc, y_pred_enc, average = 'macro')\n",
        "\n",
        "  # Error checking\n",
        "\n",
        "  unique_pred = np.unique(y_pred_enc)\n",
        "  unique_true = np.unique(y_true_enc)\n",
        "\n",
        "  if unique_pred.shape != unique_true.shape:\n",
        "      y_true_upd, y_true_onehot, y_pred_upd, y_pred_onehot, my_max = errorCheck(y_true_enc, y_pred_enc)\n",
        "\n",
        "  elif unique_pred.shape == unique_true.shape and (unique_pred != unique_true).any():\n",
        "      y_true_upd, y_true_onehot, y_pred_upd, y_pred_onehot, my_max = errorCheck(y_true_enc, y_pred_enc)\n",
        "\n",
        "  else:\n",
        "    my_max = y_pred_enc # y_pred or y_true is the same thing in this case\n",
        "    # One-hot encode the predicted class labels\n",
        "    y_pred_onehot = np.eye(len(np.unique(y_pred_enc)))[y_pred_enc]\n",
        "\n",
        "    # One-hot encode the true class labels\n",
        "    y_true_onehot = np.eye(len(np.unique(y_true_enc)))[y_true_enc]\n",
        "\n",
        "\n",
        "  m_train_roc_auc_score = roc_auc_score(y_true_onehot, y_pred_onehot, multi_class= 'ovr', average = 'macro')\n",
        "\n",
        "  # auc calculation is a bit more messy\n",
        "\n",
        "  classes = np.unique(my_max) # get the classes of the model\n",
        "  train_roc_auc_score = {}\n",
        "  for i in range(len(classes)):\n",
        "      c = classes[i]\n",
        "      # Prepares an auxiliar dataframe to help with the plots\n",
        "      df_x = pd.DataFrame (x) # convert list to a dataframe\n",
        "      y_proba = y_pred_onehot # calculate the probabilities\n",
        "      df_aux = df_x.copy()\n",
        "      df_aux_flat = df_aux.values.flatten()\n",
        "\n",
        "      list_aux_flat = []\n",
        "      # Delete the paddings from the dataframe and \"normalize\" the value to be in the scale 0 - 17\n",
        "      for j in df_aux_flat:\n",
        "        if j!=0:\n",
        "          list_aux_flat.append(j)\n",
        "      df_aux_upd = pd.DataFrame (list_aux_flat)\n",
        "\n",
        "      df_aux_upd['class'] = [1 if y == c else 0 for y in y_true_enc]\n",
        "      df_aux_upd['prob'] = y_proba[:, i]\n",
        "      df_aux_upd = df_aux_upd.reset_index(drop = True)\n",
        "    \n",
        "      # Calculates the ROC AUC OvR\n",
        "      train_roc_auc_score[c] = roc_auc_score(df_aux_upd['class'], df_aux_upd['prob'])\n",
        "\n",
        "  table = [['    ', 'Precision', 'Recall', 'F1', 'AUC', 'Macro-Precision', 'Macro-Recall', 'Macro-F1', 'Macro-AUC'], \n",
        "           ['ADJ', round(train_precision_score[0], 3), round(train_recall_score[0], 3), round(train_f1_score[0], 3), round(train_roc_auc_score[0], 3), '-', '-', '-', '-'],\n",
        "           ['ADP', round(train_precision_score[1], 3), round(train_recall_score[1], 3), round(train_f1_score[1], 3), round(train_roc_auc_score[1], 3), '-', '-', '-', '-'],\n",
        "           ['ADV', round(train_precision_score[2], 3), round(train_recall_score[2], 3), round(train_f1_score[2], 3), round(train_roc_auc_score[2], 3), '-', '-', '-', '-'],\n",
        "           ['AUX', round(train_precision_score[3], 3), round(train_recall_score[3], 3), round(train_f1_score[3], 3), round(train_roc_auc_score[3], 3), '-', '-', '-', '-'],\n",
        "           ['CCONJ', round(train_precision_score[4], 3), round(train_recall_score[4], 3), round(train_f1_score[4], 3), round(train_roc_auc_score[4], 3), '-', '-', '-', '-'],\n",
        "           ['DET', round(train_precision_score[5], 3), round(train_recall_score[5], 3), round(train_f1_score[5], 3), round(train_roc_auc_score[5], 3), '-', '-', '-', '-'],\n",
        "           ['INTJ', round(train_precision_score[6], 3), round(train_recall_score[6], 3), round(train_f1_score[6], 3), round(train_roc_auc_score[6], 3), '-', '-', '-', '-'],\n",
        "           ['NOUN', round(train_precision_score[7], 3), round(train_recall_score[7], 3), round(train_f1_score[7], 3), round(train_roc_auc_score[7], 3), '-', '-', '-', '-'],\n",
        "           ['NUM', round(train_precision_score[8], 3), round(train_recall_score[8], 3), round(train_f1_score[8], 3), round(train_roc_auc_score[8], 3), '-', '-', '-', '-'],\n",
        "           ['PART', round(train_precision_score[9], 3), round(train_recall_score[9], 3), round(train_f1_score[9], 3), round(train_roc_auc_score[9], 3), '-', '-', '-', '-'],\n",
        "           ['PRON', round(train_precision_score[10], 3), round(train_recall_score[10], 3), round(train_f1_score[10], 3), round(train_roc_auc_score[10], 3), '-', '-', '-', '-'],\n",
        "           ['PROPN', round(train_precision_score[11], 3), round(train_recall_score[11], 3), round(train_f1_score[11], 3), round(train_roc_auc_score[11], 3), '-', '-', '-', '-'],\n",
        "           ['PUNCT', round(train_precision_score[12], 3), round(train_recall_score[12], 3), round(train_f1_score[12], 3), round(train_roc_auc_score[12], 3), '-', '-', '-', '-'],\n",
        "           ['SCONJ', round(train_precision_score[13], 3), round(train_recall_score[13], 3), round(train_f1_score[13], 3), round(train_roc_auc_score[13], 3), '-', '-', '-', '-'],\n",
        "           ['SPACE', round(train_precision_score[14], 3), round(train_recall_score[14], 3), round(train_f1_score[14], 3), round(train_roc_auc_score[14], 3), '-', '-', '-', '-'],\n",
        "           ['SYM', round(train_precision_score[15], 3), round(train_recall_score[15], 3), round(train_f1_score[15], 3), round(train_roc_auc_score[15], 3), '-', '-', '-', '-'],\n",
        "           ['VERB', round(train_precision_score[16], 3), round(train_recall_score[16], 3), round(train_f1_score[16], 3), round(train_roc_auc_score[16], 3), '-', '-', '-', '-'],\n",
        "           ['X', round(train_precision_score[17], 3), round(train_recall_score[17], 3), round(train_f1_score[17], 3), round(train_roc_auc_score[17], 3), '-', '-', '-', '-'],\n",
        "           ['Total', '-', '-','-','-', round(m_train_precision_score, 3), round(m_train_recall_score, 3), round(m_train_f1_score, 3), round(m_train_roc_auc_score, 3)]]\n",
        "\n",
        "  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\n",
        "  return table"
      ],
      "metadata": {
        "id": "V_88pICLrC2z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CNN ---------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "print(\"The training results: \\n\")\n",
        "cnn_train_table = calculate_CNN_Results(x_train_padded, y_train_true, y_train_pred_CNN)\n",
        "\n",
        "print(\"The evaluation results: \\n\")\n",
        "cnn_dev_table = calculate_CNN_Results(x_dev_padded, y_dev_true, y_dev_pred_CNN)\n",
        "\n",
        "print(\"The test results: \\n\")\n",
        "cnn_test_table = calculate_CNN_Results(x_test_padded, y_test_true, y_test_pred_CNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC-1rDOwqPIR",
        "outputId": "da8faf7e-3308-4181-b351-cd7871011285"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN ---------------------------------------------------------------------------------------------------------\n",
            "\n",
            "The training results: \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│        │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │ Macro-AUC   │\n",
            "╞════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ ADJ    │ 0.987       │ 0.983    │ 0.985 │ 0.991 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADP    │ 0.989       │ 0.993    │ 0.991 │ 0.996 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADV    │ 0.975       │ 0.968    │ 0.972 │ 0.984 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ AUX    │ 0.994       │ 0.993    │ 0.994 │ 0.996 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ CCONJ  │ 0.997       │ 0.998    │ 0.998 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ DET    │ 0.998       │ 0.999    │ 0.998 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ INTJ   │ 0.96        │ 0.898    │ 0.928 │ 0.949 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NOUN   │ 0.991       │ 0.995    │ 0.993 │ 0.997 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NUM    │ 0.987       │ 0.989    │ 0.988 │ 0.995 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PART   │ 0.993       │ 0.997    │ 0.995 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PRON   │ 0.996       │ 0.995    │ 0.995 │ 0.997 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PROPN  │ 0.999       │ 0.995    │ 0.997 │ 0.997 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PUNCT  │ 0.999       │ 1.0      │ 0.999 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SCONJ  │ 0.962       │ 0.966    │ 0.964 │ 0.983 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SPACE  │ 1.0         │ 1.0      │ 1.0   │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SYM    │ 1.0         │ 0.5      │ 0.667 │ 0.75  │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ VERB   │ 0.992       │ 0.989    │ 0.991 │ 0.994 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ X      │ 0.0         │ 0.0      │ 0.0   │ 0.5   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total  │ -           │ -        │ -     │ -     │ 0.934             │ 0.903          │ 0.914      │ 0.951       │\n",
            "╘════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n",
            "The evaluation results: \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│        │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │ Macro-AUC   │\n",
            "╞════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ ADJ    │ 0.888       │ 0.798    │ 0.841 │ 0.896 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADP    │ 0.956       │ 0.973    │ 0.965 │ 0.984 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADV    │ 0.914       │ 0.813    │ 0.861 │ 0.905 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ AUX    │ 0.987       │ 0.988    │ 0.987 │ 0.994 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ CCONJ  │ 0.995       │ 0.995    │ 0.995 │ 0.997 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ DET    │ 0.979       │ 0.99     │ 0.984 │ 0.994 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ INTJ   │ 0.369       │ 0.8      │ 0.505 │ 0.899 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NOUN   │ 0.856       │ 0.933    │ 0.893 │ 0.951 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NUM    │ 0.878       │ 0.827    │ 0.852 │ 0.913 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PART   │ 0.917       │ 0.956    │ 0.936 │ 0.977 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PRON   │ 0.974       │ 0.983    │ 0.979 │ 0.99  │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PROPN  │ 0.911       │ 0.687    │ 0.784 │ 0.842 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PUNCT  │ 0.992       │ 1.0      │ 0.996 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SCONJ  │ 0.858       │ 0.887    │ 0.873 │ 0.942 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SPACE  │ 1.0         │ 1.0      │ 1.0   │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SYM    │ 0.0         │ 0.0      │ 0.0   │ 0.5   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ VERB   │ 0.907       │ 0.909    │ 0.908 │ 0.949 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ X      │ 0.0         │ 0.0      │ 0.0   │ 0.5   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total  │ -           │ -        │ -     │ -     │ 0.799             │ 0.808          │ 0.798      │ 0.902       │\n",
            "╘════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n",
            "The test results: \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│        │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │ Macro-AUC   │\n",
            "╞════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ ADJ    │ 0.859       │ 0.79     │ 0.823 │ 0.891 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADP    │ 0.956       │ 0.971    │ 0.963 │ 0.983 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADV    │ 0.907       │ 0.81     │ 0.856 │ 0.903 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ AUX    │ 0.97        │ 0.989    │ 0.979 │ 0.994 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ CCONJ  │ 0.993       │ 0.996    │ 0.994 │ 0.998 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ DET    │ 0.979       │ 0.99     │ 0.984 │ 0.994 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ INTJ   │ 0.413       │ 0.705    │ 0.521 │ 0.851 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NOUN   │ 0.862       │ 0.917    │ 0.889 │ 0.945 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NUM    │ 0.895       │ 0.895    │ 0.895 │ 0.947 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PART   │ 0.921       │ 0.973    │ 0.946 │ 0.986 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PRON   │ 0.979       │ 0.982    │ 0.98  │ 0.99  │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PROPN  │ 0.891       │ 0.675    │ 0.768 │ 0.835 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PUNCT  │ 0.992       │ 0.999    │ 0.995 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SCONJ  │ 0.874       │ 0.929    │ 0.901 │ 0.963 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SPACE  │ 1.0         │ 1.0      │ 1.0   │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SYM    │ 0.0         │ 0.0      │ 0.0   │ 0.5   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ VERB   │ 0.912       │ 0.922    │ 0.917 │ 0.955 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ X      │ 0.0         │ 0.0      │ 0.0   │ 0.5   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total  │ -           │ -        │ -     │ -     │ 0.8               │ 0.808          │ 0.801      │ 0.902       │\n",
            "╘════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4gXJQi5W9L0"
      },
      "source": [
        "### Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  \n",
        "  def nn_model(optimizer = 'Adam', dropout = 0.5, trainable = True, filters = 128, learning_rate = 0.01):\n",
        "    inputs = keras.Input((x_train_padded.shape[1],),)\n",
        "    mask = keras.layers.Masking(mask_value=0)(inputs) # Mask the pads\n",
        "    embeddings_layer = keras.layers.Embedding(input_dim = vocab_size, output_dim = embeddings.vectors.shape[1],  input_length = MAX_SEQUENCE_LENGTH,\n",
        "                                            weights = [embedding_matrix], mask_zero = True, trainable = trainable)(mask)\n",
        "    # 2grams\n",
        "    channel_1 = Conv1D(filters = filters, kernel_size=2, padding='same')(embeddings_layer)\n",
        "    channel_1_2 = Conv1D(filters = filters, kernel_size=2, padding='same')(channel_1)\n",
        "    channel_1 = add([channel_1, channel_1_2]) # residual connection\n",
        "    channel_1 = Dropout(dropout)(channel_1) \n",
        "\n",
        "    # 3grams\n",
        "    channel_2 = Conv1D(filters = filters, kernel_size=3, padding='same')(embeddings_layer)\n",
        "    channel_2_2 = Conv1D(filters= filters, kernel_size=3, padding='same')(channel_2)\n",
        "    channel_2 = add([channel_2, channel_2_2]) # residual connection\n",
        "    channel_2 = Dropout(dropout)(channel_2)  \n",
        "\n",
        "    # 4grams\n",
        "    channel_3 = Conv1D(filters= filters, kernel_size = 4, padding='same')(embeddings_layer)\n",
        "    channel_3_2 = Conv1D(filters = filters, kernel_size = 4, padding='same')(channel_3)\n",
        "    channel_3 = add([channel_3, channel_3_2]) # residual connection\n",
        "    channel_3 = Dropout(dropout)(channel_3) \n",
        "  \n",
        "    concat = concatenate([channel_1, channel_2, channel_3])\n",
        "    flatten = keras.layers.Flatten()(concat)\n",
        "    outputs = Dense(y_train_cat_padded.shape[2], activation='softmax')(flatten)  # softmax output layer   \n",
        "    cnn_model = keras.Model(inputs, outputs)\n",
        "\n",
        "    print(cnn_model.summary())\n",
        "    cnn_model.compile(optimizer = tune_lr(optimizer, learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return cnn_model\n",
        "\n",
        "  def tune_lr(optimizer, learning_rate):\n",
        "    optimizerDict = {'Adam': Adam(learning_rate=learning_rate), 'SGD': SGD(learning_rate=learning_rate), 'RMSprop': RMSprop(learning_rate=learning_rate)}\n",
        "    result = optimizerDict[optimizer]\n",
        "    \n",
        "    return result\n",
        "\n",
        "  filters = [64, 128, 256]\n",
        "  learning_rate = [0.001, 0.01, 0.1]\n",
        "  optimizer = ['SGD', 'Adam']\n",
        "  trainable = [True, False]\n",
        "  dropout = [0.2, 0.4, 0.5]\n",
        "  param_grid = dict(optimizer = optimizer, dropout = dropout, trainable = trainable, filters = filters, learning_rate = learning_rate)\n",
        "  clf = KerasClassifier(build_fn = nn_model, epochs = 5, verbose = 2, optimizer = optimizer, dropout = dropout, trainable = trainable,\n",
        "                        filters = filters, learning_rate = learning_rate)\n",
        "  cnn_model = RandomizedSearchCV(estimator= clf, cv = 5, param_distributions = param_grid, n_jobs=-1,verbose = 2,random_state=1234)\n",
        "  nsamples, nx, ny = y_dev_cat_padded.shape\n",
        "  y_dev_cat_padded_2d = y_dev_cat_padded[:, 0, :]  # 1045, 300, 19 --> 1045, 19\n",
        "  cnn_model.fit(x_dev_padded, y_dev_cat_padded_2d)\n",
        "\n",
        "print(\"Best estimator \\n\", cnn_model.best_estimator_)\n",
        "print(\"Best score \\n\", cnn_model.best_score_)\n",
        "print(\"Best params \\n\", cnn_model.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3f6boIBqQzF",
        "outputId": "d8fe762e-e2d6-49cb-8d39-f36534b4496f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " masking_2 (Masking)            (None, 300)          0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 300, 300)     1874700     ['masking_2[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 300, 64)      38464       ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 300, 64)      57664       ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 300, 64)      76864       ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 300, 64)      8256        ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 300, 64)      12352       ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 300, 64)      16448       ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 300, 64)      0           ['conv1d_12[0][0]',              \n",
            "                                                                  'conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 300, 64)      0           ['conv1d_14[0][0]',              \n",
            "                                                                  'conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 300, 64)      0           ['conv1d_16[0][0]',              \n",
            "                                                                  'conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 300, 64)      0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 300, 64)      0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 300, 64)      0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 300, 192)     0           ['dropout_6[0][0]',              \n",
            "                                                                  'dropout_7[0][0]',              \n",
            "                                                                  'dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 57600)        0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 19)           1094419     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,179,167\n",
            "Trainable params: 3,179,167\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "33/33 - 16s - loss: 442.1663 - accuracy: 0.1359 - 16s/epoch - 498ms/step\n",
            "Epoch 2/5\n",
            "33/33 - 17s - loss: 23.8161 - accuracy: 0.2871 - 17s/epoch - 504ms/step\n",
            "Epoch 3/5\n",
            "33/33 - 14s - loss: 2.5049 - accuracy: 0.7301 - 14s/epoch - 438ms/step\n",
            "Epoch 4/5\n",
            "33/33 - 14s - loss: 0.6781 - accuracy: 0.8928 - 14s/epoch - 438ms/step\n",
            "Epoch 5/5\n",
            "33/33 - 14s - loss: 0.0752 - accuracy: 0.9828 - 14s/epoch - 438ms/step\n",
            "Best estimator \n",
            " KerasClassifier(\n",
            "\tmodel=None\n",
            "\tbuild_fn=<function nn_model at 0x7fe9e67a8e50>\n",
            "\twarm_start=False\n",
            "\trandom_state=None\n",
            "\toptimizer=adam\n",
            "\tloss=None\n",
            "\tmetrics=None\n",
            "\tbatch_size=None\n",
            "\tvalidation_batch_size=None\n",
            "\tverbose=2\n",
            "\tcallbacks=None\n",
            "\tvalidation_split=0.0\n",
            "\tshuffle=True\n",
            "\trun_eagerly=False\n",
            "\tepochs=5\n",
            "\tdropout=0.4\n",
            "\ttrainable=True\n",
            "\tfilters=64\n",
            "\tlearning_rate=0.01\n",
            "\tclass_weight=None\n",
            ")\n",
            "Best score \n",
            " 0.6019138755980862\n",
            "Best params \n",
            " {'trainable': True, 'optimizer': 'adam', 'learning_rate': 0.01, 'filters': 64, 'dropout': 0.4}\n"
          ]
        }
      ]
    }
  ]
}