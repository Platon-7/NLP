{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOE+w4+T9i/PeLasH+Sl++7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRXODnxy0Thc"
      },
      "source": [
        "# **POS Tagging**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K8IUY23KfIf"
      },
      "source": [
        "# PART 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqHnUDfH1eh5"
      },
      "source": [
        "## Installs, Imports and Paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HXpfiRC3FtJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit_learn\n",
        "!pip install nltk\n",
        "!pip install --upgrade wandb\n",
        "!pip install datasets\n",
        "!pip install tensorflow\n",
        "!pip install scipy\n",
        "!pip install scikeras\n",
        "!pip install numpy\n",
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tRaa2HCLtFVQ",
        "outputId": "e2ed389c-6e1e-4847-8c7a-62eb50c7e6e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.15.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=b93ff03b3d71afa432949379bef85c06e9113b3dfabc8090de2255e671559c8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, urllib3, smmap, setproctitle, docker-pycreds, sentry-sdk, gitdb, GitPython, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.15.0 setproctitle-1.3.2 smmap-5.0.0 urllib3-1.26.14 wandb-0.13.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, multiprocess, responses, huggingface-hub, datasets\n",
            "Successfully installed datasets-2.9.0 huggingface-hub-0.12.1 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (23.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pickle\n",
        "import random\n",
        "import nltk\n",
        "import wandb\n",
        "import os\n",
        "import string\n",
        "import spacy\n",
        "import keras\n",
        "import urllib.request, zipfile\n",
        "from collections import Counter\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from sklearn import preprocessing\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.models import FastText\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "from pandas.core.missing import find_valid_index\n",
        "from sklearn.model_selection import learning_curve, GridSearchCV\n",
        "from tabulate import tabulate\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "stemmer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "fdNnHOMTtGbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR0KP_9atI8O",
        "outputId": "03aa6942-6cae-49b8-9e01-8c69d42ebb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_LOG_MODEL=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiUcQHKutJgR",
        "outputId": "6fda9dde-c35c-4589-92d7-e01b94056e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_LOG_MODEL=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./POS-Tagging'):\n",
        "  os.makedirs('./POS-Tagging')\n",
        "os.chdir('./POS-Tagging')\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "xeQfE46UtKqg",
        "outputId": "a22feb44-f138-4d09-c42b-c3a27f8c6142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7772d027-55c7-4035-b0ee-41c1d3e9a3f9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7772d027-55c7-4035-b0ee-41c1d3e9a3f9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving en_lines-ud-dev.txt to en_lines-ud-dev.txt\n",
            "Saving en_lines-ud-test.txt to en_lines-ud-test.txt\n",
            "Saving en_lines-ud-train.txt to en_lines-ud-train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL_exeMt2Gxn"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def myData(name, percentage):\n",
        "  with open(name, \"r\") as myfile:\n",
        "    my_data = myfile.read()\n",
        "    cropped_data = my_data[:int(len(my_data)*percentage)]\n",
        "\n",
        "  return cropped_data\n",
        "\n",
        "\n",
        "train_data = myData(\"en_lines-ud-train.txt\", 1) # as a second parameter pass the percentage of the data you want\n",
        "dev_data = myData(\"en_lines-ud-dev.txt\", 1)\n",
        "test_data = myData(\"en_lines-ud-test.txt\", 1)"
      ],
      "metadata": {
        "id": "I86I5oRJtOQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.add_pipe('sentencizer')\n",
        "\n",
        "# tokenize and lemmatize the data and finally create x-y list\n",
        "def processing(my_data):\n",
        "  \n",
        "  tuples=[]\n",
        "  x = []\n",
        "  y = []\n",
        "  for sent in my_data.sents:\n",
        "    partial_tuple=[]\n",
        "    temp_x = []\n",
        "    temp_y = []\n",
        "    for token in sent:\n",
        "      if token.pos_:\n",
        "        temp_x.append(token.lemma_)\n",
        "        temp_y.append(token.pos_)\n",
        "        partial_tuple.append((token.lemma_, token.pos_))\n",
        "    tuples.append(partial_tuple)\n",
        "    x.append(temp_x)\n",
        "    y.append(temp_y)\n",
        "  return tuples, x, y\n",
        "\n",
        "train_tuples, x_train, y_train = processing(nlp(train_data))\n",
        "dev_tuples, x_dev, y_dev = processing(nlp(dev_data))\n",
        "test_tuples, x_test, y_test = processing(nlp(test_data))"
      ],
      "metadata": {
        "id": "faxWt9i7tPXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SToZwv8H2XKw"
      },
      "source": [
        "## Loading Pre-trained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./embeddings'):\n",
        "  os.makedirs('./embeddings')\n",
        "\n",
        "urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip', './embeddings/wiki-news-300d-1M.vec.zip')\n",
        "zip_ref = zipfile.ZipFile('./embeddings/wiki-news-300d-1M.vec.zip', 'r')\n",
        "zip_ref.extractall('./embeddings')\n",
        "zip_ref.close()\n",
        "\n",
        "embs_path = './embeddings/wiki-news-300d-1M.vec'\n",
        "embeddings = KeyedVectors.load_word2vec_format(embs_path, binary=False)"
      ],
      "metadata": {
        "id": "6Rxz0ASvtScF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTaWRJJf2gs5"
      },
      "source": [
        "## Data Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim = embeddings.vectors.shape[1] # the width of the E matrix\n",
        "pad = np.zeros(dim) # Pad vector\n",
        "np.random.seed(3) # For reproducibility \n",
        "oov =  np.random.uniform(-0.25, 0.25, dim) # Out-of-vocabulary vector, assign relatively small values\n",
        "\n",
        "def features_embs(sentence, index, window=1):\n",
        "    \"\"\" sentence: [w1, w2, ...],\n",
        "        index: the index of the word, \n",
        "        window: number of places left and right of the classified word \"\"\"\n",
        "    unknown = 0\n",
        "    vec = np.array([]) # define the vector\n",
        "    for i in range(index-window,index+window+1):\n",
        "        if i<0 or i>(len(sentence)-1):\n",
        "            vec = np.append(vec, pad) # for word indices out of sentence bounds, append pad vector which contains only zeros \n",
        "            continue\n",
        "        try:\n",
        "            vec = np.append(vec, embeddings[sentence[i]]) # if you found the correct pre-trained embedding assign the corresponding values\n",
        "        except:\n",
        "            vec = np.append(vec, oov) #if word is not in embedding model append the out-of-vocabulary vector\n",
        "            unknown +=1 # count the total words of the sentence that were out-of-vocabulary\n",
        "                \n",
        "    return vec, unknown"
      ],
      "metadata": {
        "id": "sPDD0JXDtVCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features_basic(sentence, index):\n",
        "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
        "    return {\n",
        "        'nb_terms': len(sentence),        \n",
        "        'word': sentence[index],\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(sentence) - 1,\n",
        "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
        "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
        "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
        "        'prefix-1': sentence[index][0],\n",
        "        'prefix-2': sentence[index][:2],\n",
        "        'prefix-3': sentence[index][:3],\n",
        "        'suffix-1': sentence[index][-1],\n",
        "        'suffix-2': sentence[index][-2:],\n",
        "        'suffix-3': sentence[index][-3:],\n",
        "        'i-1_prefix-3': '' if index == 0 else sentence[index-1][:3],        \n",
        "        'i-1_suffix-3': '' if index == 0 else sentence[index-1][-3:],\n",
        "        'i+1_prefix-3': '' if index == len(sentence) - 1 else sentence[index+1][:3],        \n",
        "        'i+1_suffix-3': '' if index == len(sentence) - 1 else sentence[index+1][-3:],        \n",
        "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
        "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
        "        'has_hyphen': '-' in sentence[index],\n",
        "        'is_numeric': sentence[index].isdigit(),\n",
        "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:],\n",
        "    }"
      ],
      "metadata": {
        "id": "rOM55N5ItVby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_dataset(tuples, x, y, window):\n",
        "    i=0\n",
        "    count = 0\n",
        "    temp_x, temp_y = [], []\n",
        "    for sent_index, tagged in enumerate(tuples):\n",
        "        for index in range(len(tagged)):\n",
        "            temp_x.append([features_embs(x[count], index, window)[0], features_basic(x[count], index)])\n",
        "            temp_y.append(tagged[index][1])\n",
        "            k = features_embs(x[count], index, window)[1]\n",
        "            i += k\n",
        "        count += 1\n",
        "    return temp_x, temp_y, i"
      ],
      "metadata": {
        "id": "t7hazrK0tYQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(train_tuples, train_x, train_y, dev_tuples, dev_x, dev_y,  test_tuples, test_x, test_y, window=1):\n",
        "              \n",
        "    x_train, y_train, unk_train = transform_to_dataset(train_tuples, train_x, train_y, window=window)\n",
        "    x_train = [x[0] for x in x_train]\n",
        "    x_train = np.asarray(x_train)\n",
        "\n",
        "    x_dev, y_dev, unk_dev = transform_to_dataset(dev_tuples, dev_x, dev_y, window=window)\n",
        "    x_dev = [x[0] for x in x_dev]\n",
        "    x_dev = np.asarray(x_dev)        \n",
        "        \n",
        "    x_test, y_test, unk_test = transform_to_dataset(test_tuples, test_x, test_y, window=window)\n",
        "    x_test = [x[0] for x in x_test]\n",
        "    x_test = np.asarray(x_test)\n",
        "        \n",
        "    print('Train shape:', x_train.shape)\n",
        "    print('Validation shape:', x_dev.shape)\n",
        "    print('Test shape:', x_test.shape)\n",
        "    print('Found %s unknown words in train set %s unknown words in validation set and %s unknown words in test set' % (unk_train, unk_dev, unk_test))\n",
        "    return x_train, y_train, x_dev, y_dev, x_test, y_test"
      ],
      "metadata": {
        "id": "anE76LKBtZ11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_mod, y_train_mod, x_dev_mod, y_dev_mod, x_test_mod, y_test_mod = vectorize(train_tuples, x_train, y_train, \n",
        "                                                                dev_tuples, x_dev,\n",
        "                                                                y_dev,test_tuples, x_test, y_test, window=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InACF4eAtbBN",
        "outputId": "8bdebeb3-f96f-45ff-9b86-ba79c2023b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (61578, 900)\n",
            "Validation shape: (20650, 900)\n",
            "Test shape: (19028, 900)\n",
            "Found 11214 unknown words in train set 3814 unknown words in validation set and 3466 unknown words in test set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X']\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "y_train_lb = le.fit_transform(y_train_mod)\n",
        "y_dev_lb = le.transform(y_dev_mod)\n",
        "y_test_lb = le.transform(y_test_mod)\n",
        "\n",
        "y_train_cat = keras.utils.to_categorical(y_train_lb)\n",
        "y_dev_cat = keras.utils.to_categorical(y_dev_lb)\n",
        "y_test_cat = keras.utils.to_categorical(y_test_lb)\n",
        "\n",
        "print(np.unique(y_train_lb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jti05tJ5tcPj",
        "outputId": "6061cb30-b1ec-4cbc-de2f-3e57dec7f307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o54hArZH9n-"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dummyClassifier(x, y): # {'is' : {'verb': 3, 'noun': 4}, 'hi' : {'adjective': 6}}\n",
        "  my_dict = {}\n",
        "  unk_count = {}\n",
        "  count_sents = 0\n",
        "  for sent in x: # for every sentence in sentences\n",
        "    count_words = 0\n",
        "    for word in sent: # for every word in a sentence\n",
        "      temp_dict = {} \n",
        "      if word in my_dict.keys(): # if the word has been encountered again\n",
        "\n",
        "        if y[count_sents][count_words] in my_dict[word]: # if the tag has been encountered again\n",
        "          temp_dict = my_dict[word]\n",
        "          sum = temp_dict.get(y[count_sents][count_words]) + 1 # add 1 to the sum of the tag\n",
        "          temp_dict.update({y[count_sents][count_words]: sum})  \n",
        "          my_dict.update({word: temp_dict}) # add to the big dictionary the new sub-dict\n",
        "          sum2 = unk_count.get(y[count_sents][count_words]) + 1 # {'verb' = 3000 + 1}\n",
        "          unk_count.update({y[count_sents][count_words]: sum2})\n",
        "        else:\n",
        "          temp_dict = my_dict[word] # {'verb' : 4}\n",
        "          temp_dict[y[count_sents][count_words]] = 1 # { 'verb': 4, 'noun' = 1}\n",
        "          my_dict[word] = temp_dict\n",
        "          if y[count_sents][count_words] in unk_count:\n",
        "            sum2 = unk_count.get(y[count_sents][count_words]) + 1 # {'verb' = 3000 + 1}\n",
        "            unk_count.update({y[count_sents][count_words]: sum2})\n",
        "          else:\n",
        "            unk_count.update({y[count_sents][count_words]: 1})\n",
        "      else:\n",
        "        my_dict[word] = {y[count_sents][count_words]: 1}\n",
        "        if y[count_sents][count_words] in unk_count:\n",
        "          sum = unk_count.get(y[count_sents][count_words]) + 1 # {'verb' = 3000 + 1}\n",
        "          unk_count.update({y[count_sents][count_words]: sum})\n",
        "        else:\n",
        "          unk_count.update({y[count_sents][count_words]: 1})\n",
        "      count_words += 1\n",
        "    count_sents += 1\n",
        "\n",
        "  return my_dict, unk_count"
      ],
      "metadata": {
        "id": "Q-ZaLUiRteHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(x, y):\n",
        "  clas = []\n",
        "  pred_y = []\n",
        "  count_sents = 0\n",
        "  for sent in x:\n",
        "    count_words = 0\n",
        "    sentences = []\n",
        "    for word in sent:\n",
        "      if word in baseline:\n",
        "        sum = 0\n",
        "        for tag in baseline[word]:\n",
        "          if sum < baseline[word].get(tag):\n",
        "            sum = baseline[word].get(tag)\n",
        "            max = tag\n",
        "        sentences.append((word, max))\n",
        "        pred_y.append(max)\n",
        "      else:\n",
        "        sum = 0\n",
        "        for tag in unknown:\n",
        "          if sum < unknown.get(tag):\n",
        "            sum = unknown.get(tag)\n",
        "            max = tag\n",
        "        sentences.append((word,max))\n",
        "        pred_y.append(max)\n",
        "      count_words += 1\n",
        "    clas.append(sentences)\n",
        "    count_sents += 1\n",
        "\n",
        "  return clas, pred_y"
      ],
      "metadata": {
        "id": "1M0iF5Dqtf2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "# The dummy classifier always predicts the 'most frequent' class\n",
        "baseline, unknown = dummyClassifier(x_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "train_predictions, pred_train_y = classify(x_train, y_train)\n",
        "dummy_score = f1_score(y_train_mod, pred_train_y, average='macro')\n",
        "print(\"Train f1-score: {:.2f}%\".format(dummy_score*100))\n",
        "\n",
        "dev_predictions, pred_dev_y = classify(x_dev, y_dev)\n",
        "dummy_score = f1_score(y_dev_mod, pred_dev_y, average='macro')\n",
        "print(\"Evaluation f1-score: {:.2f}% \\n\".format(dummy_score*100))\n",
        "\n",
        "test_predictions, pred_test_y = classify(x_test, y_test)\n",
        "dummy_score = f1_score(y_test_mod, pred_test_y, average='macro')\n",
        "print(\"Test f1-score: {:.2f}% \\n\".format(dummy_score*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEw8nKMOthG9",
        "outputId": "063040bf-5932-4737-80ae-906fd739f87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train f1-score: 88.37%\n",
            "Evaluation f1-score: 81.41% \n",
            "\n",
            "Test f1-score: 76.95% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b82XejkR45dg"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, valid_data):\n",
        "        super(Metrics, self).__init__()\n",
        "        self.validation_data = valid_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
        "        val_targ = self.validation_data[1]\n",
        "        \n",
        "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
        "            val_targ = np.argmax(val_targ, -1)\n",
        "        val_targ = tf.cast(val_targ,dtype=tf.float32)\n",
        "        \n",
        "        _val_f1 = f1_score(val_targ, val_predict,average='micro')\n",
        "        _val_recall = recall_score(val_targ, val_predict,average='micro')\n",
        "        _val_precision = precision_score(val_targ, val_predict,average='micro')\n",
        "\n",
        "        logs['val_f1'] = _val_f1\n",
        "        logs['val_recall'] = _val_recall\n",
        "        logs['val_precision'] = _val_precision\n",
        "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
        "        return"
      ],
      "metadata": {
        "id": "KJL9u8wUtlJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  mlp_model = Sequential()\n",
        "  mlp_model.add(Dense(512, input_dim=x_train_mod.shape[1] , activation='relu', kernel_constraint=MaxNorm(3.0)))\n",
        "  mlp_model.add(Dropout(0.5))\n",
        "  mlp_model.add(Dense(256,  activation='relu', kernel_constraint=MaxNorm(2.0)))\n",
        "  mlp_model.add(Dropout(0.5))\n",
        "  mlp_model.add(Dense(y_train_cat.shape[1], activation='softmax'))\n",
        "\n",
        "  print(mlp_model.summary())\n",
        "  \n",
        "  #Configures the model for training.\n",
        "  #CategoricalCrossentropy: Computes the crossentropy loss between the labels and predictions.\n",
        "  mlp_model.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer=Adam(learning_rate=0.001),\n",
        "      metrics=[\"accuracy\"]\n",
        "      )\n",
        "\n",
        "  if not os.path.exists('./my_MLP_checkpoint'):\n",
        "    os.makedirs('./my_MLP_checkpoint')\n",
        "\n",
        "  # Callback to save the Keras model or model weights at some frequency.  \n",
        "  checkpoint = ModelCheckpoint(\n",
        "      './my_MLP_checkpoint/weights.hdf5',\n",
        "      monitor='val_accuracy', \n",
        "      mode='max', \n",
        "      verbose=2,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=True\n",
        "      )\n",
        "  \n",
        "\n",
        "  history = mlp_model.fit(\n",
        "      x_train_mod, \n",
        "      y_train_cat,\n",
        "      validation_data=(x_dev_mod, y_dev_cat),\n",
        "      batch_size=64,\n",
        "      epochs=15,\n",
        "      shuffle=True,\n",
        "      callbacks=[Metrics(valid_data=(x_dev_mod, y_dev_cat)), checkpoint]\n",
        "      )\n",
        "\n",
        "  print(f\"Test Accuracy: {mlp_model.evaluate(x_test_mod, y_test_cat)[1]:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzZWClVUtmNX",
        "outputId": "9c3f9e5f-6ac7-4c56-d7f5-cdf4e07c121c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               461312    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 18)                4626      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 597,266\n",
            "Trainable params: 597,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.949298 — val_precision: 0.949298 — val_recall: 0.949298\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94930, saving model to ./my_MLP_checkpoint/weights.hdf5\n",
            "963/963 [==============================] - 23s 21ms/step - loss: 0.4025 - accuracy: 0.8832 - val_loss: 0.1707 - val_accuracy: 0.9493 - val_f1: 0.9493 - val_recall: 0.9493 - val_precision: 0.9493\n",
            "Epoch 2/15\n",
            "646/646 [==============================] - 2s 4ms/step\n",
            " — val_f1: 0.953269 — val_precision: 0.953269 — val_recall: 0.953269\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.94930 to 0.95327, saving model to ./my_MLP_checkpoint/weights.hdf5\n",
            "963/963 [==============================] - 18s 19ms/step - loss: 0.1785 - accuracy: 0.9475 - val_loss: 0.1581 - val_accuracy: 0.9533 - val_f1: 0.9533 - val_recall: 0.9533 - val_precision: 0.9533\n",
            "Epoch 3/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.957530 — val_precision: 0.957530 — val_recall: 0.957530\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.95327 to 0.95753, saving model to ./my_MLP_checkpoint/weights.hdf5\n",
            "963/963 [==============================] - 20s 21ms/step - loss: 0.1486 - accuracy: 0.9557 - val_loss: 0.1511 - val_accuracy: 0.9575 - val_f1: 0.9575 - val_recall: 0.9575 - val_precision: 0.9575\n",
            "Epoch 4/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.956998 — val_precision: 0.956998 — val_recall: 0.956998\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.95753\n",
            "963/963 [==============================] - 22s 23ms/step - loss: 0.1313 - accuracy: 0.9588 - val_loss: 0.1456 - val_accuracy: 0.9570 - val_f1: 0.9570 - val_recall: 0.9570 - val_precision: 0.9570\n",
            "Epoch 5/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.956998 — val_precision: 0.956998 — val_recall: 0.956998\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.95753\n",
            "963/963 [==============================] - 19s 20ms/step - loss: 0.1155 - accuracy: 0.9635 - val_loss: 0.1566 - val_accuracy: 0.9570 - val_f1: 0.9570 - val_recall: 0.9570 - val_precision: 0.9570\n",
            "Epoch 6/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.958257 — val_precision: 0.958257 — val_recall: 0.958257\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.95753 to 0.95826, saving model to ./my_MLP_checkpoint/weights.hdf5\n",
            "963/963 [==============================] - 17s 18ms/step - loss: 0.1038 - accuracy: 0.9671 - val_loss: 0.1488 - val_accuracy: 0.9583 - val_f1: 0.9583 - val_recall: 0.9583 - val_precision: 0.9583\n",
            "Epoch 7/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.958741 — val_precision: 0.958741 — val_recall: 0.958741\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.95826 to 0.95874, saving model to ./my_MLP_checkpoint/weights.hdf5\n",
            "963/963 [==============================] - 18s 18ms/step - loss: 0.0948 - accuracy: 0.9698 - val_loss: 0.1550 - val_accuracy: 0.9587 - val_f1: 0.9587 - val_recall: 0.9587 - val_precision: 0.9587\n",
            "Epoch 8/15\n",
            "646/646 [==============================] - 3s 5ms/step\n",
            " — val_f1: 0.958741 — val_precision: 0.958741 — val_recall: 0.958741\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.95874\n",
            "963/963 [==============================] - 22s 23ms/step - loss: 0.0881 - accuracy: 0.9716 - val_loss: 0.1568 - val_accuracy: 0.9587 - val_f1: 0.9587 - val_recall: 0.9587 - val_precision: 0.9587\n",
            "Epoch 9/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.959370 — val_precision: 0.959370 — val_recall: 0.959370\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.95874 to 0.95937, saving model to ./my_MLP_checkpoint/weights.hdf5\n",
            "963/963 [==============================] - 27s 28ms/step - loss: 0.0830 - accuracy: 0.9731 - val_loss: 0.1615 - val_accuracy: 0.9594 - val_f1: 0.9594 - val_recall: 0.9594 - val_precision: 0.9594\n",
            "Epoch 10/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.960097 — val_precision: 0.960097 — val_recall: 0.960097\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.95937 to 0.96010, saving model to ./my_MLP_checkpoint/weights.hdf5\n",
            "963/963 [==============================] - 18s 19ms/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 0.1592 - val_accuracy: 0.9601 - val_f1: 0.9601 - val_recall: 0.9601 - val_precision: 0.9601\n",
            "Epoch 11/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.959613 — val_precision: 0.959613 — val_recall: 0.959613\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.96010\n",
            "963/963 [==============================] - 19s 20ms/step - loss: 0.0766 - accuracy: 0.9750 - val_loss: 0.1679 - val_accuracy: 0.9596 - val_f1: 0.9596 - val_recall: 0.9596 - val_precision: 0.9596\n",
            "Epoch 12/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.961937 — val_precision: 0.961937 — val_recall: 0.961937\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.96010 to 0.96194, saving model to ./my_MLP_checkpoint/weights.hdf5\n",
            "963/963 [==============================] - 20s 21ms/step - loss: 0.0741 - accuracy: 0.9768 - val_loss: 0.1632 - val_accuracy: 0.9619 - val_f1: 0.9619 - val_recall: 0.9619 - val_precision: 0.9619\n",
            "Epoch 13/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.959613 — val_precision: 0.959613 — val_recall: 0.959613\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96194\n",
            "963/963 [==============================] - 22s 23ms/step - loss: 0.0730 - accuracy: 0.9764 - val_loss: 0.1655 - val_accuracy: 0.9596 - val_f1: 0.9596 - val_recall: 0.9596 - val_precision: 0.9596\n",
            "Epoch 14/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.960000 — val_precision: 0.960000 — val_recall: 0.960000\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96194\n",
            "963/963 [==============================] - 20s 21ms/step - loss: 0.0706 - accuracy: 0.9771 - val_loss: 0.1694 - val_accuracy: 0.9600 - val_f1: 0.9600 - val_recall: 0.9600 - val_precision: 0.9600\n",
            "Epoch 15/15\n",
            "646/646 [==============================] - 2s 3ms/step\n",
            " — val_f1: 0.960436 — val_precision: 0.960436 — val_recall: 0.960436\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96194\n",
            "963/963 [==============================] - 18s 19ms/step - loss: 0.0690 - accuracy: 0.9776 - val_loss: 0.1721 - val_accuracy: 0.9604 - val_f1: 0.9604 - val_recall: 0.9604 - val_precision: 0.9604\n",
            "595/595 [==============================] - 2s 3ms/step - loss: 0.1614 - accuracy: 0.9615\n",
            "Test Accuracy: 0.96153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eKRT1_6Ioeb"
      },
      "source": [
        "### Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.ylim(0,1)\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "xDswMV8Ntozg",
        "outputId": "00da7a81-7de5-4d2f-a54b-ac418f17b642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH7R3s2pIwhe"
      },
      "source": [
        "### Model Assessment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  mlp_model = Sequential()\n",
        "  mlp_model.add(Dense(512, input_dim=x_train_mod.shape[1], activation='relu'))\n",
        "  mlp_model.add(Dense(256,  activation='relu'))\n",
        "  mlp_model.add(Dense(y_train_cat.shape[1],  activation='softmax'))\n",
        "  \n",
        "  # Load weights from the pre-trained model\n",
        "  mlp_model.load_weights(\"./my_MLP_checkpoint/weights.hdf5\")\n",
        "  mlp_model.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer=Adam(learning_rate=0.001),\n",
        "      metrics=[\"accuracy\"]\n",
        "      )\n",
        "\n",
        "yhat_probs = mlp_model.predict(x_train_mod, verbose=0)\n",
        "yhat_classes = np.argmax(yhat_probs, axis=1)\n",
        "m_train_f1_score = f1_score(y_train_lb, yhat_classes, average = 'macro')\n",
        "print(\"Train f1-score: {:.2f}% \\n\".format(m_train_f1_score*100))\n",
        "\n",
        "yhat_probs = mlp_model.predict(x_dev_mod, verbose=0)\n",
        "yhat_classes = np.argmax(yhat_probs, axis=1)\n",
        "m_dev_f1_score = f1_score(y_dev_lb, yhat_classes, average = 'macro')\n",
        "print(\"Evaluation f1-score: {:.2f}% \\n\".format(m_dev_f1_score*100))\n",
        "\n",
        "yhat_probs = mlp_model.predict(x_test_mod, verbose=0)\n",
        "yhat_classes = np.argmax(yhat_probs, axis=1)\n",
        "m_test_f1_score = f1_score(y_test_lb, yhat_classes, average = 'macro')\n",
        "print(\"Test f1-score: {:.2f}% \\n\".format(m_test_f1_score*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5_aw3L1tsh6",
        "outputId": "8fa86cc9-8aa3-4500-e77b-0c64ea8c8f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train f1-score: 91.52% \n",
            "\n",
            "Evaluation f1-score: 84.61% \n",
            "\n",
            "Test f1-score: 84.42% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WBP8APaI0VG"
      },
      "source": [
        "### Precision, Recall, AUC, ROC-AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def errorCheck(y_true, y_pred):\n",
        "\n",
        "  # Find the unique classes in y_true and y_pred\n",
        "  unique_classes = np.unique(np.concatenate((y_true, y_pred)))\n",
        "\n",
        "  # Find the classes present in y_true but not in y_pred\n",
        "  missing_classes_y_pred = unique_classes[np.in1d(unique_classes, y_true) & ~np.in1d(unique_classes, y_pred)]\n",
        "\n",
        "  # Find the classes present in y_pred but not in y_true\n",
        "  missing_classes_y_true = unique_classes[np.in1d(unique_classes, y_pred) & ~np.in1d(unique_classes, y_true)]\n",
        "\n",
        "  # Calculate the sample size before modifying y_pred and y_true and my_max to know which has the extra class\n",
        "  if len(y_pred) > len(y_true):\n",
        "    my_max = y_pred\n",
        "  else:\n",
        "    my_max = y_true\n",
        "\n",
        "  sample_size = max(len(y_pred), len(y_true))\n",
        "\n",
        "  # Modify y_pred to include all the classes present in y_true\n",
        "  for c in missing_classes_y_pred:\n",
        "      y_pred = np.append(y_pred, c)\n",
        "\n",
        "  # Modify y_true to include all the classes present in y_pred\n",
        "  for c in missing_classes_y_true:\n",
        "      y_true = np.append(y_true, c)\n",
        "\n",
        "  y_pred_onehot = np.eye(len(unique_classes))[y_pred[:sample_size]]\n",
        "  y_true_onehot = np.eye(len(unique_classes))[y_true[:sample_size]]\n",
        "\n",
        "\n",
        "  return y_true, y_true_onehot, y_pred, y_pred_onehot, my_max"
      ],
      "metadata": {
        "id": "TtJBOppztx62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateResults(x, y_true, y_pred):\n",
        "  # calculate precision, recall and f1\n",
        "  train_precision_score = precision_score(y_true, y_pred, average=None)\n",
        "  train_recall_score = recall_score(y_true, y_pred, average=None)\n",
        "  train_f1_score = f1_score(y_true, y_pred, average=None)\n",
        "\n",
        "  # macro precision, recall, f1 and auc\n",
        "  m_train_precision_score = precision_score(y_true, y_pred, average='macro')\n",
        "\n",
        "  m_train_recall_score = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "  m_train_f1_score = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "  # Error checking\n",
        "  unique_pred = np.unique(y_pred)\n",
        "  unique_true = np.unique(y_true)\n",
        "\n",
        "  if unique_pred.shape != unique_true.shape:\n",
        "      y_true_upd, y_true_onehot, y_pred_upd, y_pred_onehot, my_max = errorCheck(y_true, y_pred)\n",
        "\n",
        "  elif unique_pred.shape == unique_true.shape & (unique_pred != unique_true).all():\n",
        "      y_true_upd, y_true_onehot, y_pred_upd, y_pred_onehot, my_max = errorCheck(y_true, y_pred)\n",
        "\n",
        "  else:\n",
        "    my_max = y_pred # y_pred or y_true is the same thing in this case\n",
        "    # One-hot encode the predicted class labels\n",
        "    y_pred_onehot = np.eye(len(np.unique(y_pred)))[y_pred]\n",
        "\n",
        "    # One-hot encode the true class labels\n",
        "    y_true_onehot = np.eye(len(np.unique(y_true)))[y_true]\n",
        "\n",
        "  m_train_roc_auc_score = roc_auc_score(y_true_onehot, y_pred_onehot, multi_class='ovr', average='macro')\n",
        "\n",
        "  # auc calculation is a bit more messy\n",
        "\n",
        "  classes = np.unique(my_max) # get the classes of the model\n",
        "  train_roc_auc_score = {}\n",
        "  for i in range(len(classes)):\n",
        "      c = classes[i]\n",
        "      # Prepares an auxiliar dataframe to help with the plots\n",
        "      df_x = pd.DataFrame (x) # convert list to a dataframe\n",
        "      y_proba = y_pred_onehot # calculate the probabilities\n",
        "      df_aux = df_x.copy()\n",
        "      df_aux['class'] = [1 if y == c else 0 for y in y_true]\n",
        "      df_aux['prob'] = y_proba[:, i]\n",
        "      df_aux = df_aux.reset_index(drop = True)\n",
        "    \n",
        "      # Calculates the ROC AUC OvR\n",
        "      train_roc_auc_score[c] = roc_auc_score(df_aux['class'], df_aux['prob'])\n",
        "\n",
        "  # Create and print the table\n",
        "  table = [['    ', 'Precision', 'Recall', 'F1', 'AUC', 'Macro-Precision', 'Macro-Recall', 'Macro-F1', 'Macro-AUC'], \n",
        "           ['ADJ', round(train_precision_score[0], 3), round(train_recall_score[0], 3), round(train_f1_score[0], 3), round(train_roc_auc_score[0], 3), '-', '-', '-', '-'],\n",
        "           ['ADP', round(train_precision_score[1], 3), round(train_recall_score[1], 3), round(train_f1_score[1], 3), round(train_roc_auc_score[1], 3), '-', '-', '-', '-'],\n",
        "           ['ADV', round(train_precision_score[2], 3), round(train_recall_score[2], 3), round(train_f1_score[2], 3), round(train_roc_auc_score[2], 3), '-', '-', '-', '-'],\n",
        "           ['AUX', round(train_precision_score[3], 3), round(train_recall_score[3], 3), round(train_f1_score[3], 3), round(train_roc_auc_score[3], 3), '-', '-', '-', '-'],\n",
        "           ['CCONJ', round(train_precision_score[4], 3), round(train_recall_score[4], 3), round(train_f1_score[4], 3), round(train_roc_auc_score[4], 3), '-', '-', '-', '-'],\n",
        "           ['DET', round(train_precision_score[5], 3), round(train_recall_score[5], 3), round(train_f1_score[5], 3), round(train_roc_auc_score[5], 3), '-', '-', '-', '-'],\n",
        "           ['INTJ', round(train_precision_score[6], 3), round(train_recall_score[6], 3), round(train_f1_score[6], 3), round(train_roc_auc_score[6], 3), '-', '-', '-', '-'],\n",
        "           ['NOUN', round(train_precision_score[7], 3), round(train_recall_score[7], 3), round(train_f1_score[7], 3), round(train_roc_auc_score[7], 3), '-', '-', '-', '-'],\n",
        "           ['NUM', round(train_precision_score[8], 3), round(train_recall_score[8], 3), round(train_f1_score[8], 3), round(train_roc_auc_score[8], 3), '-', '-', '-', '-'],\n",
        "           ['PART', round(train_precision_score[9], 3), round(train_recall_score[9], 3), round(train_f1_score[9], 3), round(train_roc_auc_score[9], 3), '-', '-', '-', '-'],\n",
        "           ['PRON', round(train_precision_score[10], 3), round(train_recall_score[10], 3), round(train_f1_score[10], 3), round(train_roc_auc_score[10], 3), '-', '-', '-', '-'],\n",
        "           ['PROPN', round(train_precision_score[11], 3), round(train_recall_score[11], 3), round(train_f1_score[11], 3), round(train_roc_auc_score[11], 3), '-', '-', '-', '-'],\n",
        "           ['PUNCT', round(train_precision_score[12], 3), round(train_recall_score[12], 3), round(train_f1_score[12], 3), round(train_roc_auc_score[12], 3), '-', '-', '-', '-'],\n",
        "           ['SCONJ', round(train_precision_score[13], 3), round(train_recall_score[13], 3), round(train_f1_score[13], 3), round(train_roc_auc_score[13], 3), '-', '-', '-', '-'],\n",
        "           ['SPACE', round(train_precision_score[14], 3), round(train_recall_score[14], 3), round(train_f1_score[14], 3), round(train_roc_auc_score[14], 3), '-', '-', '-', '-'],\n",
        "           ['SYM', round(train_precision_score[15], 3), round(train_recall_score[15], 3), round(train_f1_score[15], 3), round(train_roc_auc_score[15], 3), '-', '-', '-', '-'],\n",
        "           ['VERB', round(train_precision_score[16], 3), round(train_recall_score[16], 3), round(train_f1_score[16], 3), round(train_roc_auc_score[16], 3), '-', '-', '-', '-'],\n",
        "           ['X', round(train_precision_score[17], 3), round(train_recall_score[17], 3), round(train_f1_score[17], 3), round(train_roc_auc_score[17], 3), '-', '-', '-', '-'],\n",
        "           ['Total', '-', '-','-','-', round(m_train_precision_score, 3), round(m_train_recall_score, 3), round(m_train_f1_score, 3), round(m_train_roc_auc_score, 3)]]\n",
        "\n",
        "\n",
        "  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\n",
        "  return table"
      ],
      "metadata": {
        "id": "uDcKC3tGtzRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateFinalResults(x, y):\n",
        "  # predict probabilities for test set\n",
        "  yhat_probs = mlp_model.predict(x, verbose=0)\n",
        "  # predict crisp classes for test set\n",
        "  yhat_classes = np.argmax(yhat_probs, axis=1)\n",
        "\n",
        "\n",
        "  train_precision_score = precision_score(y, yhat_classes, average = None)\n",
        "  train_recall_score = recall_score(y, yhat_classes, average = None)\n",
        "  train_f1_score = f1_score(y, yhat_classes, average = None)\n",
        "\n",
        "\n",
        "  m_train_precision_score = precision_score(y, yhat_classes, average = 'macro')\n",
        "  m_train_recall_score = recall_score(y, yhat_classes, average = 'macro')\n",
        "  m_train_f1_score = f1_score(y, yhat_classes, average = 'macro')\n",
        "\n",
        "\n",
        "  m_train_roc_auc_score = roc_auc_score(y, yhat_probs, multi_class= 'ovr', average = 'macro')\n",
        "\n",
        "  classes = np.unique(y)\n",
        "  train_roc_auc_score = {}\n",
        "  for i in range(len(classes)):\n",
        "      c = classes[i]\n",
        "    \n",
        "      # Prepares an auxiliar dataframe to help with the plots\n",
        "      df_x = pd.DataFrame (x) # convert list to a dataframe\n",
        "      y_proba = mlp_model.predict(x, verbose=0) # calculate the probabilities\n",
        "      df_aux = df_x.copy()\n",
        "      df_aux['class'] = [1 if y == c else 0 for y in y]\n",
        "      df_aux['prob'] = y_proba[:, i]\n",
        "      df_aux = df_aux.reset_index(drop = True)\n",
        "    \n",
        "      # Calculates the ROC AUC OvR\n",
        "      train_roc_auc_score[c] = roc_auc_score(df_aux['class'], df_aux['prob'])\n",
        "\n",
        "  table = [['    ', 'Precision', 'Recall', 'F1', 'AUC', 'Macro-Precision', 'Macro-Recall', 'Macro-F1', 'Macro-AUC'], \n",
        "           ['ADJ', round(train_precision_score[0], 3), round(train_recall_score[0], 3), round(train_f1_score[0], 3), round(train_roc_auc_score[0], 3), '-', '-', '-', '-'],\n",
        "           ['ADP', round(train_precision_score[1], 3), round(train_recall_score[1], 3), round(train_f1_score[1], 3), round(train_roc_auc_score[1], 3), '-', '-', '-', '-'],\n",
        "           ['ADV', round(train_precision_score[2], 3), round(train_recall_score[2], 3), round(train_f1_score[2], 3), round(train_roc_auc_score[2], 3), '-', '-', '-', '-'],\n",
        "           ['AUX', round(train_precision_score[3], 3), round(train_recall_score[3], 3), round(train_f1_score[3], 3), round(train_roc_auc_score[3], 3), '-', '-', '-', '-'],\n",
        "           ['CCONJ', round(train_precision_score[4], 3), round(train_recall_score[4], 3), round(train_f1_score[4], 3), round(train_roc_auc_score[4], 3), '-', '-', '-', '-'],\n",
        "           ['DET', round(train_precision_score[5], 3), round(train_recall_score[5], 3), round(train_f1_score[5], 3), round(train_roc_auc_score[5], 3), '-', '-', '-', '-'],\n",
        "           ['INTJ', round(train_precision_score[6], 3), round(train_recall_score[6], 3), round(train_f1_score[6], 3), round(train_roc_auc_score[6], 3), '-', '-', '-', '-'],\n",
        "           ['NOUN', round(train_precision_score[7], 3), round(train_recall_score[7], 3), round(train_f1_score[7], 3), round(train_roc_auc_score[7], 3), '-', '-', '-', '-'],\n",
        "           ['NUM', round(train_precision_score[8], 3), round(train_recall_score[8], 3), round(train_f1_score[8], 3), round(train_roc_auc_score[8], 3), '-', '-', '-', '-'],\n",
        "           ['PART', round(train_precision_score[9], 3), round(train_recall_score[9], 3), round(train_f1_score[9], 3), round(train_roc_auc_score[9], 3), '-', '-', '-', '-'],\n",
        "           ['PRON', round(train_precision_score[10], 3), round(train_recall_score[10], 3), round(train_f1_score[10], 3), round(train_roc_auc_score[10], 3), '-', '-', '-', '-'],\n",
        "           ['PROPN', round(train_precision_score[11], 3), round(train_recall_score[11], 3), round(train_f1_score[11], 3), round(train_roc_auc_score[11], 3), '-', '-', '-', '-'],\n",
        "           ['PUNCT', round(train_precision_score[12], 3), round(train_recall_score[12], 3), round(train_f1_score[12], 3), round(train_roc_auc_score[12], 3), '-', '-', '-', '-'],\n",
        "           ['SCONJ', round(train_precision_score[13], 3), round(train_recall_score[13], 3), round(train_f1_score[13], 3), round(train_roc_auc_score[13], 3), '-', '-', '-', '-'],\n",
        "           ['SPACE', round(train_precision_score[14], 3), round(train_recall_score[14], 3), round(train_f1_score[14], 3), round(train_roc_auc_score[14], 3), '-', '-', '-', '-'],\n",
        "           ['SYM', round(train_precision_score[15], 3), round(train_recall_score[15], 3), round(train_f1_score[15], 3), round(train_roc_auc_score[15], 3), '-', '-', '-', '-'],\n",
        "           ['VERB', round(train_precision_score[16], 3), round(train_recall_score[16], 3), round(train_f1_score[16], 3), round(train_roc_auc_score[16], 3), '-', '-', '-', '-'],\n",
        "           ['X', round(train_precision_score[17], 3), round(train_recall_score[17], 3), round(train_f1_score[17], 3), round(train_roc_auc_score[17], 3), '-', '-', '-', '-'],\n",
        "           ['Total', '-', '-','-','-', round(m_train_precision_score, 3), round(m_train_recall_score, 3), round(m_train_f1_score, 3), round(m_train_roc_auc_score, 3)]]\n",
        "\n",
        "  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\n",
        "  return table"
      ],
      "metadata": {
        "id": "siEEBOULt0bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Baseline Classifier ------------------------------------------------------------------------------------- \\n\")\n",
        "\n",
        "print(\"The training results: \\n\")\n",
        "baseline_train_table = calculateResults(x_train_mod, y_train_lb, le.fit_transform(pred_train_y))\n",
        "\n",
        "print(\"The evaluation results: \\n\")\n",
        "baseline_dev_table = calculateResults(x_dev_mod, y_dev_lb, le.transform(pred_dev_y))\n",
        "\n",
        "print(\"The test results: \\n\")\n",
        "baseline_test_table = calculateResults(x_test_mod, y_test_lb,  le.transform(pred_test_y))\n",
        "\n",
        "print(\"MLP ---------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "print(\"The training results: \\n\")\n",
        "mlp_train_table = calculateFinalResults(x_train_mod, y_train_lb)\n",
        "\n",
        "print(\"The evaluation results: \\n\")\n",
        "mlp_dev_table = calculateFinalResults(x_dev_mod, y_dev_lb)\n",
        "\n",
        "print(\"The test results: \\n\")\n",
        "mlp_test_table = calculateFinalResults(x_test_mod, y_test_lb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "189Gu7mMt1zX",
        "outputId": "ba283f1c-2511-489b-827c-9b59f3f05c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Classifier ------------------------------------------------------------------------------------- \n",
            "\n",
            "The training results: \n",
            "\n",
            "╒════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│        │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │ Macro-AUC   │\n",
            "╞════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ ADJ    │ 0.91        │ 0.939    │ 0.924 │ 0.967 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADP    │ 0.951       │ 0.875    │ 0.911 │ 0.935 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADV    │ 0.925       │ 0.798    │ 0.857 │ 0.898 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ AUX    │ 0.884       │ 0.995    │ 0.936 │ 0.994 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ CCONJ  │ 0.991       │ 0.995    │ 0.993 │ 0.997 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ DET    │ 0.947       │ 0.98     │ 0.963 │ 0.987 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ INTJ   │ 0.892       │ 0.537    │ 0.671 │ 0.768 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NOUN   │ 0.94        │ 0.941    │ 0.941 │ 0.965 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NUM    │ 0.906       │ 0.998    │ 0.95  │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PART   │ 0.718       │ 0.99     │ 0.832 │ 0.99  │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PRON   │ 0.984       │ 0.911    │ 0.946 │ 0.955 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PROPN  │ 0.995       │ 0.984    │ 0.99  │ 0.992 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PUNCT  │ 0.995       │ 1.0      │ 0.997 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SCONJ  │ 0.663       │ 0.919    │ 0.77  │ 0.955 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SPACE  │ 1.0         │ 1.0      │ 1.0   │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SYM    │ 1.0         │ 0.5      │ 0.667 │ 0.75  │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ VERB   │ 0.927       │ 0.857    │ 0.891 │ 0.924 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ X      │ 1.0         │ 0.5      │ 0.667 │ 0.75  │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total  │ -           │ -        │ -     │ -     │ 0.924             │ 0.873          │ 0.884      │ 0.935       │\n",
            "╘════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n",
            "The evaluation results: \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│        │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │ Macro-AUC   │\n",
            "╞════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ ADJ    │ 0.881       │ 0.737    │ 0.803 │ 0.866 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADP    │ 0.937       │ 0.885    │ 0.91  │ 0.939 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADV    │ 0.937       │ 0.71     │ 0.808 │ 0.854 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ AUX    │ 0.887       │ 0.995    │ 0.938 │ 0.994 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ CCONJ  │ 0.995       │ 0.995    │ 0.995 │ 0.997 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ DET    │ 0.951       │ 0.985    │ 0.967 │ 0.99  │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ INTJ   │ 1.0         │ 0.6      │ 0.75  │ 0.8   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NOUN   │ 0.737       │ 0.926    │ 0.82  │ 0.931 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NUM    │ 0.888       │ 0.856    │ 0.872 │ 0.928 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PART   │ 0.747       │ 0.978    │ 0.847 │ 0.985 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PRON   │ 0.982       │ 0.914    │ 0.947 │ 0.956 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PROPN  │ 0.997       │ 0.622    │ 0.766 │ 0.811 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PUNCT  │ 0.992       │ 1.0      │ 0.996 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SCONJ  │ 0.65        │ 0.874    │ 0.746 │ 0.933 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SPACE  │ 1.0         │ 1.0      │ 1.0   │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SYM    │ 0.0         │ 0.0      │ 0.0   │ 0.5   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ VERB   │ 0.894       │ 0.761    │ 0.822 │ 0.875 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ X      │ 0.5         │ 1.0      │ 0.667 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total  │ -           │ -        │ -     │ -     │ 0.832             │ 0.824          │ 0.814      │ 0.909       │\n",
            "╘════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n",
            "The test results: \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│        │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │ Macro-AUC   │\n",
            "╞════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ ADJ    │ 0.874       │ 0.72     │ 0.789 │ 0.857 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADP    │ 0.953       │ 0.879    │ 0.914 │ 0.937 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADV    │ 0.925       │ 0.702    │ 0.798 │ 0.85  │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ AUX    │ 0.859       │ 0.996    │ 0.923 │ 0.993 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ CCONJ  │ 0.994       │ 0.998    │ 0.996 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ DET    │ 0.944       │ 0.987    │ 0.965 │ 0.991 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ INTJ   │ 1.0         │ 0.5      │ 0.667 │ 0.75  │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NOUN   │ 0.734       │ 0.93     │ 0.82  │ 0.933 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NUM    │ 0.86        │ 0.843    │ 0.851 │ 0.921 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PART   │ 0.755       │ 0.99     │ 0.857 │ 0.991 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PRON   │ 0.987       │ 0.914    │ 0.949 │ 0.957 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PROPN  │ 0.976       │ 0.594    │ 0.739 │ 0.797 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PUNCT  │ 0.994       │ 0.999    │ 0.996 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SCONJ  │ 0.646       │ 0.919    │ 0.759 │ 0.955 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SPACE  │ 1.0         │ 1.0      │ 1.0   │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SYM    │ 0.0         │ 0.0      │ 0.0   │ 0.5   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ VERB   │ 0.906       │ 0.762    │ 0.827 │ 0.876 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ X      │ 0.0         │ 0.0      │ 0.0   │ 0.5   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total  │ -           │ -        │ -     │ -     │ 0.8               │ 0.763          │ 0.77       │ 0.878       │\n",
            "╘════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n",
            "MLP ---------------------------------------------------------------------------------------------------------\n",
            "\n",
            "The training results: \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│        │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │ Macro-AUC   │\n",
            "╞════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ ADJ    │ 0.975       │ 0.986    │ 0.98  │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADP    │ 0.992       │ 0.992    │ 0.992 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADV    │ 0.988       │ 0.978    │ 0.983 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ AUX    │ 0.993       │ 0.994    │ 0.994 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ CCONJ  │ 0.999       │ 1.0      │ 0.999 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ DET    │ 0.997       │ 0.998    │ 0.998 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ INTJ   │ 0.99        │ 0.963    │ 0.977 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NOUN   │ 0.988       │ 0.985    │ 0.987 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NUM    │ 0.974       │ 0.983    │ 0.979 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PART   │ 0.985       │ 0.999    │ 0.992 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PRON   │ 0.998       │ 0.996    │ 0.997 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PROPN  │ 0.992       │ 0.976    │ 0.984 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PUNCT  │ 0.999       │ 1.0      │ 0.999 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SCONJ  │ 0.977       │ 0.972    │ 0.974 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SPACE  │ 0.976       │ 0.999    │ 0.987 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SYM    │ 1.0         │ 0.5      │ 0.667 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ VERB   │ 0.988       │ 0.984    │ 0.986 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ X      │ 0.0         │ 0.0      │ 0.0   │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total  │ -           │ -        │ -     │ -     │ 0.934             │ 0.906          │ 0.915      │ 1.0         │\n",
            "╘════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n",
            "The evaluation results: \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│        │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │ Macro-AUC   │\n",
            "╞════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ ADJ    │ 0.896       │ 0.939    │ 0.917 │ 0.995 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADP    │ 0.965       │ 0.969    │ 0.967 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADV    │ 0.929       │ 0.899    │ 0.914 │ 0.995 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ AUX    │ 0.989       │ 0.989    │ 0.989 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ CCONJ  │ 0.997       │ 0.995    │ 0.996 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ DET    │ 0.988       │ 0.987    │ 0.988 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ INTJ   │ 0.962       │ 0.833    │ 0.893 │ 0.997 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NOUN   │ 0.946       │ 0.939    │ 0.943 │ 0.995 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NUM    │ 0.923       │ 0.942    │ 0.932 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PART   │ 0.958       │ 0.964    │ 0.961 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PRON   │ 0.982       │ 0.979    │ 0.98  │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PROPN  │ 0.978       │ 0.935    │ 0.956 │ 0.995 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PUNCT  │ 0.994       │ 1.0      │ 0.997 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SCONJ  │ 0.884       │ 0.874    │ 0.879 │ 0.998 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SPACE  │ 0.953       │ 0.995    │ 0.974 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SYM    │ 0.0         │ 0.0      │ 0.0   │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ VERB   │ 0.948       │ 0.939    │ 0.944 │ 0.996 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ X      │ 0.0         │ 0.0      │ 0.0   │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total  │ -           │ -        │ -     │ -     │ 0.85              │ 0.843          │ 0.846      │ 0.998       │\n",
            "╘════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n",
            "The test results: \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════════╤═════════════╤══════════╤═══════╤═══════╤═══════════════════╤════════════════╤════════════╤═════════════╕\n",
            "│        │ Precision   │ Recall   │ F1    │ AUC   │ Macro-Precision   │ Macro-Recall   │ Macro-F1   │ Macro-AUC   │\n",
            "╞════════╪═════════════╪══════════╪═══════╪═══════╪═══════════════════╪════════════════╪════════════╪═════════════╡\n",
            "│ ADJ    │ 0.887       │ 0.924    │ 0.905 │ 0.994 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADP    │ 0.975       │ 0.972    │ 0.973 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ ADV    │ 0.916       │ 0.896    │ 0.906 │ 0.997 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ AUX    │ 0.98        │ 0.987    │ 0.984 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ CCONJ  │ 0.994       │ 0.993    │ 0.993 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ DET    │ 0.993       │ 0.982    │ 0.987 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ INTJ   │ 0.919       │ 0.773    │ 0.84  │ 0.975 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NOUN   │ 0.946       │ 0.935    │ 0.94  │ 0.996 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ NUM    │ 0.912       │ 0.954    │ 0.933 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PART   │ 0.968       │ 0.984    │ 0.976 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PRON   │ 0.981       │ 0.981    │ 0.981 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PROPN  │ 0.963       │ 0.932    │ 0.947 │ 0.996 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ PUNCT  │ 0.992       │ 0.999    │ 0.996 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SCONJ  │ 0.896       │ 0.932    │ 0.913 │ 0.999 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SPACE  │ 0.96        │ 0.992    │ 0.976 │ 1.0   │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ SYM    │ 0.0         │ 0.0      │ 0.0   │ 0.993 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ VERB   │ 0.951       │ 0.943    │ 0.947 │ 0.997 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ X      │ 0.0         │ 0.0      │ 0.0   │ 0.737 │ -                 │ -              │ -          │ -           │\n",
            "├────────┼─────────────┼──────────┼───────┼───────┼───────────────────┼────────────────┼────────────┼─────────────┤\n",
            "│ Total  │ -           │ -        │ -     │ -     │ 0.846             │ 0.843          │ 0.844      │ 0.982       │\n",
            "╘════════╧═════════════╧══════════╧═══════╧═══════╧═══════════════════╧════════════════╧════════════╧═════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGUZhDuCJAnW"
      },
      "source": [
        "### Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  \n",
        "  def nn_model(activation = 'relu', neurons=512, optimizer = 'Adam', dropout = 0.5, kernel_constraint= 3.0, learning_rate = 0.01):\n",
        "    mlp_model = Sequential()\n",
        "    mlp_model.add(Dense(512, input_dim=x_train_mod.shape[1] , activation='relu', kernel_constraint=MaxNorm(3.0)))\n",
        "    mlp_model.add(Dropout(0.5))\n",
        "    mlp_model.add(Dense(256,  activation='relu', kernel_constraint=MaxNorm(2.0)))\n",
        "    mlp_model.add(Dropout(0.5))\n",
        "    mlp_model.add(Dense(y_train_cat.shape[1], activation='softmax'))\n",
        "    \n",
        "    mlp_model.load_weights(\"./my_MLP_checkpoint/weights.hdf5\")\n",
        "\n",
        "    mlp_model.compile(loss='categorical_crossentropy', optimizer=tune_lr(optimizer, learning_rate), metrics=[\"accuracy\"])\n",
        "\n",
        "    return mlp_model\n",
        "\n",
        "  def tune_lr(optimizer, learning_rate):\n",
        "    optimizerDict = {'Adam': Adam(learning_rate=learning_rate), 'SGD': SGD(learning_rate=learning_rate),'RMSprop': RMSprop(learning_rate=learning_rate)}\n",
        "    result = optimizerDict[optimizer]\n",
        "\n",
        "    return result\n",
        "\n",
        "  mlp_callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "    './my_MLP_checkpoint/weights.hdf5',\n",
        "    monitor = 'val_accuracy',\n",
        "    verbose=2,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True)\n",
        "  ]\n",
        "\n",
        "  learning_rate = [0.001, 0.01, 0.1]\n",
        "  activation = ['softmax', 'relu', 'tanh']\n",
        "  optimizer = ['SGD', 'Adam', 'RMSprop']\n",
        "  kernel_constraint = [1.0, 2.0, 3.0]\n",
        "  dropout = [0.1, 0.2, 0.3]\n",
        "  neurons = [1024, 512, 256]\n",
        "  batch_size = [64, 128, 256]\n",
        "  epochs = [8, 10, 12, 15, 17]\n",
        "  param_grid = dict(epochs = epochs, activation = activation, neurons = neurons, optimizer = optimizer, dropout = dropout, kernel_constraint = kernel_constraint, learning_rate= learning_rate, batch_size = batch_size)\n",
        "  clf = KerasClassifier(build_fn = nn_model, epochs = epochs, verbose = 2, activation = activation, neurons = neurons, optimizer = optimizer,\n",
        "                        dropout = dropout, kernel_constraint = kernel_constraint, learning_rate = learning_rate, batch_size = batch_size)\n",
        "  mlp_model = RandomizedSearchCV(estimator= clf, cv = 5, param_distributions = param_grid, n_jobs=-1,verbose = 2,random_state=1234)\n",
        "  mlp_model.fit(x_dev_mod, y_dev_cat)\n",
        "\n",
        "print(\"Best estimator \\n\", mlp_model.best_estimator_)\n",
        "print(\"Best score \\n\", mlp_model.best_score_)\n",
        "print(\"Best params \\n\", mlp_model.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isZJSn3Ht4YW",
        "outputId": "775cbfa3-fd85-430c-9928-b9a6ca9e7772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  warnings.warn(\n",
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "81/81 - 4s - loss: 0.1805 - accuracy: 0.9531 - 4s/epoch - 54ms/step\n",
            "Epoch 2/17\n",
            "81/81 - 3s - loss: 0.1337 - accuracy: 0.9633 - 3s/epoch - 35ms/step\n",
            "Epoch 3/17\n",
            "81/81 - 2s - loss: 0.1130 - accuracy: 0.9659 - 2s/epoch - 31ms/step\n",
            "Epoch 4/17\n",
            "81/81 - 2s - loss: 0.0958 - accuracy: 0.9701 - 2s/epoch - 27ms/step\n",
            "Epoch 5/17\n",
            "81/81 - 3s - loss: 0.0829 - accuracy: 0.9745 - 3s/epoch - 37ms/step\n",
            "Epoch 6/17\n",
            "81/81 - 2s - loss: 0.0728 - accuracy: 0.9783 - 2s/epoch - 23ms/step\n",
            "Epoch 7/17\n",
            "81/81 - 2s - loss: 0.0603 - accuracy: 0.9816 - 2s/epoch - 22ms/step\n",
            "Epoch 8/17\n",
            "81/81 - 2s - loss: 0.0566 - accuracy: 0.9821 - 2s/epoch - 22ms/step\n",
            "Epoch 9/17\n",
            "81/81 - 2s - loss: 0.0489 - accuracy: 0.9840 - 2s/epoch - 22ms/step\n",
            "Epoch 10/17\n",
            "81/81 - 2s - loss: 0.0436 - accuracy: 0.9860 - 2s/epoch - 22ms/step\n",
            "Epoch 11/17\n",
            "81/81 - 2s - loss: 0.0437 - accuracy: 0.9862 - 2s/epoch - 28ms/step\n",
            "Epoch 12/17\n",
            "81/81 - 3s - loss: 0.0397 - accuracy: 0.9877 - 3s/epoch - 36ms/step\n",
            "Epoch 13/17\n",
            "81/81 - 2s - loss: 0.0367 - accuracy: 0.9891 - 2s/epoch - 22ms/step\n",
            "Epoch 14/17\n",
            "81/81 - 2s - loss: 0.0326 - accuracy: 0.9900 - 2s/epoch - 22ms/step\n",
            "Epoch 15/17\n",
            "81/81 - 2s - loss: 0.0302 - accuracy: 0.9902 - 2s/epoch - 21ms/step\n",
            "Epoch 16/17\n",
            "81/81 - 2s - loss: 0.0295 - accuracy: 0.9908 - 2s/epoch - 22ms/step\n",
            "Epoch 17/17\n",
            "81/81 - 2s - loss: 0.0289 - accuracy: 0.9906 - 2s/epoch - 21ms/step\n",
            "Best estimator \n",
            " KerasClassifier(\n",
            "\tmodel=None\n",
            "\tbuild_fn=<function nn_model at 0x7f60efdc69d0>\n",
            "\twarm_start=False\n",
            "\trandom_state=None\n",
            "\toptimizer=SGD\n",
            "\tloss=None\n",
            "\tmetrics=None\n",
            "\tbatch_size=256\n",
            "\tvalidation_batch_size=None\n",
            "\tverbose=2\n",
            "\tcallbacks=None\n",
            "\tvalidation_split=0.0\n",
            "\tshuffle=True\n",
            "\trun_eagerly=False\n",
            "\tepochs=17\n",
            "\tactivation=relu\n",
            "\tneurons=512\n",
            "\tdropout=0.3\n",
            "\tkernel_constraint=1.0\n",
            "\tlearning_rate=0.01\n",
            "\tclass_weight=None\n",
            ")\n",
            "Best score \n",
            " 0.9612590799031476\n",
            "Best params \n",
            " {'optimizer': 'SGD', 'neurons': 512, 'learning_rate': 0.01, 'kernel_constraint': 1.0, 'epochs': 17, 'dropout': 0.3, 'batch_size': 256, 'activation': 'relu'}\n"
          ]
        }
      ]
    }
  ]
}